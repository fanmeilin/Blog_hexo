{"meta":{"version":1,"warehouse":"4.0.0"},"models":{"Asset":[{"_id":"themes/fluid/source/css/gitalk.css","path":"css/gitalk.css","modified":1,"renderable":1},{"_id":"themes/fluid/source/css/main.styl","path":"css/main.styl","modified":1,"renderable":1},{"_id":"themes/fluid/source/img/avatar.png","path":"img/avatar.png","modified":1,"renderable":1},{"_id":"themes/fluid/source/img/default.png","path":"img/default.png","modified":1,"renderable":1},{"_id":"themes/fluid/source/img/favicon.png","path":"img/favicon.png","modified":1,"renderable":1},{"_id":"themes/fluid/source/img/favicon1.png","path":"img/favicon1.png","modified":1,"renderable":1},{"_id":"themes/fluid/source/img/loading.gif","path":"img/loading.gif","modified":1,"renderable":1},{"_id":"themes/fluid/source/img/meicon.png","path":"img/meicon.png","modified":1,"renderable":1},{"_id":"themes/fluid/source/img/meiconbali.jpg","path":"img/meiconbali.jpg","modified":1,"renderable":1},{"_id":"themes/fluid/source/img/police_beian.png","path":"img/police_beian.png","modified":1,"renderable":1},{"_id":"themes/fluid/source/img/wechatid.png","path":"img/wechatid.png","modified":1,"renderable":1},{"_id":"themes/fluid/source/js/boot.js","path":"js/boot.js","modified":1,"renderable":1},{"_id":"themes/fluid/source/js/color-schema.js","path":"js/color-schema.js","modified":1,"renderable":1},{"_id":"themes/fluid/source/js/events.js","path":"js/events.js","modified":1,"renderable":1},{"_id":"themes/fluid/source/js/img-lazyload.js","path":"js/img-lazyload.js","modified":1,"renderable":1},{"_id":"themes/fluid/source/js/leancloud.js","path":"js/leancloud.js","modified":1,"renderable":1},{"_id":"themes/fluid/source/js/local-search.js","path":"js/local-search.js","modified":1,"renderable":1},{"_id":"themes/fluid/source/js/plugins.js","path":"js/plugins.js","modified":1,"renderable":1},{"_id":"themes/fluid/source/js/utils.js","path":"js/utils.js","modified":1,"renderable":1},{"_id":"themes/fluid/source/xml/local-search.xml","path":"xml/local-search.xml","modified":1,"renderable":1},{"_id":"themes/fluid/source/img/bg/03990bbe091d5cca73421ac40bacfc46_1.jpg","path":"img/bg/03990bbe091d5cca73421ac40bacfc46_1.jpg","modified":1,"renderable":1},{"_id":"themes/fluid/source/img/bg/4cb90122eb95819122b32d17e238ee1b_1.jpg","path":"img/bg/4cb90122eb95819122b32d17e238ee1b_1.jpg","modified":1,"renderable":1},{"_id":"themes/fluid/source/img/bg/36e6c0d304d7a672d6d828e164f2c48b_1.jpg","path":"img/bg/36e6c0d304d7a672d6d828e164f2c48b_1.jpg","modified":1,"renderable":1},{"_id":"themes/fluid/source/img/bg/5afd5a558c69261be00db0024ce0ccdf_1.jpg","path":"img/bg/5afd5a558c69261be00db0024ce0ccdf_1.jpg","modified":1,"renderable":1},{"_id":"themes/fluid/source/img/bg/7cc417b7ace4b99c19d3034179926555_3.jpg","path":"img/bg/7cc417b7ace4b99c19d3034179926555_3.jpg","modified":1,"renderable":1},{"_id":"themes/fluid/source/img/bg/7fb86b41c8bb0d7bff7a3142c83d8348_1.jpg","path":"img/bg/7fb86b41c8bb0d7bff7a3142c83d8348_1.jpg","modified":1,"renderable":1},{"_id":"themes/fluid/source/img/bg/9884183b3b1e1b50e1d68c69d97b38d6_4.jpg","path":"img/bg/9884183b3b1e1b50e1d68c69d97b38d6_4.jpg","modified":1,"renderable":1},{"_id":"themes/fluid/source/img/bg/a8d2b7b118107c8a8446ca81691d20ee_1.jpg","path":"img/bg/a8d2b7b118107c8a8446ca81691d20ee_1.jpg","modified":1,"renderable":1},{"_id":"themes/fluid/source/img/bg/a9564f5c58411c94f3d83feeb0647643_1.jpg","path":"img/bg/a9564f5c58411c94f3d83feeb0647643_1.jpg","modified":1,"renderable":1},{"_id":"themes/fluid/source/img/bg/b4f8a6143ef84a1ef177b4bde3f8d805_1.jpg","path":"img/bg/b4f8a6143ef84a1ef177b4bde3f8d805_1.jpg","modified":1,"renderable":1},{"_id":"themes/fluid/source/img/bg/b7fb479d6dbb4525a0393f9934aceab3_1.jpg","path":"img/bg/b7fb479d6dbb4525a0393f9934aceab3_1.jpg","modified":1,"renderable":1},{"_id":"themes/fluid/source/img/bg/c65f7b13787572d4f5d33f66d627df71_2.jpg","path":"img/bg/c65f7b13787572d4f5d33f66d627df71_2.jpg","modified":1,"renderable":1},{"_id":"themes/fluid/source/img/bg/bd643dc0ad68f830b3a0eeae50ceba5f_4.jpg","path":"img/bg/bd643dc0ad68f830b3a0eeae50ceba5f_4.jpg","modified":1,"renderable":1},{"_id":"themes/fluid/source/img/bg/c989b7d72a5a30f48a3544a7cec9562b_1.jpg","path":"img/bg/c989b7d72a5a30f48a3544a7cec9562b_1.jpg","modified":1,"renderable":1},{"_id":"themes/fluid/source/img/bg/e7050bc333ebfc01afce3b434f95e7b0_2.jpg","path":"img/bg/e7050bc333ebfc01afce3b434f95e7b0_2.jpg","modified":1,"renderable":1},{"_id":"themes/fluid/source/img/bg/girl.png","path":"img/bg/girl.png","modified":1,"renderable":1},{"_id":"themes/fluid/source/img/bg/wm1.mp4","path":"img/bg/wm1.mp4","modified":1,"renderable":1},{"_id":"themes/fluid/source/img/bg/wm10.mp4","path":"img/bg/wm10.mp4","modified":1,"renderable":1},{"_id":"themes/fluid/source/img/bg/wm11.mp4","path":"img/bg/wm11.mp4","modified":1,"renderable":1},{"_id":"themes/fluid/source/img/bg/wm2.mp4","path":"img/bg/wm2.mp4","modified":1,"renderable":1},{"_id":"themes/fluid/source/img/bg/wm9.mp4","path":"img/bg/wm9.mp4","modified":1,"renderable":1},{"_id":"themes/fluid/source/lib/hint/hint.min.css","path":"lib/hint/hint.min.css","modified":1,"renderable":1}],"Cache":[{"_id":"source/404/index.md","hash":"62e7b5d955e560619709cb232c84770eea4f89d0","modified":1628063828058},{"_id":"source/_posts/page-site.md","hash":"4d10eed5a6813f11da63a59a4aa50dd92299fb8a","modified":1628841780856},{"_id":"source/_data/friends.json","hash":"519916312399331fdcee1d72ee4cef6b284908fb","modified":1628064027776},{"_id":"source/about/index.md","hash":"6ad944506a4423dc14c4b873517c88264eb53496","modified":1628063494459},{"_id":"source/categories/index.md","hash":"4d36849168b56d025907ee89d14018aa6a97588d","modified":1628063466721},{"_id":"source/contact/index.md","hash":"f094ba3c8a8c85f46715cb0503c66610d03a2cd1","modified":1628063592028},{"_id":"source/tags/index.md","hash":"feaf990ce7dc3299d419fc52c092dd9c99f56150","modified":1627994916046},{"_id":"source/friends/index.md","hash":"514e5b3fb524e240a6dca39bef60c784a95e2b67","modified":1628063987355},{"_id":"source/_posts/deep_learning/fine-tuning.md","hash":"5225d5a38f0c3e1a17733ff0ece88382fd363ddd","modified":1628847172243},{"_id":"source/_posts/deep_learning/gradient-clip.md","hash":"ca61ef8e445bba6c6d8eee8cab37f418498883cb","modified":1628818237872},{"_id":"source/_posts/docker/docker-intro.md","hash":"c69c36fcf279975816de97b1eef012a559f14202","modified":1628654054658},{"_id":"source/_posts/docker/docker-ssh.md","hash":"c8f0b19a8c614c6df60102eb5eb5164f9e7abcee","modified":1628587429324},{"_id":"source/_posts/dvc/dvc-config.md","hash":"983437e5d91b716442fecd24c8c0ca4ecfa14ffa","modified":1628589945404},{"_id":"source/_posts/hexo_config/hexo-math-config.md","hash":"9385cc40c0183e448647f8d1e1cf2e090f29aabe","modified":1628237208572},{"_id":"source/_posts/git_config/git-submodule.md","hash":"b87b8367e54a7894a2badd89cbe1eb2da0430e1b","modified":1628585048797},{"_id":"source/_posts/leetcode/leetcode-offer05.md","hash":"7ebc5c29ede944471ba516984d116b7fba3bb1e5","modified":1628678346988},{"_id":"source/_posts/leetcode/leetcode-offer03.md","hash":"830bc728c87d64e8d15854aff04c0df3c9b5090a","modified":1628652234386},{"_id":"source/_posts/leetcode/leetcode-offer04.md","hash":"5b876963cf1ba6902a14f68d7679b43b7a0e7171","modified":1628678354713},{"_id":"source/_posts/leetcode/leetcode-offer09.md","hash":"7e6dc54015e70fd8ddc97c79f5d6660f8cad3526","modified":1628576745543},{"_id":"source/_posts/leetcode/leetcode-offer10-1.md","hash":"cd09ca86e072d1277b728f0b37534200ec254168","modified":1628577319739},{"_id":"source/_posts/leetcode/leetcode-offer10-2.md","hash":"36cce4218bf41f85ed922f30c88b2ec583eb346d","modified":1628578537399},{"_id":"source/_posts/math/Eckark-young.md","hash":"a56c5b1e2478729c654164dc9c520a21b83021a1","modified":1628494423757},{"_id":"source/_posts/math/Mahalanobis-distance.md","hash":"cbe7670e05c1a03043d911210950eb77349a08dc","modified":1628493460081},{"_id":"source/_posts/math/covariance-matrix.md","hash":"99d0795f864890030574066c0382faca492ba08c","modified":1628169263401},{"_id":"source/_posts/math/low-rank-app.md","hash":"44d8417a57ca99b0d25c581ad69e218da085cd22","modified":1628503710748},{"_id":"themes/fluid/source/css/_pages/_category/category.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1628164697300},{"_id":"themes/fluid/source/css/_pages/_tag/tag.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1628164697301},{"_id":"themes/fluid/.editorconfig","hash":"b595159772f3ee1ef5e6780ce307270e741cb309","modified":1628164697275},{"_id":"themes/fluid/.gitattributes","hash":"3e00e1fb043438cd820d94ee3dc9ffb6718996f3","modified":1628164697276},{"_id":"themes/fluid/.eslintrc","hash":"3df89453e1f63051fafc90f16a8d83951050e316","modified":1628164697276},{"_id":"themes/fluid/.gitignore","hash":"5d7e78749ba0a1efcf61253d4a9e50fc6ce0b4bc","modified":1628164697277},{"_id":"themes/fluid/LICENSE","hash":"694fb3659a4331dd752bd92e4248623bff8617cd","modified":1628164697278},{"_id":"themes/fluid/README.md","hash":"9adb524ba5a0821c8c612fe5619f64f242d5ad6b","modified":1628164697278},{"_id":"themes/fluid/README_en.md","hash":"2b47ed68ec888dcc34fa6aad9ce95aeba6744fec","modified":1628164697278},{"_id":"themes/fluid/_config.yml","hash":"f4611dbb514fabf6aa7edb31cdf90cbf7182a243","modified":1628164697278},{"_id":"themes/fluid/gulpfile.js","hash":"93e2bd4a4f1902e7a4c99ae3ebfa6420fd906c1b","modified":1628164697279},{"_id":"themes/fluid/package.json","hash":"8b6640fe2d7e71900bf708b977074f621b2e7a8a","modified":1628164697289},{"_id":"themes/fluid/languages/de.yml","hash":"288f649c2c2314eb610693b18853ee74f0541e87","modified":1628164697279},{"_id":"themes/fluid/languages/en.yml","hash":"31f2867619a768606166778d4ee51f3d00ac33a0","modified":1628164697279},{"_id":"themes/fluid/languages/ja.yml","hash":"dc43be11a300893ebef47283c22f2f946ca21260","modified":1628164697279},{"_id":"themes/fluid/languages/zh-CN.yml","hash":"3b92f4428d66c31610f6cde13b82ee723aff00d2","modified":1628164697280},{"_id":"themes/fluid/languages/eo.yml","hash":"2c1c481d9af116e79fe55a0aa0bdbb143a97f559","modified":1628164697279},{"_id":"themes/fluid/languages/zh-TW.yml","hash":"de9b7e729d72eee9327671c3d5df0a607c4c3257","modified":1628164697280},{"_id":"themes/fluid/layout/404.ejs","hash":"79a598e43c40d48b23076361720f1e77df466e41","modified":1628164697280},{"_id":"themes/fluid/layout/about.ejs","hash":"5b6de01c82b14834ab1e67f0a803612f5855f064","modified":1628164697287},{"_id":"themes/fluid/layout/categories.ejs","hash":"4255c27c8f31fbcc12ec3a973fe73b7a3a35782f","modified":1628164697287},{"_id":"themes/fluid/layout/archive.ejs","hash":"7a1e19dec37804927f0d331d7e6c80ed03becd61","modified":1628164697287},{"_id":"themes/fluid/layout/category.ejs","hash":"dd2bd15cbd811d6ea973b6e6a17d99e36151e274","modified":1628164697288},{"_id":"themes/fluid/layout/index.ejs","hash":"32a6c84b4690ecf8505ca786bc80aa90530b1534","modified":1628164697288},{"_id":"themes/fluid/layout/layout.ejs","hash":"a8342733553ce3368a8520e6f430666070f7d8dc","modified":1628164697288},{"_id":"themes/fluid/layout/links.ejs","hash":"b282e8888cd844bb24b31677a32feb444ecc4144","modified":1628164697288},{"_id":"themes/fluid/layout/page.ejs","hash":"f867e69e563b8ad83054714f73d9173ea050d93b","modified":1628164697288},{"_id":"themes/fluid/layout/post.ejs","hash":"edfeb655895027d15334d009324d27a29926cc94","modified":1628164697288},{"_id":"themes/fluid/layout/tag.ejs","hash":"3a9296eb7181e8b3fb0cdc60cbafc815b98d6f51","modified":1628164697289},{"_id":"themes/fluid/layout/tags.ejs","hash":"b7c1a6d8fc1097fc16d2300260297013cb692153","modified":1628164697289},{"_id":"themes/fluid/.github/ISSUE_TEMPLATE/bug_report.md","hash":"beb3474d6f65c1e56700ba872c6a0d0836d4168e","modified":1628164697276},{"_id":"themes/fluid/.github/ISSUE_TEMPLATE/bug_report_zh.md","hash":"78ce211415d502c5a4398d786d5c697d34d868b9","modified":1628164697276},{"_id":"themes/fluid/.github/ISSUE_TEMPLATE/feature_request.md","hash":"5cc30e7b6e7b77c8b40b182ba02a5d93d37d2fc2","modified":1628164697277},{"_id":"themes/fluid/.github/ISSUE_TEMPLATE/feature_request_zh.md","hash":"7db378613df2b7d13e8c428c006399a879a4a852","modified":1628164697277},{"_id":"themes/fluid/.github/ISSUE_TEMPLATE/question.md","hash":"102213e5d6790d060c0e26b4a3a7ec744d753c52","modified":1628164697277},{"_id":"themes/fluid/.github/ISSUE_TEMPLATE/question_zh.md","hash":"18381d03518526d7cefd024a0bdd8d9e7c6440f5","modified":1628164697277},{"_id":"themes/fluid/.github/workflows/limit.yaml","hash":"bdbdb66da69ab7353b546f02150a6792f4787975","modified":1628164697277},{"_id":"themes/fluid/.github/workflows/lint.yaml","hash":"4c04caa5ca20bbcbf0934bb7adba4d2cd8a26da2","modified":1628164697277},{"_id":"themes/fluid/layout/_partial/archive-list.ejs","hash":"7d780309e12c437c2f8a246dd2fd0c272b8636ce","modified":1628164697280},{"_id":"themes/fluid/layout/_partial/beian.ejs","hash":"53d9f79b4a3b71d2e89872fa138bc09611862ee4","modified":1628164697281},{"_id":"themes/fluid/layout/_partial/css.ejs","hash":"04957fcd5c9025da54d593652b51939e54056827","modified":1628164697283},{"_id":"themes/fluid/layout/_partial/footer.ejs","hash":"585bb98a23ced3cfbbff6d73d48fdbcd4a87577a","modified":1628164697283},{"_id":"themes/fluid/layout/_partial/head.ejs","hash":"8e29e7ddbda1555c0f9d0d4b5d4550975fec7537","modified":1628164697284},{"_id":"themes/fluid/layout/_partial/nav.ejs","hash":"48944e12d95dc46137f9f270629296cfd2a8dd22","modified":1628164697285},{"_id":"themes/fluid/layout/_partial/paginator.ejs","hash":"0d443f23c459787338917900f50fec1c8b3b3bdd","modified":1628164697285},{"_id":"themes/fluid/layout/_partial/post-meta.ejs","hash":"3f16de8c40d87c7d23eba121dd8061757c3f9a58","modified":1628164697286},{"_id":"themes/fluid/layout/_partial/scripts.ejs","hash":"1d8349b7d26271e08cee592aa66f9c79ec41c3c0","modified":1628164697286},{"_id":"themes/fluid/layout/_partial/search.ejs","hash":"bea21f1b5de61badd6c068080315c201fc80bc36","modified":1628164697286},{"_id":"themes/fluid/layout/_partial/statistics.ejs","hash":"a70c26e415a27f07f38b9384e7eb48d1f2b30328","modified":1628164697287},{"_id":"themes/fluid/layout/_partial/toc.ejs","hash":"76e6bc368cf46d4103ea9514699e10ec0b9a4b56","modified":1628164697287},{"_id":"themes/fluid/scripts/events/index.js","hash":"91defe82d50a317903411f0b260da0f140f43dc4","modified":1628164697289},{"_id":"themes/fluid/scripts/filters/locals.js","hash":"2340a576635b16fd2456b3494f5afe89cd7764db","modified":1628164697291},{"_id":"themes/fluid/scripts/filters/post-filter.js","hash":"cb72e5acfba882a6eacd6cae8db3238bb078737a","modified":1628164697291},{"_id":"themes/fluid/scripts/generators/local-search.js","hash":"bda7fbe58082a2a02c0db066794b791b14462271","modified":1628164697292},{"_id":"themes/fluid/scripts/generators/pages.js","hash":"a2a15ea722863aba09dcad578558432682a3b6b3","modified":1628164697292},{"_id":"themes/fluid/scripts/helpers/export-config.js","hash":"c72a7373c19b730e926b476eb528f651617ac4f2","modified":1628164697292},{"_id":"themes/fluid/scripts/helpers/page.js","hash":"49b2c6449d7be35739c6cfea3cab4e790580983a","modified":1628164697292},{"_id":"themes/fluid/scripts/helpers/url.js","hash":"1664f8faa028898bd6f91d6db61c7dbf7463ee01","modified":1628164697292},{"_id":"themes/fluid/scripts/helpers/utils.js","hash":"4acb213f90f1e7ba3696ef08d894a2a84807b669","modified":1628164697293},{"_id":"themes/fluid/scripts/helpers/wordcount.js","hash":"da6144ee040fed0a9b9f45da3478bc33087b5ac9","modified":1628164697293},{"_id":"themes/fluid/scripts/tags/button.js","hash":"e1d0caed12e7cd9a35cf64272c41854b2901a58f","modified":1628164697293},{"_id":"themes/fluid/scripts/tags/checkbox.js","hash":"dac0e08eaa3614a6fd9ddbdfb4584094b1bdb30a","modified":1628164697293},{"_id":"themes/fluid/scripts/tags/group-image.js","hash":"cc176cc1d7e7cc28cedf8397ae748c691d140be2","modified":1628164697293},{"_id":"themes/fluid/scripts/tags/label.js","hash":"6c5916d86c63795c7e910bf614b0e7ece5073702","modified":1628164697294},{"_id":"themes/fluid/scripts/tags/mermaid.js","hash":"dbfe59fde77d87b1d7d0c46480a2a729010988eb","modified":1628164697294},{"_id":"themes/fluid/scripts/tags/note.js","hash":"8020acc2c4bb3a2054e3cb349fac7cd10b79a0be","modified":1628164697294},{"_id":"themes/fluid/scripts/utils/join-path.js","hash":"ec068c699155565aea4aa4ab55d8a10b2947a114","modified":1628164697294},{"_id":"themes/fluid/scripts/utils/object.js","hash":"d798779ec79a53ce04b8ac79efd5d064981d95bd","modified":1628164697294},{"_id":"themes/fluid/source/css/gitalk.css","hash":"1fe60b2ab1d704f5a4f55e700dca5b8785fb390e","modified":1628164697303},{"_id":"themes/fluid/source/css/main.styl","hash":"bf536db598434c36cc0c752196bfde46e584a92e","modified":1628164697303},{"_id":"themes/fluid/source/img/avatar.png","hash":"fe739a158cc128f70f780eb5fa96f388b81d478f","modified":1628164697304},{"_id":"themes/fluid/source/img/default.png","hash":"7bb2b8ee07db305bcadee2985b81b942027ae940","modified":1628164697304},{"_id":"themes/fluid/source/img/favicon.png","hash":"fe739a158cc128f70f780eb5fa96f388b81d478f","modified":1628164697304},{"_id":"themes/fluid/source/img/favicon1.png","hash":"64b215db2cb3af98fe639e94537cb5209f959c78","modified":1628164697304},{"_id":"themes/fluid/source/img/loading.gif","hash":"2d2fc0f947940f98c21afafef39ecf226a2e8d55","modified":1628164697304},{"_id":"themes/fluid/source/img/police_beian.png","hash":"90efded6baa2dde599a9d6b1387973e8e64923ea","modified":1628164697305},{"_id":"themes/fluid/source/img/wechatid.png","hash":"fc275472320ea1215e6c7c7a3f64045b9e784944","modified":1628559587277},{"_id":"themes/fluid/source/js/boot.js","hash":"5264c0d2eb73b4948ee6bcb1bd847a924d906088","modified":1628164697305},{"_id":"themes/fluid/source/js/color-schema.js","hash":"2840108a36b1e9a02cd2ed25adcffde08c42e1cc","modified":1628164697305},{"_id":"themes/fluid/source/js/events.js","hash":"2c40be98f3471427626b9130fd231bc7e9a66d03","modified":1628164697305},{"_id":"themes/fluid/source/js/img-lazyload.js","hash":"67f6250f98b36a6599ea982d11cbb060c5ffb92a","modified":1628164697306},{"_id":"themes/fluid/source/js/leancloud.js","hash":"ca82e71e31d3d5ef7fe9487756af06d4e27d9b53","modified":1628164697306},{"_id":"themes/fluid/source/js/local-search.js","hash":"3b9322b6b669c870360db468446b00f53bd1b44c","modified":1628164697306},{"_id":"themes/fluid/source/js/plugins.js","hash":"1afcd1ca415edc994ae813d6f5d54dd3d1888bc4","modified":1628164697307},{"_id":"themes/fluid/source/js/utils.js","hash":"f20aa828122fce9a76c03b07c7da142704edc8c0","modified":1628164697307},{"_id":"themes/fluid/source/xml/local-search.xml","hash":"85fcc23b4db654a7f91fc55b6fb0442bb3ed3a9a","modified":1628164697308},{"_id":"themes/fluid/layout/_partial/comments/changyan.ejs","hash":"b13e69e555ddec2a71710e07178793e7e13319e7","modified":1628164697281},{"_id":"themes/fluid/layout/_partial/comments/cusdis.ejs","hash":"1e93ca89777e4beb0f0e5cb70e03aab48e958542","modified":1628164697281},{"_id":"themes/fluid/layout/_partial/comments/disqus.ejs","hash":"7a35381478328b65c9d81827504c4e031bc76a86","modified":1628164697281},{"_id":"themes/fluid/layout/_partial/comments/gitalk.ejs","hash":"7f04e5c22821bb94da791973d9c6692b03bac81d","modified":1628164697282},{"_id":"themes/fluid/layout/_partial/comments/remark42.ejs","hash":"45c879768b40ba56af62e18ad54bffbf73a6f3a1","modified":1628164697282},{"_id":"themes/fluid/layout/_partial/comments/twikoo.ejs","hash":"c3297931cf5d3d1bc53d988b74cbc54dd06ebbd7","modified":1628164697282},{"_id":"themes/fluid/layout/_partial/comments/utterances.ejs","hash":"d1e86754c9560f7346200b2aa9a7f715a3fac82b","modified":1628164697282},{"_id":"themes/fluid/layout/_partial/comments/valine.ejs","hash":"caae3f692523275b8ca1c56c009a6aeb9c7fdc03","modified":1628164697283},{"_id":"themes/fluid/layout/_partial/comments/livere.ejs","hash":"bcceafab01fe695c59951d939f7cef502f3d7b48","modified":1628164697282},{"_id":"themes/fluid/layout/_partial/comments/waline.ejs","hash":"d6f6620fbc6cf3df5a52322378c0d703b7e1fcf9","modified":1628164697283},{"_id":"themes/fluid/layout/_partial/plugins/analytics.ejs","hash":"d20f54bf2fd5cd274b4b9c5542eafbfec5120838","modified":1628164697285},{"_id":"themes/fluid/layout/_partial/plugins/math.ejs","hash":"a49a0064b55cf6d8f2a61abfecd41f0083757e04","modified":1628164697285},{"_id":"themes/fluid/layout/_partial/plugins/typed.ejs","hash":"c57817ceaee868d416558e56d2a8d0d418c64a2d","modified":1628164697286},{"_id":"themes/fluid/layout/_partial/plugins/nprogress.ejs","hash":"47c1df255aa552ad71ef3e57deca46530a8f2802","modified":1628164697286},{"_id":"themes/fluid/layout/_partial/plugins/mermaid.ejs","hash":"fd1f78287c868ccab78b6244b66e3f9b0968c4a8","modified":1628164697285},{"_id":"themes/fluid/scripts/events/lib/compatible-configs.js","hash":"c0da20f9adca2761d370cc6dda013ec1ecbb7710","modified":1628164697290},{"_id":"themes/fluid/scripts/events/lib/footnote.js","hash":"13d8466cd4c98367131b5f3d6a30b3d4ce8de26f","modified":1628164697290},{"_id":"themes/fluid/scripts/events/lib/hello.js","hash":"1a262c15896663dba773a1796f637f6484f3e524","modified":1628164697290},{"_id":"themes/fluid/scripts/events/lib/highlight.js","hash":"5eec946182fd537a4d75f15bdf7a09453cc00d83","modified":1628164697290},{"_id":"themes/fluid/scripts/events/lib/lazyload.js","hash":"00a4876e9c37b77fed619138b8bd9ad88ea1e9f3","modified":1628164697291},{"_id":"themes/fluid/scripts/events/lib/merge-configs.js","hash":"3f2dba4959b27466521de97eff692815650c02b7","modified":1628164697291},{"_id":"themes/fluid/source/css/_functions/base.styl","hash":"171697018fd384fce0834875ca94b91f16564cac","modified":1628164697295},{"_id":"themes/fluid/source/css/_mixins/base.styl","hash":"046979dbd8cdabd21d89f9c1d8f1bb3f2fd06d6f","modified":1628164697295},{"_id":"themes/fluid/source/css/_pages/pages.styl","hash":"92c062cf55457b6549497244d09ec34e9c0c95c2","modified":1628164697302},{"_id":"themes/fluid/source/css/_variables/base.styl","hash":"d555a4c9df7b49250c1747c2fbd8353f2d822775","modified":1628164697303},{"_id":"themes/fluid/source/lib/hint/hint.min.css","hash":"64fa8c328dc93432ec822de2818aef21a4f63b29","modified":1628164697307},{"_id":"themes/fluid/source/css/_pages/_about/about.styl","hash":"47235d222812e2f829e9bde039fa719bbced9325","modified":1628164697296},{"_id":"themes/fluid/source/css/_pages/_archive/archive.styl","hash":"86926a80bf6f39a7f47789b1a8f44b5984b4683f","modified":1628164697296},{"_id":"themes/fluid/source/css/_pages/_base/base.styl","hash":"33d237014f22324a034ae463857ce2af72a0d65e","modified":1628164697298},{"_id":"themes/fluid/source/css/_pages/_base/inline.styl","hash":"6f2a3b8af2793dd831f661c6db0ccbe0a62ccc48","modified":1628164697299},{"_id":"themes/fluid/source/css/_pages/_base/color-schema.styl","hash":"2dd6f1a8470f5bd10ed53cfcba6811197c79d487","modified":1628164697298},{"_id":"themes/fluid/source/css/_pages/_base/keyframes.styl","hash":"58a7f8f2baea2d58cf5f7edfc91314ee5d7156ca","modified":1628164697299},{"_id":"themes/fluid/source/css/_pages/_base/rewrite.styl","hash":"c628894ec5afab5b3e6f4633390f2b403bf6678f","modified":1628164697299},{"_id":"themes/fluid/source/css/_pages/_category/categories.styl","hash":"0924e35eff2ec84e2d9e4772abccda452d9463ef","modified":1628164697299},{"_id":"themes/fluid/source/css/_pages/_index/index.styl","hash":"5775fd234c62a2f3520b34b2a66fe181cc2d4ea3","modified":1628164697300},{"_id":"themes/fluid/source/css/_pages/_links/links.styl","hash":"83694b28209c548ef38bee78e473b02e90cbcf9f","modified":1628164697300},{"_id":"themes/fluid/source/css/_pages/_post/post.styl","hash":"c189a52dbc6eb554d1da3f2636920813b3b7e4fb","modified":1628164697301},{"_id":"themes/fluid/source/css/_pages/_post/tag_plugin.styl","hash":"88939a09d1ab73a2b96a6b8b08c96ad03d402728","modified":1628164697301},{"_id":"themes/fluid/source/css/_pages/_tag/tags.styl","hash":"29e9b72cfda2f2baf9cf2597fcd7f9e66303a9bd","modified":1628164697301},{"_id":"themes/fluid/source/css/_pages/_base/_widget/banner.styl","hash":"da823846f0896f16b21c7430f047f7222a89cd10","modified":1628164697296},{"_id":"themes/fluid/source/css/_pages/_base/_widget/board.styl","hash":"bb9cdde191b9b1287ba19414bab862f30be6a8a0","modified":1628164697297},{"_id":"themes/fluid/source/css/_pages/_base/_widget/copy-btn.styl","hash":"c398892fba1494dd6fd417415076458ed321d34d","modified":1628164697297},{"_id":"themes/fluid/source/css/_pages/_base/_widget/footer.styl","hash":"dbd0a3518e5bfca92851490b34654f46bb5cfc76","modified":1628164697297},{"_id":"themes/fluid/source/css/_pages/_base/_widget/footnote.styl","hash":"41935973a66c14ab2bea0539d4b1f15c62534fa4","modified":1628164697297},{"_id":"themes/fluid/source/css/_pages/_base/_widget/header.styl","hash":"f770c5c3ee89421e9e3f1313ca5bd07a2448f400","modified":1628164697297},{"_id":"themes/fluid/source/css/_pages/_base/_widget/qrcode.styl","hash":"d29064ed8bdf62d5cf4eac32ebdb5d0c7075ebbd","modified":1628164697298},{"_id":"themes/fluid/source/css/_pages/_base/_widget/scroll-btn.styl","hash":"e568f308df26465e0432197e8b57384707470f54","modified":1628164697298},{"_id":"themes/fluid/source/css/_pages/_base/_widget/search.styl","hash":"1f4e678d7219815ab62de1b92ec75e021247f90b","modified":1628164697298},{"_id":"themes/fluid/source/img/meicon.png","hash":"9232364c346db7d635804d69e1e2d5ecda6007f3","modified":1628215074715},{"_id":"themes/fluid/source/img/bg/9884183b3b1e1b50e1d68c69d97b38d6_4.jpg","hash":"a0159bcf7c7ab5b2cbe2e4fdb7307b7ac8e0d061","modified":1628600323224},{"_id":"themes/fluid/source/img/bg/36e6c0d304d7a672d6d828e164f2c48b_1.jpg","hash":"ca1ad49f059e26019a7df2904a7bc22a5b10d09c","modified":1628599383955},{"_id":"themes/fluid/source/img/bg/7fb86b41c8bb0d7bff7a3142c83d8348_1.jpg","hash":"084e16156fa67e0d090663ed15ad64b2104a67a6","modified":1628599469189},{"_id":"themes/fluid/source/img/meiconbali.jpg","hash":"251240f4833515e6df48cdec4b17f4c0313c0784","modified":1628232992878},{"_id":"themes/fluid/source/img/bg/7cc417b7ace4b99c19d3034179926555_3.jpg","hash":"36304bc7d6ed3f6d8a9330d843c92d105c506f28","modified":1628600362520},{"_id":"themes/fluid/source/img/bg/c65f7b13787572d4f5d33f66d627df71_2.jpg","hash":"ce37c68377e3d277d432507ec33e4d02c458d569","modified":1628599408332},{"_id":"themes/fluid/source/img/bg/b7fb479d6dbb4525a0393f9934aceab3_1.jpg","hash":"e5ba3a056b042b7411776311840140e17a51529c","modified":1628599510771},{"_id":"themes/fluid/source/img/bg/e7050bc333ebfc01afce3b434f95e7b0_2.jpg","hash":"b56be4c6838c5b1e98c50468b5efab86c006cdb0","modified":1628599530161},{"_id":"themes/fluid/source/img/bg/4cb90122eb95819122b32d17e238ee1b_1.jpg","hash":"7df7f85fa28588cd468bb4ccc46d788be62f468d","modified":1628599358021},{"_id":"themes/fluid/source/img/bg/bd643dc0ad68f830b3a0eeae50ceba5f_4.jpg","hash":"2b0eb78d531d1aa4ea559d18efc9068deda95d20","modified":1628599332736},{"_id":"themes/fluid/source/img/bg/5afd5a558c69261be00db0024ce0ccdf_1.jpg","hash":"9f21bac1d0ae6664b50b799880d7f6ffb16b0ac4","modified":1628599335626},{"_id":"themes/fluid/source/img/bg/c989b7d72a5a30f48a3544a7cec9562b_1.jpg","hash":"3de36db1282675551f69ffe9c4932800a712b4ee","modified":1628599055757},{"_id":"themes/fluid/source/img/bg/03990bbe091d5cca73421ac40bacfc46_1.jpg","hash":"79cb7b38f7f28ccdc9cdb8fa498fbf772036ba2c","modified":1628599224283},{"_id":"themes/fluid/source/img/bg/a9564f5c58411c94f3d83feeb0647643_1.jpg","hash":"2909b72df883e07a59e4d77f783dfbb7adce0774","modified":1628599373545},{"_id":"themes/fluid/source/img/bg/b4f8a6143ef84a1ef177b4bde3f8d805_1.jpg","hash":"c431e3f86fd73aa25221d1dc7001a9caee5b6e16","modified":1628598147585},{"_id":"themes/fluid/source/img/bg/a8d2b7b118107c8a8446ca81691d20ee_1.jpg","hash":"8a53d60923c984efe760eeadfed04d468a7b04e9","modified":1628599637788},{"_id":"themes/fluid/source/img/bg/wm2.mp4","hash":"b6fdb4962f2efe2ba593c786af557ab04e01942a","modified":1628597868505},{"_id":"themes/fluid/source/img/bg/girl.png","hash":"bb2aa45e869a12640a9c38f54dbc0fab32b9e692","modified":1628600557043},{"_id":"themes/fluid/source/img/bg/wm10.mp4","hash":"b870f16f79786e1fd956bef8b14e1e3659356025","modified":1628598805790},{"_id":"themes/fluid/source/img/bg/wm1.mp4","hash":"b5ff1c5af1be3edba17807f0c75540a078eff6af","modified":1628597830184},{"_id":"themes/fluid/source/img/bg/wm9.mp4","hash":"7333f9649921c5e94c6e081939bd7cda1dec6964","modified":1628598556280},{"_id":"themes/fluid/source/img/bg/wm11.mp4","hash":"d4bde698732e28c122f421e604be1654796a7034","modified":1628598938251},{"_id":"public/search.xml","hash":"3d8e853cdbb6359de442613680b97c2219650fb6","modified":1628847216259},{"_id":"public/local-search.xml","hash":"61f640aa3c21b7d0aab6adcfa27eadb6f8bf2f25","modified":1628847216259},{"_id":"public/404/index.html","hash":"88a01be0af7d8982f668143ea03f7e41d11b273d","modified":1628847216259},{"_id":"public/about/index.html","hash":"8f264136ffc02c65b95373b090f125980e8aa116","modified":1628847216259},{"_id":"public/contact/index.html","hash":"68fc986a991f084dce54834eb98c9336cb69dc0b","modified":1628847216259},{"_id":"public/tags/index.html","hash":"932533405e595375da0800b6fcf2977e1d1184a5","modified":1628847216259},{"_id":"public/friends/index.html","hash":"bc4ad9617a59c9d5bf4e051a0d4a7e050a53de72","modified":1628847216259},{"_id":"public/categories/文献/index.html","hash":"1b798c9d91e5650110cec11ab20a3aef0ed6c9d4","modified":1628847216259},{"_id":"public/categories/深度学习/index.html","hash":"dac46cd7449dcb813b17000b3f564963eb1f1665","modified":1628847216259},{"_id":"public/categories/docker/index.html","hash":"c39de66dc7e305577ac5ab303140e4ea25fe1215","modified":1628847216259},{"_id":"public/categories/dvc/index.html","hash":"73598d1bf6db6cf5327c15091cfceeb7c884a89e","modified":1628847216259},{"_id":"public/categories/配置/index.html","hash":"357a0ce3673edc33e53da97475d8102281b26ec4","modified":1628847216259},{"_id":"public/categories/git/index.html","hash":"f7a8f83e90424167a71cd61a466d5a514b2b3002","modified":1628847216259},{"_id":"public/categories/剑指/index.html","hash":"7d8d1a5dc1a0d3e986954a28ee7f581b4a1b9d63","modified":1628847216259},{"_id":"public/categories/math/index.html","hash":"2e95aa4f90e58dd6cb6f80b6554723f32e173d6d","modified":1628847216259},{"_id":"public/categories/math/线性代数/index.html","hash":"135fa4d4555ba2cfb75ee51f50c0ccc6039985f3","modified":1628847216259},{"_id":"public/categories/配置/hexo/index.html","hash":"8516fdfd1a1cffa1e2ac8bc64657dbaa8ff4a0bd","modified":1628847216259},{"_id":"public/categories/math/概率论/index.html","hash":"fda2ce1a93a6fc9777e3777e6be1994e1f67ed61","modified":1628847216259},{"_id":"public/archives/index.html","hash":"33c61e34c51b663ebddbf11ecbbf50fa79099aaf","modified":1628847216259},{"_id":"public/archives/page/2/index.html","hash":"541b14d4cfcda095983ac0676947ab8184902c9f","modified":1628847216259},{"_id":"public/archives/2021/index.html","hash":"ee3595f9aa98d4c9750ce0b7a461d45f4102da45","modified":1628847216259},{"_id":"public/archives/2021/page/2/index.html","hash":"f56ca0d752d3c20682f206e6f49c1a3e3623529d","modified":1628847216259},{"_id":"public/archives/2021/08/index.html","hash":"bbb1383b5ffdf0c2da35fd78282b4f4a3d090779","modified":1628847216259},{"_id":"public/archives/2021/08/page/2/index.html","hash":"dacaa21792ea48b4f9bb9e4dacc12b2fc6f22b27","modified":1628847216259},{"_id":"public/tags/深度学习，梯度/index.html","hash":"e5d8e6600c130c01cadb18ad73b73022e4b6477f","modified":1628847216259},{"_id":"public/tags/文献/index.html","hash":"3b759571b0694dc16c26104026fbe9e84a878c15","modified":1628847216259},{"_id":"public/tags/深度学习/index.html","hash":"0445c040e16bd73f49c1b928c3e46f943ca3054c","modified":1628847216259},{"_id":"public/tags/微调/index.html","hash":"8da8c8bd5f22bc788fee4d9e9ceb2325c66e8d53","modified":1628847216259},{"_id":"public/tags/docker/index.html","hash":"f5ffe229da5f2a4be3f28d365e680db3b6dd415d","modified":1628847216259},{"_id":"public/tags/远程配置/index.html","hash":"d0c28a5a81125ea3cf0f5a21f911d4ca40ac7d22","modified":1628847216259},{"_id":"public/tags/ssh/index.html","hash":"4d942f94b82dbfa5159a1c5f4cebd5088dbbaa0c","modified":1628847216259},{"_id":"public/tags/dvc/index.html","hash":"6bcc081c3bb6f357c4d0efe62979f480735e9caa","modified":1628847216259},{"_id":"public/tags/hexo/index.html","hash":"89be744cb9ec7d7b3a04959b6a525c5d4da265bc","modified":1628847216259},{"_id":"public/tags/fluid/index.html","hash":"eb91889f302b6ec99379c27bde86bc425ad1569a","modified":1628847216259},{"_id":"public/tags/配置/index.html","hash":"42349f3f94c9fdfb4f8a3d53f970c21deb8ebee8","modified":1628847216259},{"_id":"public/tags/git/index.html","hash":"ae35d867e2e0c8ece515f19850ed180fbaed1faa","modified":1628847216259},{"_id":"public/tags/剑指/index.html","hash":"4f142d845409a1c0787b3d5fa0e0ec462c7eb943","modified":1628847216259},{"_id":"public/tags/数组/index.html","hash":"af2c601b797abe2bdd77e226180c7531a96f4e08","modified":1628847216259},{"_id":"public/tags/字符串/index.html","hash":"cf8ad8bfb0556b985ee71b0a57bafedea7f04e35","modified":1628847216259},{"_id":"public/tags/数组查找/index.html","hash":"71f00f45e717c39f8810c59935fc69e299a0aace","modified":1628847216259},{"_id":"public/tags/栈/index.html","hash":"3d2ddd2feb202cad16c7260dbebfbe4fe7a567ec","modified":1628847216259},{"_id":"public/tags/斐波那契/index.html","hash":"ffda9f1832c66af3ead603f886782652dc2c2614","modified":1628847216259},{"_id":"public/tags/动态规划/index.html","hash":"29727f4b04b601ece3e190b675ae54a653139887","modified":1628847216259},{"_id":"public/tags/math/index.html","hash":"8f73cc9db6d9b9822ce3aff11210ec812e00eba6","modified":1628847216259},{"_id":"public/tags/线性代数/index.html","hash":"8ed5e3723aface81d5c9b48e9664e3ca312f80dd","modified":1628847216259},{"_id":"public/404.html","hash":"a07264e818b65c0e757b3f8d9afac6528c3d3602","modified":1628847216259},{"_id":"public/tags/马氏距离/index.html","hash":"838bd2ae41d997cfe49e406d0d1964e9adf171f1","modified":1628847216259},{"_id":"public/tags/概率论/index.html","hash":"4de028d44c8413614f1fe99e68cda80e969ea56b","modified":1628847216259},{"_id":"public/links/index.html","hash":"5e8ea5e3c8b0ce55c8e37d5e6d81db62fbb56c83","modified":1628847216259},{"_id":"public/categories/index.html","hash":"8be668c996f543196637a402e3f4e543e5fea44d","modified":1628847216259},{"_id":"public/2021/08/13/page-site/index.html","hash":"3c490e9bd18f3e801dc6ef563d5b0f09da26acf2","modified":1628847216259},{"_id":"public/2021/08/13/deep_learning/fine-tuning/index.html","hash":"3ebc334a4f6b06420b8cbe671f17ec31641e17fe","modified":1628847216259},{"_id":"public/2021/08/12/deep_learning/gradient-clip/index.html","hash":"31c1866329874dddc766b9ee1bebbb8d6cf7ee00","modified":1628847216259},{"_id":"public/2021/08/11/leetcode/leetcode-offer05/index.html","hash":"5aa1492dc11fd90e93d4307f71e4a03c829128f6","modified":1628847216259},{"_id":"public/2021/08/11/leetcode/leetcode-offer04/index.html","hash":"e70021fb326c4a998108cca72e302d5148f3c340","modified":1628847216259},{"_id":"public/2021/08/11/leetcode/leetcode-offer03/index.html","hash":"d0c7caafdf5fe9b50eb871c8d6a4095eb5f7a2b9","modified":1628847216259},{"_id":"public/2021/08/10/dvc/dvc-config/index.html","hash":"c8b5d9d8a7a3c8b0d9e58d6b7abdeaafc631a94d","modified":1628847216259},{"_id":"public/2021/08/10/docker/docker-ssh/index.html","hash":"341b786554233480714403b31a04c68aca664457","modified":1628847216259},{"_id":"public/2021/08/10/docker/docker-intro/index.html","hash":"2c0de71f9d8e717ab15dad5142bb77751be01339","modified":1628847216259},{"_id":"public/2021/08/10/leetcode/leetcode-offer10-2/index.html","hash":"711dc96b1df38dbd3714c878265ce0ae97eed4c3","modified":1628847216259},{"_id":"public/2021/08/10/leetcode/leetcode-offer10-1/index.html","hash":"9cd00ddc16a054236f5c8311a48c4f32eabad7d6","modified":1628847216259},{"_id":"public/2021/08/10/leetcode/leetcode-offer09/index.html","hash":"c9010c29b5422f4ddd890f8bb5b135ce01955040","modified":1628847216259},{"_id":"public/2021/08/09/math/Mahalanobis-distance/index.html","hash":"33421aa4a2898ef7495794d5056c01f0db6fb2d2","modified":1628847216259},{"_id":"public/2021/08/09/math/Eckark-young/index.html","hash":"1bae20ad063f1c160d6c7168959833c6a093c3dd","modified":1628847216259},{"_id":"public/2021/08/06/math/low-rank-app/index.html","hash":"aaa91afc2b458f0b0a7aab95bad65aa9cf8baebc","modified":1628847216259},{"_id":"public/2021/08/06/git_config/git-submodule/index.html","hash":"040220303d930045c2fbaa5af9ac682233274bd4","modified":1628847216259},{"_id":"public/2021/08/05/hexo_config/hexo-math-config/index.html","hash":"d43adfa23ed3491f0f059590506ebde8f649d1e5","modified":1628847216259},{"_id":"public/2021/08/05/math/covariance-matrix/index.html","hash":"dd8f6faa4697e3478289cfdc4918131c08937bd8","modified":1628847216259},{"_id":"public/index.html","hash":"ba29ccddbaaa680e70e4c39e20bc6b54844a659b","modified":1628847216259},{"_id":"public/page/2/index.html","hash":"5f270cbf248257230da8141c9507208636c3319a","modified":1628847216259},{"_id":"public/img/avatar.png","hash":"fe739a158cc128f70f780eb5fa96f388b81d478f","modified":1628847216259},{"_id":"public/img/loading.gif","hash":"2d2fc0f947940f98c21afafef39ecf226a2e8d55","modified":1628847216259},{"_id":"public/img/favicon.png","hash":"fe739a158cc128f70f780eb5fa96f388b81d478f","modified":1628847216259},{"_id":"public/img/favicon1.png","hash":"64b215db2cb3af98fe639e94537cb5209f959c78","modified":1628847216259},{"_id":"public/img/police_beian.png","hash":"90efded6baa2dde599a9d6b1387973e8e64923ea","modified":1628847216259},{"_id":"public/img/wechatid.png","hash":"fc275472320ea1215e6c7c7a3f64045b9e784944","modified":1628847216259},{"_id":"public/xml/local-search.xml","hash":"85fcc23b4db654a7f91fc55b6fb0442bb3ed3a9a","modified":1628847216259},{"_id":"public/live2dw/assets/mtn/00_idle.mtn","hash":"b224c60e463b9f71ddbfc0c720e430496c175f4f","modified":1628847216259},{"_id":"public/live2dw/assets/mtn/01.mtn","hash":"fb550833ae22c9954c3e01df37ed29b2d61700f2","modified":1628847216259},{"_id":"public/live2dw/assets/mtn/02.mtn","hash":"7eafc52edc73b7cb80ae70d34b43c6ac778fa47b","modified":1628847216259},{"_id":"public/live2dw/assets/mtn/03.mtn","hash":"f900737c7a98441cbb2e05255427e6260e19ae68","modified":1628847216259},{"_id":"public/live2dw/assets/mtn/04.mtn","hash":"c7a25d3c5d783639bae18db2f3cd284b819c3c85","modified":1628847216259},{"_id":"public/live2dw/assets/mtn/05.mtn","hash":"dd20ad24b5d1830a5d44b9bccb28f922eea5e0e5","modified":1628847216259},{"_id":"public/live2dw/assets/mtn/06.mtn","hash":"ad404bd852d276cdd3d054c953e23f90e4e45ae1","modified":1628847216259},{"_id":"public/live2dw/assets/mtn/07.mtn","hash":"b7f2e3a9fa4f3ffbb6e64a08f8d9f45ca1868ffb","modified":1628847216259},{"_id":"public/live2dw/assets/tororo.model.json","hash":"3b96ea33460642d288c98327444966d93a0c11ba","modified":1628847216259},{"_id":"public/live2dw/assets/tororo.pose.json","hash":"81438bf69b32c7c11e311b4fe043730cdc7b7ec2","modified":1628847216259},{"_id":"public/live2dw/assets/mtn/08.mtn","hash":"4411c7651ff65195b113d95e7d5ebef8a59a37d9","modified":1628847216259},{"_id":"public/live2dw/lib/L2Dwidget.min.js","hash":"5f1a807437cc723bcadc3791d37add5ceed566a2","modified":1628847216259},{"_id":"public/img/default.png","hash":"7bb2b8ee07db305bcadee2985b81b942027ae940","modified":1628847216259},{"_id":"public/img/meicon.png","hash":"9232364c346db7d635804d69e1e2d5ecda6007f3","modified":1628847216259},{"_id":"public/img/bg/9884183b3b1e1b50e1d68c69d97b38d6_4.jpg","hash":"a0159bcf7c7ab5b2cbe2e4fdb7307b7ac8e0d061","modified":1628847216259},{"_id":"public/live2dw/lib/L2Dwidget.min.js.map","hash":"3290fe2df45f065b51a1cd7b24ec325cbf9bb5ce","modified":1628847216259},{"_id":"public/img/meiconbali.jpg","hash":"251240f4833515e6df48cdec4b17f4c0313c0784","modified":1628847216259},{"_id":"public/img/bg/36e6c0d304d7a672d6d828e164f2c48b_1.jpg","hash":"ca1ad49f059e26019a7df2904a7bc22a5b10d09c","modified":1628847216259},{"_id":"public/img/bg/7fb86b41c8bb0d7bff7a3142c83d8348_1.jpg","hash":"084e16156fa67e0d090663ed15ad64b2104a67a6","modified":1628847216259},{"_id":"public/live2dw/assets/moc/tororo.moc","hash":"44289e62545a7046e0f5231103a851750b78524e","modified":1628847216259},{"_id":"public/live2dw/lib/L2Dwidget.0.min.js","hash":"35bb5b588b6de25c9be2dd51d3fd331feafac02d","modified":1628847216259},{"_id":"public/css/gitalk.css","hash":"a57b3cc8e04a0a4a27aefa07facf5b5e7bca0e76","modified":1628847216259},{"_id":"public/js/boot.js","hash":"3de344ee619da989f6dccf7c2ae459fe91075983","modified":1628847216259},{"_id":"public/js/color-schema.js","hash":"cc712fc71bf33d561e1ba74fe1d52d2353092171","modified":1628847216259},{"_id":"public/js/events.js","hash":"4b9d2676c9544db9cc40a8c7d18456792299ba86","modified":1628847216259},{"_id":"public/js/img-lazyload.js","hash":"cbdeca434ec4da51f488c821d51b4d23c73294af","modified":1628847216259},{"_id":"public/js/leancloud.js","hash":"b7985ac3cff9ee2722db43ee6b32b5484c43f5f2","modified":1628847216259},{"_id":"public/js/local-search.js","hash":"bf00f5786bb8de7241f635455b67243d26656222","modified":1628847216259},{"_id":"public/js/plugins.js","hash":"342b1fbc30d1465687ce389a4e07f967266d5d86","modified":1628847216259},{"_id":"public/js/utils.js","hash":"9d492fab9c26311ad0ab553c890e09b9575a76f2","modified":1628847216259},{"_id":"public/lib/hint/hint.min.css","hash":"b38df228460ebfb4c0b6085336ee2878fe85aafe","modified":1628847216259},{"_id":"public/css/main.css","hash":"bf7b61acb0f60f43cf343fed01575b3ce40b2138","modified":1628847216259},{"_id":"public/img/bg/7cc417b7ace4b99c19d3034179926555_3.jpg","hash":"36304bc7d6ed3f6d8a9330d843c92d105c506f28","modified":1628847216259},{"_id":"public/img/bg/c65f7b13787572d4f5d33f66d627df71_2.jpg","hash":"ce37c68377e3d277d432507ec33e4d02c458d569","modified":1628847216259},{"_id":"public/img/bg/b7fb479d6dbb4525a0393f9934aceab3_1.jpg","hash":"e5ba3a056b042b7411776311840140e17a51529c","modified":1628847216259},{"_id":"public/img/bg/e7050bc333ebfc01afce3b434f95e7b0_2.jpg","hash":"b56be4c6838c5b1e98c50468b5efab86c006cdb0","modified":1628847216259},{"_id":"public/live2dw/assets/moc/tororo.2048/texture_00.png","hash":"98af764b541083e87fc2f8e85f02d2db38c898cc","modified":1628847216259},{"_id":"public/img/bg/bd643dc0ad68f830b3a0eeae50ceba5f_4.jpg","hash":"2b0eb78d531d1aa4ea559d18efc9068deda95d20","modified":1628847216259},{"_id":"public/img/bg/4cb90122eb95819122b32d17e238ee1b_1.jpg","hash":"7df7f85fa28588cd468bb4ccc46d788be62f468d","modified":1628847216259},{"_id":"public/img/bg/5afd5a558c69261be00db0024ce0ccdf_1.jpg","hash":"9f21bac1d0ae6664b50b799880d7f6ffb16b0ac4","modified":1628847216259},{"_id":"public/img/bg/c989b7d72a5a30f48a3544a7cec9562b_1.jpg","hash":"3de36db1282675551f69ffe9c4932800a712b4ee","modified":1628847216259},{"_id":"public/img/bg/a9564f5c58411c94f3d83feeb0647643_1.jpg","hash":"2909b72df883e07a59e4d77f783dfbb7adce0774","modified":1628847216259},{"_id":"public/live2dw/lib/L2Dwidget.0.min.js.map","hash":"35e71cc2a130199efb167b9a06939576602f0d75","modified":1628847216259},{"_id":"public/img/bg/03990bbe091d5cca73421ac40bacfc46_1.jpg","hash":"79cb7b38f7f28ccdc9cdb8fa498fbf772036ba2c","modified":1628847216259},{"_id":"public/img/bg/b4f8a6143ef84a1ef177b4bde3f8d805_1.jpg","hash":"c431e3f86fd73aa25221d1dc7001a9caee5b6e16","modified":1628847216259},{"_id":"public/img/bg/wm2.mp4","hash":"b6fdb4962f2efe2ba593c786af557ab04e01942a","modified":1628847216259},{"_id":"public/img/bg/a8d2b7b118107c8a8446ca81691d20ee_1.jpg","hash":"8a53d60923c984efe760eeadfed04d468a7b04e9","modified":1628847216259},{"_id":"public/img/bg/girl.png","hash":"bb2aa45e869a12640a9c38f54dbc0fab32b9e692","modified":1628847216259},{"_id":"public/img/bg/wm10.mp4","hash":"b870f16f79786e1fd956bef8b14e1e3659356025","modified":1628847216259},{"_id":"public/img/bg/wm1.mp4","hash":"b5ff1c5af1be3edba17807f0c75540a078eff6af","modified":1628847216259},{"_id":"public/img/bg/wm9.mp4","hash":"7333f9649921c5e94c6e081939bd7cda1dec6964","modified":1628847216259},{"_id":"public/img/bg/wm11.mp4","hash":"d4bde698732e28c122f421e604be1654796a7034","modified":1628847216259}],"Category":[{"name":"文献","_id":"cksa5ksek0004a0x44uoe7ta5"},{"name":"深度学习","_id":"cksa5ksep000ca0x47so09han"},{"name":"docker","_id":"cksa5ksev000oa0x42pw950jz"},{"name":"dvc","_id":"cksa5ksf0000za0x43yw86jlg"},{"name":"配置","_id":"cksa5ksf20016a0x41tixf2m8"},{"name":"git","_id":"cksa5ksf4001ca0x48qe954qh"},{"name":"剑指","_id":"cksa5ksf5001fa0x41irvcs3k"},{"name":"math","_id":"cksa5ksf90021a0x41n4i8jki"},{"name":"hexo","parent":"cksa5ksf20016a0x41tixf2m8","_id":"cksa5ksfb002ca0x44dmw7jsa"},{"name":"线性代数","parent":"cksa5ksf90021a0x41n4i8jki","_id":"cksa5ksfb002ga0x49jeo7noc"},{"name":"概率论","parent":"cksa5ksf90021a0x41n4i8jki","_id":"cksa5ksfc002ja0x46nxg0ux6"}],"Data":[{"_id":"friends","data":[{"avatar":"http://image.luokangyuan.com/1_qq_27922023.jpg","name":"码酱","introduction":"我不是大佬，只是在追寻大佬的脚步","url":"http://luokangyuan.com/","title":"前去学习"},{"avatar":"http://image.luokangyuan.com/4027734.jpeg","name":"闪烁之狐","introduction":"编程界大佬，技术牛，人还特别好，不懂的都可以请教大佬","url":"https://blinkfox.github.io/","title":"前去学习"},{"avatar":"http://image.luokangyuan.com/avatar.jpg","name":"ja_rome","introduction":"平凡的脚步也可以走出伟大的行程","url":"https://me.csdn.net/jlh912008548","title":"前去学习"}]}],"Page":[{"title":"404","date":"2021-08-04T07:56:32.000Z","type":"404","layout":"404","description":"Oops～，我崩溃了！找不到你想要的页面 :(","_content":"","source":"404/index.md","raw":"---\ntitle: 404\ndate: 2021-08-04 15:56:32\ntype: \"404\"\nlayout: \"404\"\ndescription: \"Oops～，我崩溃了！找不到你想要的页面 :(\"\n---\n","updated":"2021-08-04T07:57:08.058Z","path":"404/index.html","comments":1,"_id":"cksa5ksef0000a0x4agp54lvn","content":"","site":{"data":{"friends":[{"avatar":"http://image.luokangyuan.com/1_qq_27922023.jpg","name":"码酱","introduction":"我不是大佬，只是在追寻大佬的脚步","url":"http://luokangyuan.com/","title":"前去学习"},{"avatar":"http://image.luokangyuan.com/4027734.jpeg","name":"闪烁之狐","introduction":"编程界大佬，技术牛，人还特别好，不懂的都可以请教大佬","url":"https://blinkfox.github.io/","title":"前去学习"},{"avatar":"http://image.luokangyuan.com/avatar.jpg","name":"ja_rome","introduction":"平凡的脚步也可以走出伟大的行程","url":"https://me.csdn.net/jlh912008548","title":"前去学习"}]}},"excerpt":"","more":""},{"title":"小站自述","date":"2021-08-03T11:39:55.000Z","type":"about","layout":"about","_content":"","source":"about/index.md","raw":"---\ntitle: 小站自述\ndate: 2021-08-03 19:39:55\ntype: \"about\"\nlayout: \"about\"\n---\n","updated":"2021-08-04T07:51:34.459Z","path":"about/index.html","comments":1,"_id":"cksa5ksei0002a0x4b8635af8","content":"","site":{"data":{"friends":[{"avatar":"http://image.luokangyuan.com/1_qq_27922023.jpg","name":"码酱","introduction":"我不是大佬，只是在追寻大佬的脚步","url":"http://luokangyuan.com/","title":"前去学习"},{"avatar":"http://image.luokangyuan.com/4027734.jpeg","name":"闪烁之狐","introduction":"编程界大佬，技术牛，人还特别好，不懂的都可以请教大佬","url":"https://blinkfox.github.io/","title":"前去学习"},{"avatar":"http://image.luokangyuan.com/avatar.jpg","name":"ja_rome","introduction":"平凡的脚步也可以走出伟大的行程","url":"https://me.csdn.net/jlh912008548","title":"前去学习"}]}},"excerpt":"","more":""},{"title":"文章类别","date":"2021-08-03T11:38:47.000Z","type":"categories","layout":"categories","_content":"","source":"categories/index.md","raw":"---\ntitle: 文章类别\ndate: 2021-08-03 19:38:47\ntype: \"categories\"\nlayout: \"categories\"\n---\n","updated":"2021-08-04T07:51:06.721Z","path":"categories/index.html","comments":1,"_id":"cksa5ksel0006a0x4d9qk670f","content":"","site":{"data":{"friends":[{"avatar":"http://image.luokangyuan.com/1_qq_27922023.jpg","name":"码酱","introduction":"我不是大佬，只是在追寻大佬的脚步","url":"http://luokangyuan.com/","title":"前去学习"},{"avatar":"http://image.luokangyuan.com/4027734.jpeg","name":"闪烁之狐","introduction":"编程界大佬，技术牛，人还特别好，不懂的都可以请教大佬","url":"https://blinkfox.github.io/","title":"前去学习"},{"avatar":"http://image.luokangyuan.com/avatar.jpg","name":"ja_rome","introduction":"平凡的脚步也可以走出伟大的行程","url":"https://me.csdn.net/jlh912008548","title":"前去学习"}]}},"excerpt":"","more":""},{"title":"contact","date":"2021-08-04T07:52:31.000Z","type":"contact","layout":"contact","_content":"","source":"contact/index.md","raw":"---\ntitle: contact\ndate: 2021-08-04 15:52:31\ntype: \"contact\"\nlayout: \"contact\"\n---\n","updated":"2021-08-04T07:53:12.028Z","path":"contact/index.html","comments":1,"_id":"cksa5ksen0008a0x415538o5j","content":"","site":{"data":{"friends":[{"avatar":"http://image.luokangyuan.com/1_qq_27922023.jpg","name":"码酱","introduction":"我不是大佬，只是在追寻大佬的脚步","url":"http://luokangyuan.com/","title":"前去学习"},{"avatar":"http://image.luokangyuan.com/4027734.jpeg","name":"闪烁之狐","introduction":"编程界大佬，技术牛，人还特别好，不懂的都可以请教大佬","url":"https://blinkfox.github.io/","title":"前去学习"},{"avatar":"http://image.luokangyuan.com/avatar.jpg","name":"ja_rome","introduction":"平凡的脚步也可以走出伟大的行程","url":"https://me.csdn.net/jlh912008548","title":"前去学习"}]}},"excerpt":"","more":""},{"title":"article","date":"2021-08-03T11:33:47.000Z","type":"tags","layout":"tags","_content":"\n","source":"tags/index.md","raw":"---\ntitle: article\ndate: 2021-08-03 19:33:47\ntype: \"tags\"\nlayout: \"tags\"\n---\n\n","updated":"2021-08-03T12:48:36.046Z","path":"tags/index.html","comments":1,"_id":"cksa5kseo000aa0x4gfwkcsgq","content":"","site":{"data":{"friends":[{"avatar":"http://image.luokangyuan.com/1_qq_27922023.jpg","name":"码酱","introduction":"我不是大佬，只是在追寻大佬的脚步","url":"http://luokangyuan.com/","title":"前去学习"},{"avatar":"http://image.luokangyuan.com/4027734.jpeg","name":"闪烁之狐","introduction":"编程界大佬，技术牛，人还特别好，不懂的都可以请教大佬","url":"https://blinkfox.github.io/","title":"前去学习"},{"avatar":"http://image.luokangyuan.com/avatar.jpg","name":"ja_rome","introduction":"平凡的脚步也可以走出伟大的行程","url":"https://me.csdn.net/jlh912008548","title":"前去学习"}]}},"excerpt":"","more":""},{"title":"friends","date":"2021-08-04T07:59:30.000Z","type":"friends","layout":"friends","_content":"\n","source":"friends/index.md","raw":"---\ntitle: friends\ndate: 2021-08-04 15:59:30\ntype: \"friends\"\nlayout: \"friends\"\n---\n\n","updated":"2021-08-04T07:59:47.355Z","path":"friends/index.html","comments":1,"_id":"cksa5ksep000fa0x40tl25nko","content":"","site":{"data":{"friends":[{"avatar":"http://image.luokangyuan.com/1_qq_27922023.jpg","name":"码酱","introduction":"我不是大佬，只是在追寻大佬的脚步","url":"http://luokangyuan.com/","title":"前去学习"},{"avatar":"http://image.luokangyuan.com/4027734.jpeg","name":"闪烁之狐","introduction":"编程界大佬，技术牛，人还特别好，不懂的都可以请教大佬","url":"https://blinkfox.github.io/","title":"前去学习"},{"avatar":"http://image.luokangyuan.com/avatar.jpg","name":"ja_rome","introduction":"平凡的脚步也可以走出伟大的行程","url":"https://me.csdn.net/jlh912008548","title":"前去学习"}]}},"excerpt":"","more":""}],"Post":[{"title":"文献整理笔记","date":"2021-08-13T07:18:31.000Z","_content":"> 查找文献的网站\n> https://www.thecvf.com/\n> https://arxiv.org/list/cs/recent\n\n###  微调技巧\n\n[**Accurate, Large Minibatch SGD Training ImageNet in 1 Hour.pdf**](http://qxrol67de.hn-bkt.clouddn.com/Accurate%2C%20Large%20Minibatch%20SGD%20Training%20ImageNet%20in%201%20Hour.pdf?e=1628844027&token=XOjUoKvaLFMqS1LkRGv-hKeP9QfGCl4I7Lq18FO5:MibpfCuStpYUbfD8qs8aMC3U2y0=)\n[**BIT : General Visual Representation Learning.pdf**](http://qxrol67de.hn-bkt.clouddn.com/BITGeneral%20Visual%20Representation%20Learning.pdf?e=1628844027&token=XOjUoKvaLFMqS1LkRGv-hKeP9QfGCl4I7Lq18FO5:m9ZxInQumMS8DO8NwtI9HvuyxCY=)\n[**Co-Tuning for Transfer Learning.pdf**](http://qxrol67de.hn-bkt.clouddn.com/Co-Tuning%20for%20Transfer%20Learning.pdf?e=1628844027&token=XOjUoKvaLFMqS1LkRGv-hKeP9QfGCl4I7Lq18FO5:zKqFz-uPhbE5o_oUWYs8uAT9aXc=)\n[**EfficientNet Rethinking Model Scaling for Convolutional Neural Networks.pdf**](http://qxrol67de.hn-bkt.clouddn.com/EfficientNet%20Rethinking%20Model%20Scaling%20for%20Convolutional%20Neural%20Networks.pdf?e=1628844027&token=XOjUoKvaLFMqS1LkRGv-hKeP9QfGCl4I7Lq18FO5:K_nkiBpr-4L07Xa_VRoN4xsRNU4=)\n[**He_Bag_of_Tricks_for_Image_Classification_with_Convolutional_Neural_Networks_CVPR_2019_paper.pdf**](http://qxrol67de.hn-bkt.clouddn.com/He_Bag_of_Tricks_for_Image_Classification_with_Convolutional_Neural_Networks_CVPR_2019_paper.pdf?e=1628844027&token=XOjUoKvaLFMqS1LkRGv-hKeP9QfGCl4I7Lq18FO5:38vBt7XcdylOUC5C_pFcevVpXas=)\n[**Simple Copy-Paste is a Strong Data Augmentation Method.pdf**](http://qxrol67de.hn-bkt.clouddn.com/Simple%20Copy-Paste%20is%20a%20Strong%20Data%20Augmentation%20Method.pdf?e=1628844027&token=XOjUoKvaLFMqS1LkRGv-hKeP9QfGCl4I7Lq18FO5:NRT0zKN1hdhwyUU8KzKb6aGBC1M=)\n[**Discriminative Feature Alignment Improving Transferability of.pdf**](http://qxrol67de.hn-bkt.clouddn.com/Discriminative%20Feature%20Alignment%20Improving%20Transferability%20of.pdf?e=1628844027&token=XOjUoKvaLFMqS1LkRGv-hKeP9QfGCl4I7Lq18FO5:mU7vMQVsm3DEXt7QHTqtzDNaogg=)\n[**Movement Pruning adaptive sparsity by fine-tuning.pdf**](http://qxrol67de.hn-bkt.clouddn.com/Movement%20Pruning%20adaptive%20sparsity%20by%20fine-tuning.pdf?e=1628844027&token=XOjUoKvaLFMqS1LkRGv-hKeP9QfGCl4I7Lq18FO5:UFJJB_PWAAbWqCS7RZUwswuBNTM=)\n\n### Transformer\n\n[**Attention Is All You Need**](http://qxrol67de.hn-bkt.clouddn.com/attention%20is%20all%20you%20need1706.03762.pdf?e=1628844027&token=XOjUoKvaLFMqS1LkRGv-hKeP9QfGCl4I7Lq18FO5:2eZzguYiYMcXj1n-OLDZwUFwGYU=) (讲解Attention机制)\n\n [**AN IMAGE IS WORTH 16X16 WORDS: TRANSFORMERS FOR IMAGE RECOGNITION AT**](http://qxrol67de.hn-bkt.clouddn.com/AN%20IMAGE%20IS%20WORTH%2016X16%20WORDS.pdf?e=1628844027&token=XOjUoKvaLFMqS1LkRGv-hKeP9QfGCl4I7Lq18FO5:NUSVTIvWzrJf2Zv031E5YW2RlFA=)（将transformer应用于图像分类）\n\n[**A Survey of Transformers**](http://qxrol67de.hn-bkt.clouddn.com/transformer%20%E6%80%BB%E7%BB%93.pdf?e=1628844027&token=XOjUoKvaLFMqS1LkRGv-hKeP9QfGCl4I7Lq18FO5:WSUaru3yoQne8yY-qSfnsfNChL4=)（Transformer的总结）\n\n","source":"_posts/page-site.md","raw":"---\ntitle: 文献整理笔记\ntags: [文献]\ncategories: [文献]\ndate: 2021-08-13 15:18:31\n---\n> 查找文献的网站\n> https://www.thecvf.com/\n> https://arxiv.org/list/cs/recent\n\n###  微调技巧\n\n[**Accurate, Large Minibatch SGD Training ImageNet in 1 Hour.pdf**](http://qxrol67de.hn-bkt.clouddn.com/Accurate%2C%20Large%20Minibatch%20SGD%20Training%20ImageNet%20in%201%20Hour.pdf?e=1628844027&token=XOjUoKvaLFMqS1LkRGv-hKeP9QfGCl4I7Lq18FO5:MibpfCuStpYUbfD8qs8aMC3U2y0=)\n[**BIT : General Visual Representation Learning.pdf**](http://qxrol67de.hn-bkt.clouddn.com/BITGeneral%20Visual%20Representation%20Learning.pdf?e=1628844027&token=XOjUoKvaLFMqS1LkRGv-hKeP9QfGCl4I7Lq18FO5:m9ZxInQumMS8DO8NwtI9HvuyxCY=)\n[**Co-Tuning for Transfer Learning.pdf**](http://qxrol67de.hn-bkt.clouddn.com/Co-Tuning%20for%20Transfer%20Learning.pdf?e=1628844027&token=XOjUoKvaLFMqS1LkRGv-hKeP9QfGCl4I7Lq18FO5:zKqFz-uPhbE5o_oUWYs8uAT9aXc=)\n[**EfficientNet Rethinking Model Scaling for Convolutional Neural Networks.pdf**](http://qxrol67de.hn-bkt.clouddn.com/EfficientNet%20Rethinking%20Model%20Scaling%20for%20Convolutional%20Neural%20Networks.pdf?e=1628844027&token=XOjUoKvaLFMqS1LkRGv-hKeP9QfGCl4I7Lq18FO5:K_nkiBpr-4L07Xa_VRoN4xsRNU4=)\n[**He_Bag_of_Tricks_for_Image_Classification_with_Convolutional_Neural_Networks_CVPR_2019_paper.pdf**](http://qxrol67de.hn-bkt.clouddn.com/He_Bag_of_Tricks_for_Image_Classification_with_Convolutional_Neural_Networks_CVPR_2019_paper.pdf?e=1628844027&token=XOjUoKvaLFMqS1LkRGv-hKeP9QfGCl4I7Lq18FO5:38vBt7XcdylOUC5C_pFcevVpXas=)\n[**Simple Copy-Paste is a Strong Data Augmentation Method.pdf**](http://qxrol67de.hn-bkt.clouddn.com/Simple%20Copy-Paste%20is%20a%20Strong%20Data%20Augmentation%20Method.pdf?e=1628844027&token=XOjUoKvaLFMqS1LkRGv-hKeP9QfGCl4I7Lq18FO5:NRT0zKN1hdhwyUU8KzKb6aGBC1M=)\n[**Discriminative Feature Alignment Improving Transferability of.pdf**](http://qxrol67de.hn-bkt.clouddn.com/Discriminative%20Feature%20Alignment%20Improving%20Transferability%20of.pdf?e=1628844027&token=XOjUoKvaLFMqS1LkRGv-hKeP9QfGCl4I7Lq18FO5:mU7vMQVsm3DEXt7QHTqtzDNaogg=)\n[**Movement Pruning adaptive sparsity by fine-tuning.pdf**](http://qxrol67de.hn-bkt.clouddn.com/Movement%20Pruning%20adaptive%20sparsity%20by%20fine-tuning.pdf?e=1628844027&token=XOjUoKvaLFMqS1LkRGv-hKeP9QfGCl4I7Lq18FO5:UFJJB_PWAAbWqCS7RZUwswuBNTM=)\n\n### Transformer\n\n[**Attention Is All You Need**](http://qxrol67de.hn-bkt.clouddn.com/attention%20is%20all%20you%20need1706.03762.pdf?e=1628844027&token=XOjUoKvaLFMqS1LkRGv-hKeP9QfGCl4I7Lq18FO5:2eZzguYiYMcXj1n-OLDZwUFwGYU=) (讲解Attention机制)\n\n [**AN IMAGE IS WORTH 16X16 WORDS: TRANSFORMERS FOR IMAGE RECOGNITION AT**](http://qxrol67de.hn-bkt.clouddn.com/AN%20IMAGE%20IS%20WORTH%2016X16%20WORDS.pdf?e=1628844027&token=XOjUoKvaLFMqS1LkRGv-hKeP9QfGCl4I7Lq18FO5:NUSVTIvWzrJf2Zv031E5YW2RlFA=)（将transformer应用于图像分类）\n\n[**A Survey of Transformers**](http://qxrol67de.hn-bkt.clouddn.com/transformer%20%E6%80%BB%E7%BB%93.pdf?e=1628844027&token=XOjUoKvaLFMqS1LkRGv-hKeP9QfGCl4I7Lq18FO5:WSUaru3yoQne8yY-qSfnsfNChL4=)（Transformer的总结）\n\n","slug":"page-site","published":1,"updated":"2021-08-13T08:03:00.856Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cksa5kseg0001a0x4ea7vc6s3","content":"<blockquote>\n<p>查找文献的网站<br><a href=\"https://www.thecvf.com/\">https://www.thecvf.com/</a><br><a href=\"https://arxiv.org/list/cs/recent\">https://arxiv.org/list/cs/recent</a></p>\n</blockquote>\n<h3 id=\"微调技巧\"><a href=\"#微调技巧\" class=\"headerlink\" title=\"微调技巧\"></a>微调技巧</h3><p><a href=\"http://qxrol67de.hn-bkt.clouddn.com/Accurate%2C%20Large%20Minibatch%20SGD%20Training%20ImageNet%20in%201%20Hour.pdf?e=1628844027&amp;token=XOjUoKvaLFMqS1LkRGv-hKeP9QfGCl4I7Lq18FO5:MibpfCuStpYUbfD8qs8aMC3U2y0=\"><strong>Accurate, Large Minibatch SGD Training ImageNet in 1 Hour.pdf</strong></a><br><a href=\"http://qxrol67de.hn-bkt.clouddn.com/BITGeneral%20Visual%20Representation%20Learning.pdf?e=1628844027&amp;token=XOjUoKvaLFMqS1LkRGv-hKeP9QfGCl4I7Lq18FO5:m9ZxInQumMS8DO8NwtI9HvuyxCY=\"><strong>BIT : General Visual Representation Learning.pdf</strong></a><br><a href=\"http://qxrol67de.hn-bkt.clouddn.com/Co-Tuning%20for%20Transfer%20Learning.pdf?e=1628844027&amp;token=XOjUoKvaLFMqS1LkRGv-hKeP9QfGCl4I7Lq18FO5:zKqFz-uPhbE5o_oUWYs8uAT9aXc=\"><strong>Co-Tuning for Transfer Learning.pdf</strong></a><br><a href=\"http://qxrol67de.hn-bkt.clouddn.com/EfficientNet%20Rethinking%20Model%20Scaling%20for%20Convolutional%20Neural%20Networks.pdf?e=1628844027&amp;token=XOjUoKvaLFMqS1LkRGv-hKeP9QfGCl4I7Lq18FO5:K_nkiBpr-4L07Xa_VRoN4xsRNU4=\"><strong>EfficientNet Rethinking Model Scaling for Convolutional Neural Networks.pdf</strong></a><br><a href=\"http://qxrol67de.hn-bkt.clouddn.com/He_Bag_of_Tricks_for_Image_Classification_with_Convolutional_Neural_Networks_CVPR_2019_paper.pdf?e=1628844027&amp;token=XOjUoKvaLFMqS1LkRGv-hKeP9QfGCl4I7Lq18FO5:38vBt7XcdylOUC5C_pFcevVpXas=\"><strong>He_Bag_of_Tricks_for_Image_Classification_with_Convolutional_Neural_Networks_CVPR_2019_paper.pdf</strong></a><br><a href=\"http://qxrol67de.hn-bkt.clouddn.com/Simple%20Copy-Paste%20is%20a%20Strong%20Data%20Augmentation%20Method.pdf?e=1628844027&amp;token=XOjUoKvaLFMqS1LkRGv-hKeP9QfGCl4I7Lq18FO5:NRT0zKN1hdhwyUU8KzKb6aGBC1M=\"><strong>Simple Copy-Paste is a Strong Data Augmentation Method.pdf</strong></a><br><a href=\"http://qxrol67de.hn-bkt.clouddn.com/Discriminative%20Feature%20Alignment%20Improving%20Transferability%20of.pdf?e=1628844027&amp;token=XOjUoKvaLFMqS1LkRGv-hKeP9QfGCl4I7Lq18FO5:mU7vMQVsm3DEXt7QHTqtzDNaogg=\"><strong>Discriminative Feature Alignment Improving Transferability of.pdf</strong></a><br><a href=\"http://qxrol67de.hn-bkt.clouddn.com/Movement%20Pruning%20adaptive%20sparsity%20by%20fine-tuning.pdf?e=1628844027&amp;token=XOjUoKvaLFMqS1LkRGv-hKeP9QfGCl4I7Lq18FO5:UFJJB_PWAAbWqCS7RZUwswuBNTM=\"><strong>Movement Pruning adaptive sparsity by fine-tuning.pdf</strong></a></p>\n<h3 id=\"Transformer\"><a href=\"#Transformer\" class=\"headerlink\" title=\"Transformer\"></a>Transformer</h3><p><a href=\"http://qxrol67de.hn-bkt.clouddn.com/attention%20is%20all%20you%20need1706.03762.pdf?e=1628844027&amp;token=XOjUoKvaLFMqS1LkRGv-hKeP9QfGCl4I7Lq18FO5:2eZzguYiYMcXj1n-OLDZwUFwGYU=\"><strong>Attention Is All You Need</strong></a> (讲解Attention机制)</p>\n<p> <a href=\"http://qxrol67de.hn-bkt.clouddn.com/AN%20IMAGE%20IS%20WORTH%2016X16%20WORDS.pdf?e=1628844027&amp;token=XOjUoKvaLFMqS1LkRGv-hKeP9QfGCl4I7Lq18FO5:NUSVTIvWzrJf2Zv031E5YW2RlFA=\"><strong>AN IMAGE IS WORTH 16X16 WORDS: TRANSFORMERS FOR IMAGE RECOGNITION AT</strong></a>（将transformer应用于图像分类）</p>\n<p><a href=\"http://qxrol67de.hn-bkt.clouddn.com/transformer%20%E6%80%BB%E7%BB%93.pdf?e=1628844027&amp;token=XOjUoKvaLFMqS1LkRGv-hKeP9QfGCl4I7Lq18FO5:WSUaru3yoQne8yY-qSfnsfNChL4=\"><strong>A Survey of Transformers</strong></a>（Transformer的总结）</p>\n","site":{"data":{"friends":[{"avatar":"http://image.luokangyuan.com/1_qq_27922023.jpg","name":"码酱","introduction":"我不是大佬，只是在追寻大佬的脚步","url":"http://luokangyuan.com/","title":"前去学习"},{"avatar":"http://image.luokangyuan.com/4027734.jpeg","name":"闪烁之狐","introduction":"编程界大佬，技术牛，人还特别好，不懂的都可以请教大佬","url":"https://blinkfox.github.io/","title":"前去学习"},{"avatar":"http://image.luokangyuan.com/avatar.jpg","name":"ja_rome","introduction":"平凡的脚步也可以走出伟大的行程","url":"https://me.csdn.net/jlh912008548","title":"前去学习"}]}},"excerpt":"","more":"<blockquote>\n<p>查找文献的网站<br><a href=\"https://www.thecvf.com/\">https://www.thecvf.com/</a><br><a href=\"https://arxiv.org/list/cs/recent\">https://arxiv.org/list/cs/recent</a></p>\n</blockquote>\n<h3 id=\"微调技巧\"><a href=\"#微调技巧\" class=\"headerlink\" title=\"微调技巧\"></a>微调技巧</h3><p><a href=\"http://qxrol67de.hn-bkt.clouddn.com/Accurate%2C%20Large%20Minibatch%20SGD%20Training%20ImageNet%20in%201%20Hour.pdf?e=1628844027&token=XOjUoKvaLFMqS1LkRGv-hKeP9QfGCl4I7Lq18FO5:MibpfCuStpYUbfD8qs8aMC3U2y0=\"><strong>Accurate, Large Minibatch SGD Training ImageNet in 1 Hour.pdf</strong></a><br><a href=\"http://qxrol67de.hn-bkt.clouddn.com/BITGeneral%20Visual%20Representation%20Learning.pdf?e=1628844027&token=XOjUoKvaLFMqS1LkRGv-hKeP9QfGCl4I7Lq18FO5:m9ZxInQumMS8DO8NwtI9HvuyxCY=\"><strong>BIT : General Visual Representation Learning.pdf</strong></a><br><a href=\"http://qxrol67de.hn-bkt.clouddn.com/Co-Tuning%20for%20Transfer%20Learning.pdf?e=1628844027&token=XOjUoKvaLFMqS1LkRGv-hKeP9QfGCl4I7Lq18FO5:zKqFz-uPhbE5o_oUWYs8uAT9aXc=\"><strong>Co-Tuning for Transfer Learning.pdf</strong></a><br><a href=\"http://qxrol67de.hn-bkt.clouddn.com/EfficientNet%20Rethinking%20Model%20Scaling%20for%20Convolutional%20Neural%20Networks.pdf?e=1628844027&token=XOjUoKvaLFMqS1LkRGv-hKeP9QfGCl4I7Lq18FO5:K_nkiBpr-4L07Xa_VRoN4xsRNU4=\"><strong>EfficientNet Rethinking Model Scaling for Convolutional Neural Networks.pdf</strong></a><br><a href=\"http://qxrol67de.hn-bkt.clouddn.com/He_Bag_of_Tricks_for_Image_Classification_with_Convolutional_Neural_Networks_CVPR_2019_paper.pdf?e=1628844027&token=XOjUoKvaLFMqS1LkRGv-hKeP9QfGCl4I7Lq18FO5:38vBt7XcdylOUC5C_pFcevVpXas=\"><strong>He_Bag_of_Tricks_for_Image_Classification_with_Convolutional_Neural_Networks_CVPR_2019_paper.pdf</strong></a><br><a href=\"http://qxrol67de.hn-bkt.clouddn.com/Simple%20Copy-Paste%20is%20a%20Strong%20Data%20Augmentation%20Method.pdf?e=1628844027&token=XOjUoKvaLFMqS1LkRGv-hKeP9QfGCl4I7Lq18FO5:NRT0zKN1hdhwyUU8KzKb6aGBC1M=\"><strong>Simple Copy-Paste is a Strong Data Augmentation Method.pdf</strong></a><br><a href=\"http://qxrol67de.hn-bkt.clouddn.com/Discriminative%20Feature%20Alignment%20Improving%20Transferability%20of.pdf?e=1628844027&token=XOjUoKvaLFMqS1LkRGv-hKeP9QfGCl4I7Lq18FO5:mU7vMQVsm3DEXt7QHTqtzDNaogg=\"><strong>Discriminative Feature Alignment Improving Transferability of.pdf</strong></a><br><a href=\"http://qxrol67de.hn-bkt.clouddn.com/Movement%20Pruning%20adaptive%20sparsity%20by%20fine-tuning.pdf?e=1628844027&token=XOjUoKvaLFMqS1LkRGv-hKeP9QfGCl4I7Lq18FO5:UFJJB_PWAAbWqCS7RZUwswuBNTM=\"><strong>Movement Pruning adaptive sparsity by fine-tuning.pdf</strong></a></p>\n<h3 id=\"Transformer\"><a href=\"#Transformer\" class=\"headerlink\" title=\"Transformer\"></a>Transformer</h3><p><a href=\"http://qxrol67de.hn-bkt.clouddn.com/attention%20is%20all%20you%20need1706.03762.pdf?e=1628844027&token=XOjUoKvaLFMqS1LkRGv-hKeP9QfGCl4I7Lq18FO5:2eZzguYiYMcXj1n-OLDZwUFwGYU=\"><strong>Attention Is All You Need</strong></a> (讲解Attention机制)</p>\n<p> <a href=\"http://qxrol67de.hn-bkt.clouddn.com/AN%20IMAGE%20IS%20WORTH%2016X16%20WORDS.pdf?e=1628844027&token=XOjUoKvaLFMqS1LkRGv-hKeP9QfGCl4I7Lq18FO5:NUSVTIvWzrJf2Zv031E5YW2RlFA=\"><strong>AN IMAGE IS WORTH 16X16 WORDS: TRANSFORMERS FOR IMAGE RECOGNITION AT</strong></a>（将transformer应用于图像分类）</p>\n<p><a href=\"http://qxrol67de.hn-bkt.clouddn.com/transformer%20%E6%80%BB%E7%BB%93.pdf?e=1628844027&token=XOjUoKvaLFMqS1LkRGv-hKeP9QfGCl4I7Lq18FO5:WSUaru3yoQne8yY-qSfnsfNChL4=\"><strong>A Survey of Transformers</strong></a>（Transformer的总结）</p>\n"},{"title":"梯度裁剪","date":"2021-08-12T02:20:29.000Z","math":true,"_content":"\n>阅读代码 optimizer_config = dict(grad_clip=dict(max_norm=35, norm_type=2))，就此探究一下grap_clip。他的作用是梯度裁剪，为了防止梯度爆炸。其中max_norm是最大梯度阈值，norm_type是指定的范数类型。\n\n## 梯度爆炸\n\n梯度爆炸就是在梯度更新的时候偏导数很大，导致更新参数无法收敛到最值（总是跳到其他不好的地方）。\n\n$$\nw_1=w_1− \\alpha \\frac{∂J(w)}{∂w1} \n$$\n\n$$\nw_2=w_2− \\alpha \\frac{∂J(w)}{∂w2}\n$$\n\n![](https://img-blog.csdn.net/20180313201807699?watermark/2/text/Ly9ibG9nLmNzZG4ubmV0L2d1b2xpbmRvbmdnbGQ=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)\n\n这里介绍梯度裁剪（Gradient Clipping）的方法，对梯度进行裁剪，论文提出对梯度的L2范数进行裁剪，也就是所有参数偏导数的平方和再开方。\n\n$$\ng_1=\\frac{∂J(w)}{∂w1} \n$$\n\n$$\ng_2=\\frac{∂J(w)}{∂w2}\n$$\n\n设定裁剪阈值为 C = max_norm，$\\Vert g\\Vert_2= \\sqrt{g^2_1+g^2_2}$\n\n当$\\Vert g\\Vert_2$大于c时：\n\n$$\ng = \\frac{c}{\\Vert g \\Vert_2} \\cdot g\n$$\n当$\\Vert g\\Vert_2$小于等于C时：g不变。其中，$\\frac{c}{\\Vert g \\Vert_2}$是一个标量\n\n## 总结\n\n训练模型出现Loss值出现跳动，一直不收敛时，除了设小学习率之外，梯度裁剪也是一个好方法。\n\n然而效果不佳时，那这就跟学习率和梯度爆炸没啥关系了。因此，**学习率**的设定和**梯度裁剪**的阈值并不能提高模型的准确率\n","source":"_posts/deep_learning/gradient-clip.md","raw":"---\ntitle: 梯度裁剪\ntags: [深度学习，梯度]\ncategories: 深度学习\ndate: 2021-08-12 10:20:29\nmath: true\n---\n\n>阅读代码 optimizer_config = dict(grad_clip=dict(max_norm=35, norm_type=2))，就此探究一下grap_clip。他的作用是梯度裁剪，为了防止梯度爆炸。其中max_norm是最大梯度阈值，norm_type是指定的范数类型。\n\n## 梯度爆炸\n\n梯度爆炸就是在梯度更新的时候偏导数很大，导致更新参数无法收敛到最值（总是跳到其他不好的地方）。\n\n$$\nw_1=w_1− \\alpha \\frac{∂J(w)}{∂w1} \n$$\n\n$$\nw_2=w_2− \\alpha \\frac{∂J(w)}{∂w2}\n$$\n\n![](https://img-blog.csdn.net/20180313201807699?watermark/2/text/Ly9ibG9nLmNzZG4ubmV0L2d1b2xpbmRvbmdnbGQ=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)\n\n这里介绍梯度裁剪（Gradient Clipping）的方法，对梯度进行裁剪，论文提出对梯度的L2范数进行裁剪，也就是所有参数偏导数的平方和再开方。\n\n$$\ng_1=\\frac{∂J(w)}{∂w1} \n$$\n\n$$\ng_2=\\frac{∂J(w)}{∂w2}\n$$\n\n设定裁剪阈值为 C = max_norm，$\\Vert g\\Vert_2= \\sqrt{g^2_1+g^2_2}$\n\n当$\\Vert g\\Vert_2$大于c时：\n\n$$\ng = \\frac{c}{\\Vert g \\Vert_2} \\cdot g\n$$\n当$\\Vert g\\Vert_2$小于等于C时：g不变。其中，$\\frac{c}{\\Vert g \\Vert_2}$是一个标量\n\n## 总结\n\n训练模型出现Loss值出现跳动，一直不收敛时，除了设小学习率之外，梯度裁剪也是一个好方法。\n\n然而效果不佳时，那这就跟学习率和梯度爆炸没啥关系了。因此，**学习率**的设定和**梯度裁剪**的阈值并不能提高模型的准确率\n","slug":"deep_learning/gradient-clip","published":1,"updated":"2021-08-13T01:30:37.872Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cksa5ksej0003a0x42r6jb0qq","content":"<blockquote>\n<p>阅读代码 optimizer_config = dict(grad_clip=dict(max_norm=35, norm_type=2))，就此探究一下grap_clip。他的作用是梯度裁剪，为了防止梯度爆炸。其中max_norm是最大梯度阈值，norm_type是指定的范数类型。</p>\n</blockquote>\n<h2 id=\"梯度爆炸\"><a href=\"#梯度爆炸\" class=\"headerlink\" title=\"梯度爆炸\"></a>梯度爆炸</h2><p>梯度爆炸就是在梯度更新的时候偏导数很大，导致更新参数无法收敛到最值（总是跳到其他不好的地方）。</p>\n<p>$$<br>w_1=w_1− \\alpha \\frac{∂J(w)}{∂w1}<br>$$</p>\n<p>$$<br>w_2=w_2− \\alpha \\frac{∂J(w)}{∂w2}<br>$$</p>\n<p><img src=\"https://img-blog.csdn.net/20180313201807699?watermark/2/text/Ly9ibG9nLmNzZG4ubmV0L2d1b2xpbmRvbmdnbGQ=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70\"></p>\n<p>这里介绍梯度裁剪（Gradient Clipping）的方法，对梯度进行裁剪，论文提出对梯度的L2范数进行裁剪，也就是所有参数偏导数的平方和再开方。</p>\n<p>$$<br>g_1=\\frac{∂J(w)}{∂w1}<br>$$</p>\n<p>$$<br>g_2=\\frac{∂J(w)}{∂w2}<br>$$</p>\n<p>设定裁剪阈值为 C = max_norm，$\\Vert g\\Vert_2= \\sqrt{g^2_1+g^2_2}$</p>\n<p>当$\\Vert g\\Vert_2$大于c时：</p>\n<p>$$<br>g = \\frac{c}{\\Vert g \\Vert_2} \\cdot g<br>$$<br>当$\\Vert g\\Vert_2$小于等于C时：g不变。其中，$\\frac{c}{\\Vert g \\Vert_2}$是一个标量</p>\n<h2 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h2><p>训练模型出现Loss值出现跳动，一直不收敛时，除了设小学习率之外，梯度裁剪也是一个好方法。</p>\n<p>然而效果不佳时，那这就跟学习率和梯度爆炸没啥关系了。因此，<strong>学习率</strong>的设定和<strong>梯度裁剪</strong>的阈值并不能提高模型的准确率</p>\n","site":{"data":{"friends":[{"avatar":"http://image.luokangyuan.com/1_qq_27922023.jpg","name":"码酱","introduction":"我不是大佬，只是在追寻大佬的脚步","url":"http://luokangyuan.com/","title":"前去学习"},{"avatar":"http://image.luokangyuan.com/4027734.jpeg","name":"闪烁之狐","introduction":"编程界大佬，技术牛，人还特别好，不懂的都可以请教大佬","url":"https://blinkfox.github.io/","title":"前去学习"},{"avatar":"http://image.luokangyuan.com/avatar.jpg","name":"ja_rome","introduction":"平凡的脚步也可以走出伟大的行程","url":"https://me.csdn.net/jlh912008548","title":"前去学习"}]}},"excerpt":"","more":"<blockquote>\n<p>阅读代码 optimizer_config = dict(grad_clip=dict(max_norm=35, norm_type=2))，就此探究一下grap_clip。他的作用是梯度裁剪，为了防止梯度爆炸。其中max_norm是最大梯度阈值，norm_type是指定的范数类型。</p>\n</blockquote>\n<h2 id=\"梯度爆炸\"><a href=\"#梯度爆炸\" class=\"headerlink\" title=\"梯度爆炸\"></a>梯度爆炸</h2><p>梯度爆炸就是在梯度更新的时候偏导数很大，导致更新参数无法收敛到最值（总是跳到其他不好的地方）。</p>\n<p>$$<br>w_1=w_1− \\alpha \\frac{∂J(w)}{∂w1}<br>$$</p>\n<p>$$<br>w_2=w_2− \\alpha \\frac{∂J(w)}{∂w2}<br>$$</p>\n<p><img src=\"https://img-blog.csdn.net/20180313201807699?watermark/2/text/Ly9ibG9nLmNzZG4ubmV0L2d1b2xpbmRvbmdnbGQ=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70\"></p>\n<p>这里介绍梯度裁剪（Gradient Clipping）的方法，对梯度进行裁剪，论文提出对梯度的L2范数进行裁剪，也就是所有参数偏导数的平方和再开方。</p>\n<p>$$<br>g_1=\\frac{∂J(w)}{∂w1}<br>$$</p>\n<p>$$<br>g_2=\\frac{∂J(w)}{∂w2}<br>$$</p>\n<p>设定裁剪阈值为 C = max_norm，$\\Vert g\\Vert_2= \\sqrt{g^2_1+g^2_2}$</p>\n<p>当$\\Vert g\\Vert_2$大于c时：</p>\n<p>$$<br>g = \\frac{c}{\\Vert g \\Vert_2} \\cdot g<br>$$<br>当$\\Vert g\\Vert_2$小于等于C时：g不变。其中，$\\frac{c}{\\Vert g \\Vert_2}$是一个标量</p>\n<h2 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h2><p>训练模型出现Loss值出现跳动，一直不收敛时，除了设小学习率之外，梯度裁剪也是一个好方法。</p>\n<p>然而效果不佳时，那这就跟学习率和梯度爆炸没啥关系了。因此，<strong>学习率</strong>的设定和<strong>梯度裁剪</strong>的阈值并不能提高模型的准确率</p>\n"},{"title":"fine-tuning的方法","date":"2021-08-13T06:28:24.000Z","_content":"\n>收集关于深度学习的调参的相关笔记，主要用于网络训练的微调。\n\n### **训练技巧**\n\n1.要做**梯度归一化**,即算出来的梯度除以minibatch size\n\n2.clip c(梯度裁剪): 限制最大梯度,其实是value = sqrt(w1^2 +w2^2….),如果value超过了阈值,就算一个衰减系数,让value的值等于阈值: 5,10,15\n\n##### **3.防止过拟合**\n\n​\t一般常用的防止过拟合方法有使用**L1正则项、L2正则项、dropout、提前终止、数据集扩充等**。如果模型在训练集上表现比较好但在测试集上表现欠佳可以选择增大L1或L2正则的惩罚力度（**L2正则经验上首选1.0**，超过10很少见），或**增大dropout的随机失活概率**（经验首选0.5）；或者当随着训练的持续在测试集上不增反降时，使用提前终止训练的方法。当然**最有效的还是增大训练集的规模**，实在难以获得新数据也可以使用数据集增强的方法，比如CV任务可以对数据集进行裁剪、翻转、平移等方法进行数据集增强，这种方法往往都会提高最后模型的测试精度。\n \tdropout对小数据防止过拟合有很好的效果,值一般设为0.5,小数据上dropout+sgd。在大部分实验中，效果提升都非常明显.**建议尝试**。 dropout的位置比较有讲究, 对于RNN,建议放到输入->RNN与RNN->输出的位置.关于RNN如何用dropout,可以参考:[http://arxiv.org/abs/1409.2329](https://link.zhihu.com/?target=http%3A//arxiv.org/abs/1409.2329)(Captain Jack令言:(不仅仅可以防止过拟合, 其实这相当于做人力成本最低的Ensemble, 当然, 训练起来会比没有Dropout的要慢一点, 同时网络参数你最好相应加一点, 对, 这会再慢一点).)\n\n**4.超参** \n\n​\tlearning rate 最重要**，推荐了解 cosine learning rate 和 cyclic learning rate，其次是 **batchsize 和 weight decay**。当你的模型还不错的时候，可以试着做数据增广和改损失函数锦上添花了。(罗浩ZJU令言：随着网络训练的进行，学习率要逐渐降下来；网络性能越好，学习率要越小（即越需要微调而非粗调)；batchsize通常影响没那么大，塞满卡就行，除了特殊的算法需要batch大一点)\n​\tadam,adadelta等,在小数据上,我这里实验的效果不如sgd, sgd收敛速度会慢一些，但是最终收敛后的结果，一般都比较好。**如果使用sgd的话,可以选择从1.0或者0.1的学习率开始,隔一段时间,在验证集上检查一下,如果cost没有下降,就对学习率减半**. 我看过很多论文都这么搞,我自己实验的结果也很好. 当然,也可以先用ada系列先跑,最后快收敛的时候,更换成sgd继续训练.同样也会有提升.据说adadelta一般在分类问题上效果比较好，adam在生成问题上效果比较好。(Captain Jack令言：sgd adam 这些选择上, 看你个人选择. 一般对网络不是决定性的. 反正我无脑用sgd + momentum. ）\n\n5.**激活函数**\n\t除了gate之类的地方,需要把输出限制成0-1之外,**尽量不要用sigmoid**,可以用tanh或者relu之类的激活函数.1. sigmoid函数在-4到4之外的区间梯度接近0，很容易造成梯度消失问题。2. 输入0均值，sigmoid函数的输出不是0均值的。（hzwer令言:虽然有至少十种激活函数，但在 Relu 外只推荐试一下 Swish。)\n\n6.BN层具有加速训练速度，有效防止梯度消失与梯度爆炸，具有防止过拟合的效果，所以构建网络时最好要加上这个组件。(Captain Jack令言：batch normalization我一直没用, 虽然我知道这个很好, 我不用仅仅是因为我懒. 所以要鼓励使用batch normalization.）\n\n7.如果你的模型包含全连接层（MLP），并且输入和输出大小一样，可以考虑将MLP替换成**Highway Network**,我尝试对结果有一点提升，建议作为最后提升模型的手段，原理很简单，就是给**输出加了一个gate来控制信息的流动**，详细介绍请参考论文: [http://arxiv.org/abs/1505.00387](https://link.zhihu.com/?target=http%3A//arxiv.org/abs/1505.00387)\n\n8.来自@张馨宇的技巧：**一轮加正则，一轮不加正则，反复进行。**\n\n**9.Ensemble**\nEnsemble是论文刷结果的终极核武器,深度学习中一般有以下几种方式\n同样的参数,不同的初始化方式\n不同的参数,通过cross-validation,选取最好的几组\n同样的参数,模型训练的不同阶段，即不同迭代次数的模型。\n不同的模型,进行线性融合. 例如RNN和传统模型.\n\n**10.自动调参方法**\n（1）Grid Search：其原理就像是在数组里找最大值。缺点是太费时间了，特别像神经网络，一般尝试不了太多的参数组合。\n（2）Random Search：经验上，Random Search比Gird Search更有效。实际操作的时候，一般也是先用Gird Search的方法，得到所有候选参数，然后每次从中随机选择进行训练。另外Random Search往往会和由粗到细的调参策略结合使用，即在效果比较好的参数附近进行更加精细的搜索。\n（3）Bayesian Optimization：贝叶斯优化，考虑到了不同参数对应的 实验结果值，因此更节省时间，贝叶斯调参比Grid Search迭代次数少， 速度快；而且其针对非凸问题依然稳健。\n\n**11.Loss设计**\n\\+ 一般来说分类就是Softmax, 回归就是L2的loss. 但是要注意loss的错误范围(主要是回归), 你预测一个label是10000的值, 模型输出0, 你算算这loss多大, 这还是单变量的情况下. 一般结果都是nan. 所以不仅仅输入要做normalization, 输出也要.\n\\+ 多任务情况下, 各loss想法限制在一个量级上, 或者最终限制在一个量级上, 初期可以着重一个任务的loss。\n\n### **网络结构设计（关于SE)**\n\nSE在分类上是个涨点必备的工具，换言之，堆最高精度是一定要给每个block都加上它的，但是如果需要考虑时间，参数量和精度等的trade-off，无脑堆就没有意义了，这个时候应该要选择在合适的地方使用合适的模块。这个时候，**推荐在block数量和添加SE上做权衡**，即**给部分blcok加上SE，同时砍掉一些block来加速**，这样可以在精度差不多的情况下减少一些参数量。当然inference时间这个事需要看具体的应用平台对SE的实现，就是GAP和FC的速度，这就具体问题具体分析了。**有余力有卡的人，可以迁移某种NAS方法来做这个的搜索。**\n参考自：\n你有哪些deep learning（rnn、cnn）调参的经验？ - 萧瑟的回答 - 知乎 https://www.zhihu.com/question/41631631/answer/94816420\n你有哪些deep learning（rnn、cnn）调参的经验？ - Towser的回答 - 知乎 https://www.zhihu.com/question/41631631/answer/862075836\n你有哪些deep learning（rnn、cnn）调参的经验？ - 罗浩.ZJU的回答 - 知乎 https://www.zhihu.com/question/41631631/answer/216788968\n你有哪些deep learning（rnn、cnn）调参的经验？ - 京东白条的回答 - 知乎 [https://www.zhihu.com/question/4163](https://www.zhihu.com/question/41631631/answer/776852832)\n\n> 所谓SE：SENet是Squeeze-and-Excitation Networks的简称，拿到了ImageNet2017分类比赛冠军，其效果得到了认可，其提出的SE模块思想简单，易于实现，并且很容易可以加载到现有的网络模型框架中。*<u>SENet主要是学习了channel之间的相关性，筛选出了针对通道的注意力</u>*，稍微增加了一点计算量，但是效果比较好。\n\n对于CNN网络来说，其核心计算是卷积算子，其通过卷积核从输入特征图学习到新特征图。从本质上讲，卷积是对一个局部区域进行特征融合，这包括空间上（H和W维度）以及通道间（C维度）的特征融合。\n\n\n![](https://img-blog.csdnimg.cn/2019051415564658.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L25pamlheWFuMTIz,size_16,color_FFFFFF,t_70)\n\n卷积实际上是对<u>局部区域</u>进行的特征融合。 这也导致了普通卷积神经网络的感受野不大，当然你也可以设计出更多的通道特征来增加这个，但是这样做导致了计算量大大的增加。因此为了空间上融合更多特征融合，或者是提取多尺度空间信息。也提出了许多不同的方法如Inception网络的多分支结构。对于channel维度的特征融合，卷积操作基本上默认对输入特征图的所有channel进行融合。<u>而SENet网络的创新点在于关注channel之间的关系，希望模型可以自动学习到不同channel特征的重要程度</u>。为此，SENet提出了Squeeze-and-Excitation (SE)模块，如下图所示：\n\n\n![](https://img-blog.csdnimg.cn/20190514160215998.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L25pamlheWFuMTIz,size_16,color_FFFFFF,t_70)\n\n### 反面训诫\n\n1.1、一上来就自己动手写模型。\n建议首先用**成熟的开源项目及其默认配置**（例如 Gluon 对经典模型的各种复现、各个著名模型作者自己放出来的代码仓库）在自己的数据集上跑一遍，在等程序运行结束的时间里仔细研究一下代码里的各种细节，最后再自己写或者改代码。\n\n1.2、**不推荐做人肉模型设计**，比如把某层卷积改大一点，或者微调一下通道数。除非有特别 insight，不要自己乱设计新组件。\n\n2、训 RNN 不加 gradient clipping，导致训练一段时间以后 loss 突然变成 Nan。\n\n3、tying input & output embedding（就是词向量层和输出 softmax 前的矩阵共享参数，在语言模型或机器翻译中常用）时学习率需要设置得非常小，不然容易 Nan。\n\n4.1、在数据集很大的情况下，一上来就跑全量数据。建议先用 1/100、1/10 的数据跑一跑，对模型性能和训练时间有个底。\n\n4.2认为网络层数越大越好。参数量什么的都不是大问题，在性能不丢的情况下，网络层数减到最小.（Captain Jack令言：你有95%概率不会使用超过40层的模型. ）\n\n5、只喜欢漂亮的模型结构，瞧不起调参数的论文/实验报告，**看论文时经常不看超参数设置等细节**。殊不知在自己没有太多资源实验的情况下，实验报告类文章简直是业界良心！\nNLP 领域主要推荐以下几篇：\nRegularizing and Optimizing LSTM Language Models（LSTM 的训练技巧）\nMassive Exploration of Neural Machine Translation Architectures（NMT 里各个超参的影响）\nTraining Tips for the Transformer Model（训练 Transformer 时会发生的各种现象）\nRoBERTa: A Robustly Optimized BERT Pretraining Approach（BERT 预训练技巧，虽然跟大部分人没啥关系）\nCV 我不算太熟，不过也可以勉强推荐几篇：\n\n[Training ImageNet in 1 Hour（大批量训练技巧）](https://arxiv.org/pdf/1706.02677.pdf)\n[Bag of Tricks for Image Classification with Convolutional Neural Networks（各种训练技巧集大成）](https://openaccess.thecvf.com/content_CVPR_2019/papers/He_Bag_of_Tricks_for_Image_Classification_with_Convolutional_Neural_Networks_CVPR_2019_paper.pdf)\n[EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks（当前对参数利用最有效的 CNN）](https://arxiv.org/pdf/1905.11946.pdf)\n\n6、对于loss这种受 batch size、sequence length 各种因素影响的数字，人是没有数感的，建议首先计算一下 per token loss（如果是多任务，可以每个任务单独算；类似地，某些 CV 任务可以计算 per pixel loss），心里有点感觉。**脱离损失函数的形式谈学习率没有意义**（例如单是对 batch size 求和或者取平均这个差异就会使梯度差成百上千倍）。\n在确定初始学习率的时候，从一个很小的值（例如 1e-7）开始，然后**每一步指数增大学习率（例如扩大1.05 倍）进行训练。**训练几百步应该能观察到损失函数随训练步数呈对勾形，选择损失下降最快那一段的学习率即可。\n(Captain Jack令言：**观察loss胜于观察准确率**\n准确率虽然是评测指标, 但是训练过程中还是要注意loss的. 你会发现有些情况下, 准确率是突变的, 原来一直是0, 可能保持上千迭代, 然后突然变1. 要是因为这个你提前中断训练了, 只有老天替你惋惜了. 而loss是不会有这么诡异的情况发生的, 毕竟优化目标是loss.\n给NN一点时间, 要根据任务留给NN的学习一定空间. 不能说前面一段时间没起色就不管了. 有些情况下就是前面一段时间看不出起色, 然后开始稳定学习.）\n\n7.1、优化器**只推荐** Momentum 和 Adam。在这些方面做尝试意义不大，如果性能提升反倒可能说明模型不成熟。\n\n7.2、**Adam 可以解决一堆奇奇怪怪的问题**（有时 loss 降不下去，换 Adam 瞬间就好了），**也可以带来一堆奇奇怪怪的问题**（比如单词词频差异很大，当前 batch 没有的单词的词向量也被更新；再比如Adam和L2正则结合产生的复杂效果）。用的时候要胆大心细，万一遇到问题找各种魔改 Adam（比如 [MaskedAdam](https://www.zhihu.com/question/265357659/answer/580469438), AdamW 啥的）抢救。\n\n8、subword 总是会很稳定地涨点，只管用就对了。\n\n9、**GPU 上报错时尽量放在 CPU 上重跑**，错误信息更友好。例如 \"ERROR:tensorflow:Model diverged with loss = NaN\" 其实很有可能是输入 ID 超出了 softmax 词表的范围。\n\n**10、别没耐心**！\n**有些指标是有滞后性的，需要等训练一段时间才开始动。**很多人训练几步看没什么效果就把程序停掉开始 debug 了，但其实代码毫无问题。如此反复好几天甚至一两周都在原地踏步，其实需要做的仅仅是让程序自个儿安安静静地跑上几个小时或者一天……\n\n### trick\n\n-  fine-tuning: 通常来说，直接把预训练模型来用效果不一定足够好，因此需要进行fine-tuning（微调）。fine-tuning需要冻结网络的前几层参数，只更新网络结构的后面几层和最后的全连接层，这样效果会更好。\n\n-   Learning rate:在迁移学习的微调过程中一般不建议使用过大的学习率，通常来说1e-5是比较合适的选择。\n\n  #### 迁移学习往往还和你的任务中的数据关系密切，可以考虑以下几种情况。\n\n  - ##### 新的数据集较小，并且和pre-trained model所使用的训练数据集相似度较高\n\n    由于数据集较小，在进行finetune存在overfit的风险，又由于数据集和原始数据集相似度较高，因此二者不论是local feature还是global feature都比较相   近，所以此时最佳的方法是把CNN网络当做特征提取器然后训练一个分类器进行分类  \n\n  - ##### 新的数据集较大，并且和pre-trained model所使用的训练数据集相似度较高：\n\n    很明显，此时我们不用担心overfit，因此对全部网络结构进行fine-tune是较好的。\n\n  - ##### 新的数据集较小，并且和pre-trained model所使用的训练数据集差异很大： \n\n    由于数据集较小，不适合进行fine-tune，由于数据集差异大，应该在单独训练网络结构中较高的层，前面几层local的就不用训练了，直接固定权值。在实际中，这种问题下较好的解决方案一般是从网络的某层开始取出特征，然后训练SVM分类器。 \n\n  - ##### 新的数据集较大，并且和pre-trained model所使用的训练数据集差异很大：  \n\n    本来由于数据集较大，可以从头开始训练的，但是在实际中更偏向于训练整个pre-trained model的网络。\n\n  \n\n  ​    \n","source":"_posts/deep_learning/fine-tuning.md","raw":"---\ntitle: fine-tuning的方法\ntags: [深度学习,微调]\ncategories: [深度学习]\ndate: 2021-08-13 14:28:24\n---\n\n>收集关于深度学习的调参的相关笔记，主要用于网络训练的微调。\n\n### **训练技巧**\n\n1.要做**梯度归一化**,即算出来的梯度除以minibatch size\n\n2.clip c(梯度裁剪): 限制最大梯度,其实是value = sqrt(w1^2 +w2^2….),如果value超过了阈值,就算一个衰减系数,让value的值等于阈值: 5,10,15\n\n##### **3.防止过拟合**\n\n​\t一般常用的防止过拟合方法有使用**L1正则项、L2正则项、dropout、提前终止、数据集扩充等**。如果模型在训练集上表现比较好但在测试集上表现欠佳可以选择增大L1或L2正则的惩罚力度（**L2正则经验上首选1.0**，超过10很少见），或**增大dropout的随机失活概率**（经验首选0.5）；或者当随着训练的持续在测试集上不增反降时，使用提前终止训练的方法。当然**最有效的还是增大训练集的规模**，实在难以获得新数据也可以使用数据集增强的方法，比如CV任务可以对数据集进行裁剪、翻转、平移等方法进行数据集增强，这种方法往往都会提高最后模型的测试精度。\n \tdropout对小数据防止过拟合有很好的效果,值一般设为0.5,小数据上dropout+sgd。在大部分实验中，效果提升都非常明显.**建议尝试**。 dropout的位置比较有讲究, 对于RNN,建议放到输入->RNN与RNN->输出的位置.关于RNN如何用dropout,可以参考:[http://arxiv.org/abs/1409.2329](https://link.zhihu.com/?target=http%3A//arxiv.org/abs/1409.2329)(Captain Jack令言:(不仅仅可以防止过拟合, 其实这相当于做人力成本最低的Ensemble, 当然, 训练起来会比没有Dropout的要慢一点, 同时网络参数你最好相应加一点, 对, 这会再慢一点).)\n\n**4.超参** \n\n​\tlearning rate 最重要**，推荐了解 cosine learning rate 和 cyclic learning rate，其次是 **batchsize 和 weight decay**。当你的模型还不错的时候，可以试着做数据增广和改损失函数锦上添花了。(罗浩ZJU令言：随着网络训练的进行，学习率要逐渐降下来；网络性能越好，学习率要越小（即越需要微调而非粗调)；batchsize通常影响没那么大，塞满卡就行，除了特殊的算法需要batch大一点)\n​\tadam,adadelta等,在小数据上,我这里实验的效果不如sgd, sgd收敛速度会慢一些，但是最终收敛后的结果，一般都比较好。**如果使用sgd的话,可以选择从1.0或者0.1的学习率开始,隔一段时间,在验证集上检查一下,如果cost没有下降,就对学习率减半**. 我看过很多论文都这么搞,我自己实验的结果也很好. 当然,也可以先用ada系列先跑,最后快收敛的时候,更换成sgd继续训练.同样也会有提升.据说adadelta一般在分类问题上效果比较好，adam在生成问题上效果比较好。(Captain Jack令言：sgd adam 这些选择上, 看你个人选择. 一般对网络不是决定性的. 反正我无脑用sgd + momentum. ）\n\n5.**激活函数**\n\t除了gate之类的地方,需要把输出限制成0-1之外,**尽量不要用sigmoid**,可以用tanh或者relu之类的激活函数.1. sigmoid函数在-4到4之外的区间梯度接近0，很容易造成梯度消失问题。2. 输入0均值，sigmoid函数的输出不是0均值的。（hzwer令言:虽然有至少十种激活函数，但在 Relu 外只推荐试一下 Swish。)\n\n6.BN层具有加速训练速度，有效防止梯度消失与梯度爆炸，具有防止过拟合的效果，所以构建网络时最好要加上这个组件。(Captain Jack令言：batch normalization我一直没用, 虽然我知道这个很好, 我不用仅仅是因为我懒. 所以要鼓励使用batch normalization.）\n\n7.如果你的模型包含全连接层（MLP），并且输入和输出大小一样，可以考虑将MLP替换成**Highway Network**,我尝试对结果有一点提升，建议作为最后提升模型的手段，原理很简单，就是给**输出加了一个gate来控制信息的流动**，详细介绍请参考论文: [http://arxiv.org/abs/1505.00387](https://link.zhihu.com/?target=http%3A//arxiv.org/abs/1505.00387)\n\n8.来自@张馨宇的技巧：**一轮加正则，一轮不加正则，反复进行。**\n\n**9.Ensemble**\nEnsemble是论文刷结果的终极核武器,深度学习中一般有以下几种方式\n同样的参数,不同的初始化方式\n不同的参数,通过cross-validation,选取最好的几组\n同样的参数,模型训练的不同阶段，即不同迭代次数的模型。\n不同的模型,进行线性融合. 例如RNN和传统模型.\n\n**10.自动调参方法**\n（1）Grid Search：其原理就像是在数组里找最大值。缺点是太费时间了，特别像神经网络，一般尝试不了太多的参数组合。\n（2）Random Search：经验上，Random Search比Gird Search更有效。实际操作的时候，一般也是先用Gird Search的方法，得到所有候选参数，然后每次从中随机选择进行训练。另外Random Search往往会和由粗到细的调参策略结合使用，即在效果比较好的参数附近进行更加精细的搜索。\n（3）Bayesian Optimization：贝叶斯优化，考虑到了不同参数对应的 实验结果值，因此更节省时间，贝叶斯调参比Grid Search迭代次数少， 速度快；而且其针对非凸问题依然稳健。\n\n**11.Loss设计**\n\\+ 一般来说分类就是Softmax, 回归就是L2的loss. 但是要注意loss的错误范围(主要是回归), 你预测一个label是10000的值, 模型输出0, 你算算这loss多大, 这还是单变量的情况下. 一般结果都是nan. 所以不仅仅输入要做normalization, 输出也要.\n\\+ 多任务情况下, 各loss想法限制在一个量级上, 或者最终限制在一个量级上, 初期可以着重一个任务的loss。\n\n### **网络结构设计（关于SE)**\n\nSE在分类上是个涨点必备的工具，换言之，堆最高精度是一定要给每个block都加上它的，但是如果需要考虑时间，参数量和精度等的trade-off，无脑堆就没有意义了，这个时候应该要选择在合适的地方使用合适的模块。这个时候，**推荐在block数量和添加SE上做权衡**，即**给部分blcok加上SE，同时砍掉一些block来加速**，这样可以在精度差不多的情况下减少一些参数量。当然inference时间这个事需要看具体的应用平台对SE的实现，就是GAP和FC的速度，这就具体问题具体分析了。**有余力有卡的人，可以迁移某种NAS方法来做这个的搜索。**\n参考自：\n你有哪些deep learning（rnn、cnn）调参的经验？ - 萧瑟的回答 - 知乎 https://www.zhihu.com/question/41631631/answer/94816420\n你有哪些deep learning（rnn、cnn）调参的经验？ - Towser的回答 - 知乎 https://www.zhihu.com/question/41631631/answer/862075836\n你有哪些deep learning（rnn、cnn）调参的经验？ - 罗浩.ZJU的回答 - 知乎 https://www.zhihu.com/question/41631631/answer/216788968\n你有哪些deep learning（rnn、cnn）调参的经验？ - 京东白条的回答 - 知乎 [https://www.zhihu.com/question/4163](https://www.zhihu.com/question/41631631/answer/776852832)\n\n> 所谓SE：SENet是Squeeze-and-Excitation Networks的简称，拿到了ImageNet2017分类比赛冠军，其效果得到了认可，其提出的SE模块思想简单，易于实现，并且很容易可以加载到现有的网络模型框架中。*<u>SENet主要是学习了channel之间的相关性，筛选出了针对通道的注意力</u>*，稍微增加了一点计算量，但是效果比较好。\n\n对于CNN网络来说，其核心计算是卷积算子，其通过卷积核从输入特征图学习到新特征图。从本质上讲，卷积是对一个局部区域进行特征融合，这包括空间上（H和W维度）以及通道间（C维度）的特征融合。\n\n\n![](https://img-blog.csdnimg.cn/2019051415564658.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L25pamlheWFuMTIz,size_16,color_FFFFFF,t_70)\n\n卷积实际上是对<u>局部区域</u>进行的特征融合。 这也导致了普通卷积神经网络的感受野不大，当然你也可以设计出更多的通道特征来增加这个，但是这样做导致了计算量大大的增加。因此为了空间上融合更多特征融合，或者是提取多尺度空间信息。也提出了许多不同的方法如Inception网络的多分支结构。对于channel维度的特征融合，卷积操作基本上默认对输入特征图的所有channel进行融合。<u>而SENet网络的创新点在于关注channel之间的关系，希望模型可以自动学习到不同channel特征的重要程度</u>。为此，SENet提出了Squeeze-and-Excitation (SE)模块，如下图所示：\n\n\n![](https://img-blog.csdnimg.cn/20190514160215998.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L25pamlheWFuMTIz,size_16,color_FFFFFF,t_70)\n\n### 反面训诫\n\n1.1、一上来就自己动手写模型。\n建议首先用**成熟的开源项目及其默认配置**（例如 Gluon 对经典模型的各种复现、各个著名模型作者自己放出来的代码仓库）在自己的数据集上跑一遍，在等程序运行结束的时间里仔细研究一下代码里的各种细节，最后再自己写或者改代码。\n\n1.2、**不推荐做人肉模型设计**，比如把某层卷积改大一点，或者微调一下通道数。除非有特别 insight，不要自己乱设计新组件。\n\n2、训 RNN 不加 gradient clipping，导致训练一段时间以后 loss 突然变成 Nan。\n\n3、tying input & output embedding（就是词向量层和输出 softmax 前的矩阵共享参数，在语言模型或机器翻译中常用）时学习率需要设置得非常小，不然容易 Nan。\n\n4.1、在数据集很大的情况下，一上来就跑全量数据。建议先用 1/100、1/10 的数据跑一跑，对模型性能和训练时间有个底。\n\n4.2认为网络层数越大越好。参数量什么的都不是大问题，在性能不丢的情况下，网络层数减到最小.（Captain Jack令言：你有95%概率不会使用超过40层的模型. ）\n\n5、只喜欢漂亮的模型结构，瞧不起调参数的论文/实验报告，**看论文时经常不看超参数设置等细节**。殊不知在自己没有太多资源实验的情况下，实验报告类文章简直是业界良心！\nNLP 领域主要推荐以下几篇：\nRegularizing and Optimizing LSTM Language Models（LSTM 的训练技巧）\nMassive Exploration of Neural Machine Translation Architectures（NMT 里各个超参的影响）\nTraining Tips for the Transformer Model（训练 Transformer 时会发生的各种现象）\nRoBERTa: A Robustly Optimized BERT Pretraining Approach（BERT 预训练技巧，虽然跟大部分人没啥关系）\nCV 我不算太熟，不过也可以勉强推荐几篇：\n\n[Training ImageNet in 1 Hour（大批量训练技巧）](https://arxiv.org/pdf/1706.02677.pdf)\n[Bag of Tricks for Image Classification with Convolutional Neural Networks（各种训练技巧集大成）](https://openaccess.thecvf.com/content_CVPR_2019/papers/He_Bag_of_Tricks_for_Image_Classification_with_Convolutional_Neural_Networks_CVPR_2019_paper.pdf)\n[EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks（当前对参数利用最有效的 CNN）](https://arxiv.org/pdf/1905.11946.pdf)\n\n6、对于loss这种受 batch size、sequence length 各种因素影响的数字，人是没有数感的，建议首先计算一下 per token loss（如果是多任务，可以每个任务单独算；类似地，某些 CV 任务可以计算 per pixel loss），心里有点感觉。**脱离损失函数的形式谈学习率没有意义**（例如单是对 batch size 求和或者取平均这个差异就会使梯度差成百上千倍）。\n在确定初始学习率的时候，从一个很小的值（例如 1e-7）开始，然后**每一步指数增大学习率（例如扩大1.05 倍）进行训练。**训练几百步应该能观察到损失函数随训练步数呈对勾形，选择损失下降最快那一段的学习率即可。\n(Captain Jack令言：**观察loss胜于观察准确率**\n准确率虽然是评测指标, 但是训练过程中还是要注意loss的. 你会发现有些情况下, 准确率是突变的, 原来一直是0, 可能保持上千迭代, 然后突然变1. 要是因为这个你提前中断训练了, 只有老天替你惋惜了. 而loss是不会有这么诡异的情况发生的, 毕竟优化目标是loss.\n给NN一点时间, 要根据任务留给NN的学习一定空间. 不能说前面一段时间没起色就不管了. 有些情况下就是前面一段时间看不出起色, 然后开始稳定学习.）\n\n7.1、优化器**只推荐** Momentum 和 Adam。在这些方面做尝试意义不大，如果性能提升反倒可能说明模型不成熟。\n\n7.2、**Adam 可以解决一堆奇奇怪怪的问题**（有时 loss 降不下去，换 Adam 瞬间就好了），**也可以带来一堆奇奇怪怪的问题**（比如单词词频差异很大，当前 batch 没有的单词的词向量也被更新；再比如Adam和L2正则结合产生的复杂效果）。用的时候要胆大心细，万一遇到问题找各种魔改 Adam（比如 [MaskedAdam](https://www.zhihu.com/question/265357659/answer/580469438), AdamW 啥的）抢救。\n\n8、subword 总是会很稳定地涨点，只管用就对了。\n\n9、**GPU 上报错时尽量放在 CPU 上重跑**，错误信息更友好。例如 \"ERROR:tensorflow:Model diverged with loss = NaN\" 其实很有可能是输入 ID 超出了 softmax 词表的范围。\n\n**10、别没耐心**！\n**有些指标是有滞后性的，需要等训练一段时间才开始动。**很多人训练几步看没什么效果就把程序停掉开始 debug 了，但其实代码毫无问题。如此反复好几天甚至一两周都在原地踏步，其实需要做的仅仅是让程序自个儿安安静静地跑上几个小时或者一天……\n\n### trick\n\n-  fine-tuning: 通常来说，直接把预训练模型来用效果不一定足够好，因此需要进行fine-tuning（微调）。fine-tuning需要冻结网络的前几层参数，只更新网络结构的后面几层和最后的全连接层，这样效果会更好。\n\n-   Learning rate:在迁移学习的微调过程中一般不建议使用过大的学习率，通常来说1e-5是比较合适的选择。\n\n  #### 迁移学习往往还和你的任务中的数据关系密切，可以考虑以下几种情况。\n\n  - ##### 新的数据集较小，并且和pre-trained model所使用的训练数据集相似度较高\n\n    由于数据集较小，在进行finetune存在overfit的风险，又由于数据集和原始数据集相似度较高，因此二者不论是local feature还是global feature都比较相   近，所以此时最佳的方法是把CNN网络当做特征提取器然后训练一个分类器进行分类  \n\n  - ##### 新的数据集较大，并且和pre-trained model所使用的训练数据集相似度较高：\n\n    很明显，此时我们不用担心overfit，因此对全部网络结构进行fine-tune是较好的。\n\n  - ##### 新的数据集较小，并且和pre-trained model所使用的训练数据集差异很大： \n\n    由于数据集较小，不适合进行fine-tune，由于数据集差异大，应该在单独训练网络结构中较高的层，前面几层local的就不用训练了，直接固定权值。在实际中，这种问题下较好的解决方案一般是从网络的某层开始取出特征，然后训练SVM分类器。 \n\n  - ##### 新的数据集较大，并且和pre-trained model所使用的训练数据集差异很大：  \n\n    本来由于数据集较大，可以从头开始训练的，但是在实际中更偏向于训练整个pre-trained model的网络。\n\n  \n\n  ​    \n","slug":"deep_learning/fine-tuning","published":1,"updated":"2021-08-13T09:32:52.243Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cksa5ksem0007a0x4aa4ighm6","content":"<blockquote>\n<p>收集关于深度学习的调参的相关笔记，主要用于网络训练的微调。</p>\n</blockquote>\n<h3 id=\"训练技巧\"><a href=\"#训练技巧\" class=\"headerlink\" title=\"训练技巧\"></a><strong>训练技巧</strong></h3><p>1.要做<strong>梯度归一化</strong>,即算出来的梯度除以minibatch size</p>\n<p>2.clip c(梯度裁剪): 限制最大梯度,其实是value = sqrt(w1^2 +w2^2….),如果value超过了阈值,就算一个衰减系数,让value的值等于阈值: 5,10,15</p>\n<h5 id=\"3-防止过拟合\"><a href=\"#3-防止过拟合\" class=\"headerlink\" title=\"3.防止过拟合\"></a><strong>3.防止过拟合</strong></h5><p>​    一般常用的防止过拟合方法有使用<strong>L1正则项、L2正则项、dropout、提前终止、数据集扩充等</strong>。如果模型在训练集上表现比较好但在测试集上表现欠佳可以选择增大L1或L2正则的惩罚力度（<strong>L2正则经验上首选1.0</strong>，超过10很少见），或<strong>增大dropout的随机失活概率</strong>（经验首选0.5）；或者当随着训练的持续在测试集上不增反降时，使用提前终止训练的方法。当然<strong>最有效的还是增大训练集的规模</strong>，实在难以获得新数据也可以使用数据集增强的方法，比如CV任务可以对数据集进行裁剪、翻转、平移等方法进行数据集增强，这种方法往往都会提高最后模型的测试精度。<br>     dropout对小数据防止过拟合有很好的效果,值一般设为0.5,小数据上dropout+sgd。在大部分实验中，效果提升都非常明显.<strong>建议尝试</strong>。 dropout的位置比较有讲究, 对于RNN,建议放到输入-&gt;RNN与RNN-&gt;输出的位置.关于RNN如何用dropout,可以参考:<a href=\"https://link.zhihu.com/?target=http://arxiv.org/abs/1409.2329\">http://arxiv.org/abs/1409.2329</a>(Captain Jack令言:(不仅仅可以防止过拟合, 其实这相当于做人力成本最低的Ensemble, 当然, 训练起来会比没有Dropout的要慢一点, 同时网络参数你最好相应加一点, 对, 这会再慢一点).)</p>\n<p><strong>4.超参</strong> </p>\n<p>​    learning rate 最重要<strong>，推荐了解 cosine learning rate 和 cyclic learning rate，其次是 <strong>batchsize 和 weight decay</strong>。当你的模型还不错的时候，可以试着做数据增广和改损失函数锦上添花了。(罗浩ZJU令言：随着网络训练的进行，学习率要逐渐降下来；网络性能越好，学习率要越小（即越需要微调而非粗调)；batchsize通常影响没那么大，塞满卡就行，除了特殊的算法需要batch大一点)<br>​    adam,adadelta等,在小数据上,我这里实验的效果不如sgd, sgd收敛速度会慢一些，但是最终收敛后的结果，一般都比较好。</strong>如果使用sgd的话,可以选择从1.0或者0.1的学习率开始,隔一段时间,在验证集上检查一下,如果cost没有下降,就对学习率减半**. 我看过很多论文都这么搞,我自己实验的结果也很好. 当然,也可以先用ada系列先跑,最后快收敛的时候,更换成sgd继续训练.同样也会有提升.据说adadelta一般在分类问题上效果比较好，adam在生成问题上效果比较好。(Captain Jack令言：sgd adam 这些选择上, 看你个人选择. 一般对网络不是决定性的. 反正我无脑用sgd + momentum. ）</p>\n<p>5.<strong>激活函数</strong><br>    除了gate之类的地方,需要把输出限制成0-1之外,<strong>尽量不要用sigmoid</strong>,可以用tanh或者relu之类的激活函数.1. sigmoid函数在-4到4之外的区间梯度接近0，很容易造成梯度消失问题。2. 输入0均值，sigmoid函数的输出不是0均值的。（hzwer令言:虽然有至少十种激活函数，但在 Relu 外只推荐试一下 Swish。)</p>\n<p>6.BN层具有加速训练速度，有效防止梯度消失与梯度爆炸，具有防止过拟合的效果，所以构建网络时最好要加上这个组件。(Captain Jack令言：batch normalization我一直没用, 虽然我知道这个很好, 我不用仅仅是因为我懒. 所以要鼓励使用batch normalization.）</p>\n<p>7.如果你的模型包含全连接层（MLP），并且输入和输出大小一样，可以考虑将MLP替换成<strong>Highway Network</strong>,我尝试对结果有一点提升，建议作为最后提升模型的手段，原理很简单，就是给<strong>输出加了一个gate来控制信息的流动</strong>，详细介绍请参考论文: <a href=\"https://link.zhihu.com/?target=http://arxiv.org/abs/1505.00387\">http://arxiv.org/abs/1505.00387</a></p>\n<p>8.来自@张馨宇的技巧：<strong>一轮加正则，一轮不加正则，反复进行。</strong></p>\n<p><strong>9.Ensemble</strong><br>Ensemble是论文刷结果的终极核武器,深度学习中一般有以下几种方式<br>同样的参数,不同的初始化方式<br>不同的参数,通过cross-validation,选取最好的几组<br>同样的参数,模型训练的不同阶段，即不同迭代次数的模型。<br>不同的模型,进行线性融合. 例如RNN和传统模型.</p>\n<p><strong>10.自动调参方法</strong><br>（1）Grid Search：其原理就像是在数组里找最大值。缺点是太费时间了，特别像神经网络，一般尝试不了太多的参数组合。<br>（2）Random Search：经验上，Random Search比Gird Search更有效。实际操作的时候，一般也是先用Gird Search的方法，得到所有候选参数，然后每次从中随机选择进行训练。另外Random Search往往会和由粗到细的调参策略结合使用，即在效果比较好的参数附近进行更加精细的搜索。<br>（3）Bayesian Optimization：贝叶斯优化，考虑到了不同参数对应的 实验结果值，因此更节省时间，贝叶斯调参比Grid Search迭代次数少， 速度快；而且其针对非凸问题依然稳健。</p>\n<p><strong>11.Loss设计</strong><br>+ 一般来说分类就是Softmax, 回归就是L2的loss. 但是要注意loss的错误范围(主要是回归), 你预测一个label是10000的值, 模型输出0, 你算算这loss多大, 这还是单变量的情况下. 一般结果都是nan. 所以不仅仅输入要做normalization, 输出也要.<br>+ 多任务情况下, 各loss想法限制在一个量级上, 或者最终限制在一个量级上, 初期可以着重一个任务的loss。</p>\n<h3 id=\"网络结构设计（关于SE\"><a href=\"#网络结构设计（关于SE\" class=\"headerlink\" title=\"网络结构设计（关于SE)\"></a><strong>网络结构设计（关于SE)</strong></h3><p>SE在分类上是个涨点必备的工具，换言之，堆最高精度是一定要给每个block都加上它的，但是如果需要考虑时间，参数量和精度等的trade-off，无脑堆就没有意义了，这个时候应该要选择在合适的地方使用合适的模块。这个时候，<strong>推荐在block数量和添加SE上做权衡</strong>，即<strong>给部分blcok加上SE，同时砍掉一些block来加速</strong>，这样可以在精度差不多的情况下减少一些参数量。当然inference时间这个事需要看具体的应用平台对SE的实现，就是GAP和FC的速度，这就具体问题具体分析了。<strong>有余力有卡的人，可以迁移某种NAS方法来做这个的搜索。</strong><br>参考自：<br>你有哪些deep learning（rnn、cnn）调参的经验？ - 萧瑟的回答 - 知乎 <a href=\"https://www.zhihu.com/question/41631631/answer/94816420\">https://www.zhihu.com/question/41631631/answer/94816420</a><br>你有哪些deep learning（rnn、cnn）调参的经验？ - Towser的回答 - 知乎 <a href=\"https://www.zhihu.com/question/41631631/answer/862075836\">https://www.zhihu.com/question/41631631/answer/862075836</a><br>你有哪些deep learning（rnn、cnn）调参的经验？ - 罗浩.ZJU的回答 - 知乎 <a href=\"https://www.zhihu.com/question/41631631/answer/216788968\">https://www.zhihu.com/question/41631631/answer/216788968</a><br>你有哪些deep learning（rnn、cnn）调参的经验？ - 京东白条的回答 - 知乎 <a href=\"https://www.zhihu.com/question/41631631/answer/776852832\">https://www.zhihu.com/question/4163</a></p>\n<blockquote>\n<p>所谓SE：SENet是Squeeze-and-Excitation Networks的简称，拿到了ImageNet2017分类比赛冠军，其效果得到了认可，其提出的SE模块思想简单，易于实现，并且很容易可以加载到现有的网络模型框架中。*<u>SENet主要是学习了channel之间的相关性，筛选出了针对通道的注意力</u>*，稍微增加了一点计算量，但是效果比较好。</p>\n</blockquote>\n<p>对于CNN网络来说，其核心计算是卷积算子，其通过卷积核从输入特征图学习到新特征图。从本质上讲，卷积是对一个局部区域进行特征融合，这包括空间上（H和W维度）以及通道间（C维度）的特征融合。</p>\n<p><img src=\"https://img-blog.csdnimg.cn/2019051415564658.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L25pamlheWFuMTIz,size_16,color_FFFFFF,t_70\"></p>\n<p>卷积实际上是对<u>局部区域</u>进行的特征融合。 这也导致了普通卷积神经网络的感受野不大，当然你也可以设计出更多的通道特征来增加这个，但是这样做导致了计算量大大的增加。因此为了空间上融合更多特征融合，或者是提取多尺度空间信息。也提出了许多不同的方法如Inception网络的多分支结构。对于channel维度的特征融合，卷积操作基本上默认对输入特征图的所有channel进行融合。<u>而SENet网络的创新点在于关注channel之间的关系，希望模型可以自动学习到不同channel特征的重要程度</u>。为此，SENet提出了Squeeze-and-Excitation (SE)模块，如下图所示：</p>\n<p><img src=\"https://img-blog.csdnimg.cn/20190514160215998.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L25pamlheWFuMTIz,size_16,color_FFFFFF,t_70\"></p>\n<h3 id=\"反面训诫\"><a href=\"#反面训诫\" class=\"headerlink\" title=\"反面训诫\"></a>反面训诫</h3><p>1.1、一上来就自己动手写模型。<br>建议首先用<strong>成熟的开源项目及其默认配置</strong>（例如 Gluon 对经典模型的各种复现、各个著名模型作者自己放出来的代码仓库）在自己的数据集上跑一遍，在等程序运行结束的时间里仔细研究一下代码里的各种细节，最后再自己写或者改代码。</p>\n<p>1.2、<strong>不推荐做人肉模型设计</strong>，比如把某层卷积改大一点，或者微调一下通道数。除非有特别 insight，不要自己乱设计新组件。</p>\n<p>2、训 RNN 不加 gradient clipping，导致训练一段时间以后 loss 突然变成 Nan。</p>\n<p>3、tying input &amp; output embedding（就是词向量层和输出 softmax 前的矩阵共享参数，在语言模型或机器翻译中常用）时学习率需要设置得非常小，不然容易 Nan。</p>\n<p>4.1、在数据集很大的情况下，一上来就跑全量数据。建议先用 1/100、1/10 的数据跑一跑，对模型性能和训练时间有个底。</p>\n<p>4.2认为网络层数越大越好。参数量什么的都不是大问题，在性能不丢的情况下，网络层数减到最小.（Captain Jack令言：你有95%概率不会使用超过40层的模型. ）</p>\n<p>5、只喜欢漂亮的模型结构，瞧不起调参数的论文/实验报告，<strong>看论文时经常不看超参数设置等细节</strong>。殊不知在自己没有太多资源实验的情况下，实验报告类文章简直是业界良心！<br>NLP 领域主要推荐以下几篇：<br>Regularizing and Optimizing LSTM Language Models（LSTM 的训练技巧）<br>Massive Exploration of Neural Machine Translation Architectures（NMT 里各个超参的影响）<br>Training Tips for the Transformer Model（训练 Transformer 时会发生的各种现象）<br>RoBERTa: A Robustly Optimized BERT Pretraining Approach（BERT 预训练技巧，虽然跟大部分人没啥关系）<br>CV 我不算太熟，不过也可以勉强推荐几篇：</p>\n<p><a href=\"https://arxiv.org/pdf/1706.02677.pdf\">Training ImageNet in 1 Hour（大批量训练技巧）</a><br><a href=\"https://openaccess.thecvf.com/content_CVPR_2019/papers/He_Bag_of_Tricks_for_Image_Classification_with_Convolutional_Neural_Networks_CVPR_2019_paper.pdf\">Bag of Tricks for Image Classification with Convolutional Neural Networks（各种训练技巧集大成）</a><br><a href=\"https://arxiv.org/pdf/1905.11946.pdf\">EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks（当前对参数利用最有效的 CNN）</a></p>\n<p>6、对于loss这种受 batch size、sequence length 各种因素影响的数字，人是没有数感的，建议首先计算一下 per token loss（如果是多任务，可以每个任务单独算；类似地，某些 CV 任务可以计算 per pixel loss），心里有点感觉。<strong>脱离损失函数的形式谈学习率没有意义</strong>（例如单是对 batch size 求和或者取平均这个差异就会使梯度差成百上千倍）。<br>在确定初始学习率的时候，从一个很小的值（例如 1e-7）开始，然后<strong>每一步指数增大学习率（例如扩大1.05 倍）进行训练。</strong>训练几百步应该能观察到损失函数随训练步数呈对勾形，选择损失下降最快那一段的学习率即可。<br>(Captain Jack令言：<strong>观察loss胜于观察准确率</strong><br>准确率虽然是评测指标, 但是训练过程中还是要注意loss的. 你会发现有些情况下, 准确率是突变的, 原来一直是0, 可能保持上千迭代, 然后突然变1. 要是因为这个你提前中断训练了, 只有老天替你惋惜了. 而loss是不会有这么诡异的情况发生的, 毕竟优化目标是loss.<br>给NN一点时间, 要根据任务留给NN的学习一定空间. 不能说前面一段时间没起色就不管了. 有些情况下就是前面一段时间看不出起色, 然后开始稳定学习.）</p>\n<p>7.1、优化器<strong>只推荐</strong> Momentum 和 Adam。在这些方面做尝试意义不大，如果性能提升反倒可能说明模型不成熟。</p>\n<p>7.2、<strong>Adam 可以解决一堆奇奇怪怪的问题</strong>（有时 loss 降不下去，换 Adam 瞬间就好了），<strong>也可以带来一堆奇奇怪怪的问题</strong>（比如单词词频差异很大，当前 batch 没有的单词的词向量也被更新；再比如Adam和L2正则结合产生的复杂效果）。用的时候要胆大心细，万一遇到问题找各种魔改 Adam（比如 <a href=\"https://www.zhihu.com/question/265357659/answer/580469438\">MaskedAdam</a>, AdamW 啥的）抢救。</p>\n<p>8、subword 总是会很稳定地涨点，只管用就对了。</p>\n<p>9、<strong>GPU 上报错时尽量放在 CPU 上重跑</strong>，错误信息更友好。例如 “ERROR:tensorflow:Model diverged with loss = NaN” 其实很有可能是输入 ID 超出了 softmax 词表的范围。</p>\n<p><strong>10、别没耐心</strong>！<br><strong>有些指标是有滞后性的，需要等训练一段时间才开始动。</strong>很多人训练几步看没什么效果就把程序停掉开始 debug 了，但其实代码毫无问题。如此反复好几天甚至一两周都在原地踏步，其实需要做的仅仅是让程序自个儿安安静静地跑上几个小时或者一天……</p>\n<h3 id=\"trick\"><a href=\"#trick\" class=\"headerlink\" title=\"trick\"></a>trick</h3><ul>\n<li><p> fine-tuning: 通常来说，直接把预训练模型来用效果不一定足够好，因此需要进行fine-tuning（微调）。fine-tuning需要冻结网络的前几层参数，只更新网络结构的后面几层和最后的全连接层，这样效果会更好。</p>\n</li>\n<li><p>  Learning rate:在迁移学习的微调过程中一般不建议使用过大的学习率，通常来说1e-5是比较合适的选择。</p>\n</li>\n</ul>\n<h4 id=\"迁移学习往往还和你的任务中的数据关系密切，可以考虑以下几种情况。\"><a href=\"#迁移学习往往还和你的任务中的数据关系密切，可以考虑以下几种情况。\" class=\"headerlink\" title=\"迁移学习往往还和你的任务中的数据关系密切，可以考虑以下几种情况。\"></a>迁移学习往往还和你的任务中的数据关系密切，可以考虑以下几种情况。</h4><ul>\n<li><h5 id=\"新的数据集较小，并且和pre-trained-model所使用的训练数据集相似度较高\"><a href=\"#新的数据集较小，并且和pre-trained-model所使用的训练数据集相似度较高\" class=\"headerlink\" title=\"新的数据集较小，并且和pre-trained model所使用的训练数据集相似度较高\"></a>新的数据集较小，并且和pre-trained model所使用的训练数据集相似度较高</h5><p>由于数据集较小，在进行finetune存在overfit的风险，又由于数据集和原始数据集相似度较高，因此二者不论是local feature还是global feature都比较相   近，所以此时最佳的方法是把CNN网络当做特征提取器然后训练一个分类器进行分类  </p>\n</li>\n<li><h5 id=\"新的数据集较大，并且和pre-trained-model所使用的训练数据集相似度较高：\"><a href=\"#新的数据集较大，并且和pre-trained-model所使用的训练数据集相似度较高：\" class=\"headerlink\" title=\"新的数据集较大，并且和pre-trained model所使用的训练数据集相似度较高：\"></a>新的数据集较大，并且和pre-trained model所使用的训练数据集相似度较高：</h5><p>很明显，此时我们不用担心overfit，因此对全部网络结构进行fine-tune是较好的。</p>\n</li>\n<li><h5 id=\"新的数据集较小，并且和pre-trained-model所使用的训练数据集差异很大：\"><a href=\"#新的数据集较小，并且和pre-trained-model所使用的训练数据集差异很大：\" class=\"headerlink\" title=\"新的数据集较小，并且和pre-trained model所使用的训练数据集差异很大：\"></a>新的数据集较小，并且和pre-trained model所使用的训练数据集差异很大：</h5><p>由于数据集较小，不适合进行fine-tune，由于数据集差异大，应该在单独训练网络结构中较高的层，前面几层local的就不用训练了，直接固定权值。在实际中，这种问题下较好的解决方案一般是从网络的某层开始取出特征，然后训练SVM分类器。 </p>\n</li>\n<li><h5 id=\"新的数据集较大，并且和pre-trained-model所使用的训练数据集差异很大：\"><a href=\"#新的数据集较大，并且和pre-trained-model所使用的训练数据集差异很大：\" class=\"headerlink\" title=\"新的数据集较大，并且和pre-trained model所使用的训练数据集差异很大：\"></a>新的数据集较大，并且和pre-trained model所使用的训练数据集差异很大：</h5><p>本来由于数据集较大，可以从头开始训练的，但是在实际中更偏向于训练整个pre-trained model的网络。</p>\n</li>\n</ul>\n<p>  ​    </p>\n","site":{"data":{"friends":[{"avatar":"http://image.luokangyuan.com/1_qq_27922023.jpg","name":"码酱","introduction":"我不是大佬，只是在追寻大佬的脚步","url":"http://luokangyuan.com/","title":"前去学习"},{"avatar":"http://image.luokangyuan.com/4027734.jpeg","name":"闪烁之狐","introduction":"编程界大佬，技术牛，人还特别好，不懂的都可以请教大佬","url":"https://blinkfox.github.io/","title":"前去学习"},{"avatar":"http://image.luokangyuan.com/avatar.jpg","name":"ja_rome","introduction":"平凡的脚步也可以走出伟大的行程","url":"https://me.csdn.net/jlh912008548","title":"前去学习"}]}},"excerpt":"","more":"<blockquote>\n<p>收集关于深度学习的调参的相关笔记，主要用于网络训练的微调。</p>\n</blockquote>\n<h3 id=\"训练技巧\"><a href=\"#训练技巧\" class=\"headerlink\" title=\"训练技巧\"></a><strong>训练技巧</strong></h3><p>1.要做<strong>梯度归一化</strong>,即算出来的梯度除以minibatch size</p>\n<p>2.clip c(梯度裁剪): 限制最大梯度,其实是value = sqrt(w1^2 +w2^2….),如果value超过了阈值,就算一个衰减系数,让value的值等于阈值: 5,10,15</p>\n<h5 id=\"3-防止过拟合\"><a href=\"#3-防止过拟合\" class=\"headerlink\" title=\"3.防止过拟合\"></a><strong>3.防止过拟合</strong></h5><p>​    一般常用的防止过拟合方法有使用<strong>L1正则项、L2正则项、dropout、提前终止、数据集扩充等</strong>。如果模型在训练集上表现比较好但在测试集上表现欠佳可以选择增大L1或L2正则的惩罚力度（<strong>L2正则经验上首选1.0</strong>，超过10很少见），或<strong>增大dropout的随机失活概率</strong>（经验首选0.5）；或者当随着训练的持续在测试集上不增反降时，使用提前终止训练的方法。当然<strong>最有效的还是增大训练集的规模</strong>，实在难以获得新数据也可以使用数据集增强的方法，比如CV任务可以对数据集进行裁剪、翻转、平移等方法进行数据集增强，这种方法往往都会提高最后模型的测试精度。<br>     dropout对小数据防止过拟合有很好的效果,值一般设为0.5,小数据上dropout+sgd。在大部分实验中，效果提升都非常明显.<strong>建议尝试</strong>。 dropout的位置比较有讲究, 对于RNN,建议放到输入-&gt;RNN与RNN-&gt;输出的位置.关于RNN如何用dropout,可以参考:<a href=\"https://link.zhihu.com/?target=http://arxiv.org/abs/1409.2329\">http://arxiv.org/abs/1409.2329</a>(Captain Jack令言:(不仅仅可以防止过拟合, 其实这相当于做人力成本最低的Ensemble, 当然, 训练起来会比没有Dropout的要慢一点, 同时网络参数你最好相应加一点, 对, 这会再慢一点).)</p>\n<p><strong>4.超参</strong> </p>\n<p>​    learning rate 最重要<strong>，推荐了解 cosine learning rate 和 cyclic learning rate，其次是 <strong>batchsize 和 weight decay</strong>。当你的模型还不错的时候，可以试着做数据增广和改损失函数锦上添花了。(罗浩ZJU令言：随着网络训练的进行，学习率要逐渐降下来；网络性能越好，学习率要越小（即越需要微调而非粗调)；batchsize通常影响没那么大，塞满卡就行，除了特殊的算法需要batch大一点)<br>​    adam,adadelta等,在小数据上,我这里实验的效果不如sgd, sgd收敛速度会慢一些，但是最终收敛后的结果，一般都比较好。</strong>如果使用sgd的话,可以选择从1.0或者0.1的学习率开始,隔一段时间,在验证集上检查一下,如果cost没有下降,就对学习率减半**. 我看过很多论文都这么搞,我自己实验的结果也很好. 当然,也可以先用ada系列先跑,最后快收敛的时候,更换成sgd继续训练.同样也会有提升.据说adadelta一般在分类问题上效果比较好，adam在生成问题上效果比较好。(Captain Jack令言：sgd adam 这些选择上, 看你个人选择. 一般对网络不是决定性的. 反正我无脑用sgd + momentum. ）</p>\n<p>5.<strong>激活函数</strong><br>    除了gate之类的地方,需要把输出限制成0-1之外,<strong>尽量不要用sigmoid</strong>,可以用tanh或者relu之类的激活函数.1. sigmoid函数在-4到4之外的区间梯度接近0，很容易造成梯度消失问题。2. 输入0均值，sigmoid函数的输出不是0均值的。（hzwer令言:虽然有至少十种激活函数，但在 Relu 外只推荐试一下 Swish。)</p>\n<p>6.BN层具有加速训练速度，有效防止梯度消失与梯度爆炸，具有防止过拟合的效果，所以构建网络时最好要加上这个组件。(Captain Jack令言：batch normalization我一直没用, 虽然我知道这个很好, 我不用仅仅是因为我懒. 所以要鼓励使用batch normalization.）</p>\n<p>7.如果你的模型包含全连接层（MLP），并且输入和输出大小一样，可以考虑将MLP替换成<strong>Highway Network</strong>,我尝试对结果有一点提升，建议作为最后提升模型的手段，原理很简单，就是给<strong>输出加了一个gate来控制信息的流动</strong>，详细介绍请参考论文: <a href=\"https://link.zhihu.com/?target=http://arxiv.org/abs/1505.00387\">http://arxiv.org/abs/1505.00387</a></p>\n<p>8.来自@张馨宇的技巧：<strong>一轮加正则，一轮不加正则，反复进行。</strong></p>\n<p><strong>9.Ensemble</strong><br>Ensemble是论文刷结果的终极核武器,深度学习中一般有以下几种方式<br>同样的参数,不同的初始化方式<br>不同的参数,通过cross-validation,选取最好的几组<br>同样的参数,模型训练的不同阶段，即不同迭代次数的模型。<br>不同的模型,进行线性融合. 例如RNN和传统模型.</p>\n<p><strong>10.自动调参方法</strong><br>（1）Grid Search：其原理就像是在数组里找最大值。缺点是太费时间了，特别像神经网络，一般尝试不了太多的参数组合。<br>（2）Random Search：经验上，Random Search比Gird Search更有效。实际操作的时候，一般也是先用Gird Search的方法，得到所有候选参数，然后每次从中随机选择进行训练。另外Random Search往往会和由粗到细的调参策略结合使用，即在效果比较好的参数附近进行更加精细的搜索。<br>（3）Bayesian Optimization：贝叶斯优化，考虑到了不同参数对应的 实验结果值，因此更节省时间，贝叶斯调参比Grid Search迭代次数少， 速度快；而且其针对非凸问题依然稳健。</p>\n<p><strong>11.Loss设计</strong><br>+ 一般来说分类就是Softmax, 回归就是L2的loss. 但是要注意loss的错误范围(主要是回归), 你预测一个label是10000的值, 模型输出0, 你算算这loss多大, 这还是单变量的情况下. 一般结果都是nan. 所以不仅仅输入要做normalization, 输出也要.<br>+ 多任务情况下, 各loss想法限制在一个量级上, 或者最终限制在一个量级上, 初期可以着重一个任务的loss。</p>\n<h3 id=\"网络结构设计（关于SE\"><a href=\"#网络结构设计（关于SE\" class=\"headerlink\" title=\"网络结构设计（关于SE)\"></a><strong>网络结构设计（关于SE)</strong></h3><p>SE在分类上是个涨点必备的工具，换言之，堆最高精度是一定要给每个block都加上它的，但是如果需要考虑时间，参数量和精度等的trade-off，无脑堆就没有意义了，这个时候应该要选择在合适的地方使用合适的模块。这个时候，<strong>推荐在block数量和添加SE上做权衡</strong>，即<strong>给部分blcok加上SE，同时砍掉一些block来加速</strong>，这样可以在精度差不多的情况下减少一些参数量。当然inference时间这个事需要看具体的应用平台对SE的实现，就是GAP和FC的速度，这就具体问题具体分析了。<strong>有余力有卡的人，可以迁移某种NAS方法来做这个的搜索。</strong><br>参考自：<br>你有哪些deep learning（rnn、cnn）调参的经验？ - 萧瑟的回答 - 知乎 <a href=\"https://www.zhihu.com/question/41631631/answer/94816420\">https://www.zhihu.com/question/41631631/answer/94816420</a><br>你有哪些deep learning（rnn、cnn）调参的经验？ - Towser的回答 - 知乎 <a href=\"https://www.zhihu.com/question/41631631/answer/862075836\">https://www.zhihu.com/question/41631631/answer/862075836</a><br>你有哪些deep learning（rnn、cnn）调参的经验？ - 罗浩.ZJU的回答 - 知乎 <a href=\"https://www.zhihu.com/question/41631631/answer/216788968\">https://www.zhihu.com/question/41631631/answer/216788968</a><br>你有哪些deep learning（rnn、cnn）调参的经验？ - 京东白条的回答 - 知乎 <a href=\"https://www.zhihu.com/question/41631631/answer/776852832\">https://www.zhihu.com/question/4163</a></p>\n<blockquote>\n<p>所谓SE：SENet是Squeeze-and-Excitation Networks的简称，拿到了ImageNet2017分类比赛冠军，其效果得到了认可，其提出的SE模块思想简单，易于实现，并且很容易可以加载到现有的网络模型框架中。*<u>SENet主要是学习了channel之间的相关性，筛选出了针对通道的注意力</u>*，稍微增加了一点计算量，但是效果比较好。</p>\n</blockquote>\n<p>对于CNN网络来说，其核心计算是卷积算子，其通过卷积核从输入特征图学习到新特征图。从本质上讲，卷积是对一个局部区域进行特征融合，这包括空间上（H和W维度）以及通道间（C维度）的特征融合。</p>\n<p><img src=\"https://img-blog.csdnimg.cn/2019051415564658.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L25pamlheWFuMTIz,size_16,color_FFFFFF,t_70\"></p>\n<p>卷积实际上是对<u>局部区域</u>进行的特征融合。 这也导致了普通卷积神经网络的感受野不大，当然你也可以设计出更多的通道特征来增加这个，但是这样做导致了计算量大大的增加。因此为了空间上融合更多特征融合，或者是提取多尺度空间信息。也提出了许多不同的方法如Inception网络的多分支结构。对于channel维度的特征融合，卷积操作基本上默认对输入特征图的所有channel进行融合。<u>而SENet网络的创新点在于关注channel之间的关系，希望模型可以自动学习到不同channel特征的重要程度</u>。为此，SENet提出了Squeeze-and-Excitation (SE)模块，如下图所示：</p>\n<p><img src=\"https://img-blog.csdnimg.cn/20190514160215998.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L25pamlheWFuMTIz,size_16,color_FFFFFF,t_70\"></p>\n<h3 id=\"反面训诫\"><a href=\"#反面训诫\" class=\"headerlink\" title=\"反面训诫\"></a>反面训诫</h3><p>1.1、一上来就自己动手写模型。<br>建议首先用<strong>成熟的开源项目及其默认配置</strong>（例如 Gluon 对经典模型的各种复现、各个著名模型作者自己放出来的代码仓库）在自己的数据集上跑一遍，在等程序运行结束的时间里仔细研究一下代码里的各种细节，最后再自己写或者改代码。</p>\n<p>1.2、<strong>不推荐做人肉模型设计</strong>，比如把某层卷积改大一点，或者微调一下通道数。除非有特别 insight，不要自己乱设计新组件。</p>\n<p>2、训 RNN 不加 gradient clipping，导致训练一段时间以后 loss 突然变成 Nan。</p>\n<p>3、tying input &amp; output embedding（就是词向量层和输出 softmax 前的矩阵共享参数，在语言模型或机器翻译中常用）时学习率需要设置得非常小，不然容易 Nan。</p>\n<p>4.1、在数据集很大的情况下，一上来就跑全量数据。建议先用 1/100、1/10 的数据跑一跑，对模型性能和训练时间有个底。</p>\n<p>4.2认为网络层数越大越好。参数量什么的都不是大问题，在性能不丢的情况下，网络层数减到最小.（Captain Jack令言：你有95%概率不会使用超过40层的模型. ）</p>\n<p>5、只喜欢漂亮的模型结构，瞧不起调参数的论文/实验报告，<strong>看论文时经常不看超参数设置等细节</strong>。殊不知在自己没有太多资源实验的情况下，实验报告类文章简直是业界良心！<br>NLP 领域主要推荐以下几篇：<br>Regularizing and Optimizing LSTM Language Models（LSTM 的训练技巧）<br>Massive Exploration of Neural Machine Translation Architectures（NMT 里各个超参的影响）<br>Training Tips for the Transformer Model（训练 Transformer 时会发生的各种现象）<br>RoBERTa: A Robustly Optimized BERT Pretraining Approach（BERT 预训练技巧，虽然跟大部分人没啥关系）<br>CV 我不算太熟，不过也可以勉强推荐几篇：</p>\n<p><a href=\"https://arxiv.org/pdf/1706.02677.pdf\">Training ImageNet in 1 Hour（大批量训练技巧）</a><br><a href=\"https://openaccess.thecvf.com/content_CVPR_2019/papers/He_Bag_of_Tricks_for_Image_Classification_with_Convolutional_Neural_Networks_CVPR_2019_paper.pdf\">Bag of Tricks for Image Classification with Convolutional Neural Networks（各种训练技巧集大成）</a><br><a href=\"https://arxiv.org/pdf/1905.11946.pdf\">EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks（当前对参数利用最有效的 CNN）</a></p>\n<p>6、对于loss这种受 batch size、sequence length 各种因素影响的数字，人是没有数感的，建议首先计算一下 per token loss（如果是多任务，可以每个任务单独算；类似地，某些 CV 任务可以计算 per pixel loss），心里有点感觉。<strong>脱离损失函数的形式谈学习率没有意义</strong>（例如单是对 batch size 求和或者取平均这个差异就会使梯度差成百上千倍）。<br>在确定初始学习率的时候，从一个很小的值（例如 1e-7）开始，然后<strong>每一步指数增大学习率（例如扩大1.05 倍）进行训练。</strong>训练几百步应该能观察到损失函数随训练步数呈对勾形，选择损失下降最快那一段的学习率即可。<br>(Captain Jack令言：<strong>观察loss胜于观察准确率</strong><br>准确率虽然是评测指标, 但是训练过程中还是要注意loss的. 你会发现有些情况下, 准确率是突变的, 原来一直是0, 可能保持上千迭代, 然后突然变1. 要是因为这个你提前中断训练了, 只有老天替你惋惜了. 而loss是不会有这么诡异的情况发生的, 毕竟优化目标是loss.<br>给NN一点时间, 要根据任务留给NN的学习一定空间. 不能说前面一段时间没起色就不管了. 有些情况下就是前面一段时间看不出起色, 然后开始稳定学习.）</p>\n<p>7.1、优化器<strong>只推荐</strong> Momentum 和 Adam。在这些方面做尝试意义不大，如果性能提升反倒可能说明模型不成熟。</p>\n<p>7.2、<strong>Adam 可以解决一堆奇奇怪怪的问题</strong>（有时 loss 降不下去，换 Adam 瞬间就好了），<strong>也可以带来一堆奇奇怪怪的问题</strong>（比如单词词频差异很大，当前 batch 没有的单词的词向量也被更新；再比如Adam和L2正则结合产生的复杂效果）。用的时候要胆大心细，万一遇到问题找各种魔改 Adam（比如 <a href=\"https://www.zhihu.com/question/265357659/answer/580469438\">MaskedAdam</a>, AdamW 啥的）抢救。</p>\n<p>8、subword 总是会很稳定地涨点，只管用就对了。</p>\n<p>9、<strong>GPU 上报错时尽量放在 CPU 上重跑</strong>，错误信息更友好。例如 “ERROR:tensorflow:Model diverged with loss = NaN” 其实很有可能是输入 ID 超出了 softmax 词表的范围。</p>\n<p><strong>10、别没耐心</strong>！<br><strong>有些指标是有滞后性的，需要等训练一段时间才开始动。</strong>很多人训练几步看没什么效果就把程序停掉开始 debug 了，但其实代码毫无问题。如此反复好几天甚至一两周都在原地踏步，其实需要做的仅仅是让程序自个儿安安静静地跑上几个小时或者一天……</p>\n<h3 id=\"trick\"><a href=\"#trick\" class=\"headerlink\" title=\"trick\"></a>trick</h3><ul>\n<li><p> fine-tuning: 通常来说，直接把预训练模型来用效果不一定足够好，因此需要进行fine-tuning（微调）。fine-tuning需要冻结网络的前几层参数，只更新网络结构的后面几层和最后的全连接层，这样效果会更好。</p>\n</li>\n<li><p>  Learning rate:在迁移学习的微调过程中一般不建议使用过大的学习率，通常来说1e-5是比较合适的选择。</p>\n</li>\n</ul>\n<h4 id=\"迁移学习往往还和你的任务中的数据关系密切，可以考虑以下几种情况。\"><a href=\"#迁移学习往往还和你的任务中的数据关系密切，可以考虑以下几种情况。\" class=\"headerlink\" title=\"迁移学习往往还和你的任务中的数据关系密切，可以考虑以下几种情况。\"></a>迁移学习往往还和你的任务中的数据关系密切，可以考虑以下几种情况。</h4><ul>\n<li><h5 id=\"新的数据集较小，并且和pre-trained-model所使用的训练数据集相似度较高\"><a href=\"#新的数据集较小，并且和pre-trained-model所使用的训练数据集相似度较高\" class=\"headerlink\" title=\"新的数据集较小，并且和pre-trained model所使用的训练数据集相似度较高\"></a>新的数据集较小，并且和pre-trained model所使用的训练数据集相似度较高</h5><p>由于数据集较小，在进行finetune存在overfit的风险，又由于数据集和原始数据集相似度较高，因此二者不论是local feature还是global feature都比较相   近，所以此时最佳的方法是把CNN网络当做特征提取器然后训练一个分类器进行分类  </p>\n</li>\n<li><h5 id=\"新的数据集较大，并且和pre-trained-model所使用的训练数据集相似度较高：\"><a href=\"#新的数据集较大，并且和pre-trained-model所使用的训练数据集相似度较高：\" class=\"headerlink\" title=\"新的数据集较大，并且和pre-trained model所使用的训练数据集相似度较高：\"></a>新的数据集较大，并且和pre-trained model所使用的训练数据集相似度较高：</h5><p>很明显，此时我们不用担心overfit，因此对全部网络结构进行fine-tune是较好的。</p>\n</li>\n<li><h5 id=\"新的数据集较小，并且和pre-trained-model所使用的训练数据集差异很大：\"><a href=\"#新的数据集较小，并且和pre-trained-model所使用的训练数据集差异很大：\" class=\"headerlink\" title=\"新的数据集较小，并且和pre-trained model所使用的训练数据集差异很大：\"></a>新的数据集较小，并且和pre-trained model所使用的训练数据集差异很大：</h5><p>由于数据集较小，不适合进行fine-tune，由于数据集差异大，应该在单独训练网络结构中较高的层，前面几层local的就不用训练了，直接固定权值。在实际中，这种问题下较好的解决方案一般是从网络的某层开始取出特征，然后训练SVM分类器。 </p>\n</li>\n<li><h5 id=\"新的数据集较大，并且和pre-trained-model所使用的训练数据集差异很大：\"><a href=\"#新的数据集较大，并且和pre-trained-model所使用的训练数据集差异很大：\" class=\"headerlink\" title=\"新的数据集较大，并且和pre-trained model所使用的训练数据集差异很大：\"></a>新的数据集较大，并且和pre-trained model所使用的训练数据集差异很大：</h5><p>本来由于数据集较大，可以从头开始训练的，但是在实际中更偏向于训练整个pre-trained model的网络。</p>\n</li>\n</ul>\n<p>  ​    </p>\n"},{"title":"docker相关命令","date":"2021-08-10T07:15:16.000Z","_content":"\n>简要介绍Docker，记录Docker常用命令使用方法。\n>\n>搬运自师兄的博客 又见苍岚 ：https://www.zywvvd.com/2020/05/06/docker/docker_usage/\n\n### Docker 简介\n\n> **Docker 属于 Linux 容器的一种封装，提供简单易用的容器使用接口。**Docker 将应用程序与该程序的依赖，打包在一个文件里面。运行这个文件，就会生成一个虚拟容器。程序在这个虚拟容器里运行，就好像在真实的物理机上运行一样。有了 Docker，就不用担心环境问题。\n\n### Docker 使用流程\n\n- [安装docker](https://docs.docker.com/desktop/)\n- 创建Image\n- 从Image创建Container\n- 在Container中工作\n- 将在Container中做的修改提交给Image\n- 销毁Container\n\n### 命令介绍\n\n- 拉取 image\n\n```\ndocker image pull [docker-url]\n```\n\n- 获取docker images 列表\n\n```\ndocker images\n或\ndocker image ls\n```\n\n- 建立container （nvidia docker)\n\n```\nNV_GPU=[gpu_num] nvidia-docker run -it --name [container_name] --shm-size=[shm_size] --rm -v [current_dir]:[container_dir] -p [current_port]:[container_port] [image_name]:[image_tag]  [command] \n```\n实例：\n```\nnvidia-docker run -it --name mlfan --shm-size=10g -v /disk/fanmeilin:/workspace/fanmeilin -p 12345:22 -p 12346:8080 -p 12347:5678 tf-1.14-2.0-2.1:1.0 bash\n```\n<font color=SlateBlue size=4>注意不要加 --rm  否则载在container stop之后会自动删除此容器</font>\n\n> NV_GPU: container中可见的GPU，如果不设置可见所有GPU\n>\n> -it: 将容器的 Shell 映射到当前的 Shell，然后你在本机窗口输入的命令，就会传入容器\n>\n> –name: 容器名称，如果不设置会随机分配一个名字\n>\n> –shm-size: 容器共享内存大小设置。如果不设置默认大小64M，对于需要使用共享内存的情况往往是不够用的，如果设置为10g，这样配置： `--ssh-size=\"10g\"`\n>\n> –rm: 容器关闭后自动删除，如果不设置容器不会自动删除\n>\n> -v: 驱动器映射，将本机的目录映射到容器的指定文件夹中；需要说明的是，在主机文件夹中的挂载目录在容器中是可见的；需要再说明的是容器启动时主机挂载的目录容器是见不到的；最后说明，容器关闭再打开就可以看到主机挂载的所有文件夹了。\n>\n> -p: 暴漏容器的端口到本机的端口上，例如用于ssh连接容器时需要将容器的22端口暴露到主机的端口上(比如3721)，则可以设置 `-p 3721:22`\n>\n> image_name, image_tag: 这是docker镜像的名称与标记，如果使用本机镜像可以在docker images列表中查询到\n>\n> command: 启动容器后内部执行的第一个命令，一般为 `/bin/bash`\n\n- 查询container列表\n\n```\ndocker container ls --all\n```\n\n> –all: 加上该参数会显示没有在运行的容器，不加的话仅显示运行中的容器\n\n- 停止指定的容器运行\n\n```\ndocker container kill [containerID]\ndocker stop [containerID]\n```\n\n> `docker container kill`命令终止容器运行，相当于向容器里面的主进程发出 SIGKILL 信号。`docker container stop`命令相当于向容器里面的主进程发出 SIGTERM 信号，然后过一段时间再发出 SIGKILL 信号。\n\n- 启动停止的容器\n\n```\ndocker start [containerID]\n```\n\n- 重启运行的容器\n\n```\ndocker restart [containerID]\n```\n\n- 删除指定的容器文件（仅在停止运行时可用）\n\n```\ndocker container rm [containerID]\n```\n\n- 查看容器输出\n\n```\ndocker container logs [containerID]\n```\n\n- 启动容器的一个终端\n\n```\ndocker exec -it [containerID] /bin/bash\n```\n\n> 此种方法启动的终端，即使退出也不会关闭容器\n>\n> 相反 - 如果直接通过端口映射连接 docker 建立的ssh链接，窗口退出后该终端的工作也会一同停止\n\n- 进入容器的主终端\n\n```\ndocker attach [containerID]\n```\n\n> 连接到容器的主终端，该终端退出后容器关闭。\n>\n> 如果不希望退出后关闭，可以加入选项 `--sig-proxy=false`\n\n- 退出终端\n\n```\nctrl p + ctrl q\n```\n\n> 可以在退出终端的同时保持终端继续工作\n\n- 退出容器\n\n```\nexit\n```\n\n> 在容器中运行此命令\n\n- 拷贝容器里的文件到本机\n\n```\ndocker container cp [containerID]:[/path/to/file]\n```\n\n- 提交容器修改到镜像\n\n```\ndocker commit -a [name] -m [comments] -p  [containerID[:TAG]]\n```\n\n> -a: 提交的镜像作者\n>\n> -m: 提交时的说明文字\n>\n> -p: 在commit时，将容器暂停\n\n- 删除镜像\n\n```\ndocker rmi [image]\n```\n\n> 或\n\n```\ndocker image rm [image]\n```\n\n> 支持的子命令如下：\n\n- `-f, -force`: 强制删除镜像，即便有容器引用该镜像；\n- `-no-prune`: 不要删除未带标签的父镜像；\n\n### 参考资料\n\n- http://www.ruanyifeng.com/blog/2018/02/docker-tutorial.html\n- https://www.runoob.com/docker/docker-tutorial.html\n","source":"_posts/docker/docker-intro.md","raw":"---\ntitle: docker相关命令\ndate: 2021-08-10 15:15:16\ntags: [docker,远程配置]\ncategories: docker\n---\n\n>简要介绍Docker，记录Docker常用命令使用方法。\n>\n>搬运自师兄的博客 又见苍岚 ：https://www.zywvvd.com/2020/05/06/docker/docker_usage/\n\n### Docker 简介\n\n> **Docker 属于 Linux 容器的一种封装，提供简单易用的容器使用接口。**Docker 将应用程序与该程序的依赖，打包在一个文件里面。运行这个文件，就会生成一个虚拟容器。程序在这个虚拟容器里运行，就好像在真实的物理机上运行一样。有了 Docker，就不用担心环境问题。\n\n### Docker 使用流程\n\n- [安装docker](https://docs.docker.com/desktop/)\n- 创建Image\n- 从Image创建Container\n- 在Container中工作\n- 将在Container中做的修改提交给Image\n- 销毁Container\n\n### 命令介绍\n\n- 拉取 image\n\n```\ndocker image pull [docker-url]\n```\n\n- 获取docker images 列表\n\n```\ndocker images\n或\ndocker image ls\n```\n\n- 建立container （nvidia docker)\n\n```\nNV_GPU=[gpu_num] nvidia-docker run -it --name [container_name] --shm-size=[shm_size] --rm -v [current_dir]:[container_dir] -p [current_port]:[container_port] [image_name]:[image_tag]  [command] \n```\n实例：\n```\nnvidia-docker run -it --name mlfan --shm-size=10g -v /disk/fanmeilin:/workspace/fanmeilin -p 12345:22 -p 12346:8080 -p 12347:5678 tf-1.14-2.0-2.1:1.0 bash\n```\n<font color=SlateBlue size=4>注意不要加 --rm  否则载在container stop之后会自动删除此容器</font>\n\n> NV_GPU: container中可见的GPU，如果不设置可见所有GPU\n>\n> -it: 将容器的 Shell 映射到当前的 Shell，然后你在本机窗口输入的命令，就会传入容器\n>\n> –name: 容器名称，如果不设置会随机分配一个名字\n>\n> –shm-size: 容器共享内存大小设置。如果不设置默认大小64M，对于需要使用共享内存的情况往往是不够用的，如果设置为10g，这样配置： `--ssh-size=\"10g\"`\n>\n> –rm: 容器关闭后自动删除，如果不设置容器不会自动删除\n>\n> -v: 驱动器映射，将本机的目录映射到容器的指定文件夹中；需要说明的是，在主机文件夹中的挂载目录在容器中是可见的；需要再说明的是容器启动时主机挂载的目录容器是见不到的；最后说明，容器关闭再打开就可以看到主机挂载的所有文件夹了。\n>\n> -p: 暴漏容器的端口到本机的端口上，例如用于ssh连接容器时需要将容器的22端口暴露到主机的端口上(比如3721)，则可以设置 `-p 3721:22`\n>\n> image_name, image_tag: 这是docker镜像的名称与标记，如果使用本机镜像可以在docker images列表中查询到\n>\n> command: 启动容器后内部执行的第一个命令，一般为 `/bin/bash`\n\n- 查询container列表\n\n```\ndocker container ls --all\n```\n\n> –all: 加上该参数会显示没有在运行的容器，不加的话仅显示运行中的容器\n\n- 停止指定的容器运行\n\n```\ndocker container kill [containerID]\ndocker stop [containerID]\n```\n\n> `docker container kill`命令终止容器运行，相当于向容器里面的主进程发出 SIGKILL 信号。`docker container stop`命令相当于向容器里面的主进程发出 SIGTERM 信号，然后过一段时间再发出 SIGKILL 信号。\n\n- 启动停止的容器\n\n```\ndocker start [containerID]\n```\n\n- 重启运行的容器\n\n```\ndocker restart [containerID]\n```\n\n- 删除指定的容器文件（仅在停止运行时可用）\n\n```\ndocker container rm [containerID]\n```\n\n- 查看容器输出\n\n```\ndocker container logs [containerID]\n```\n\n- 启动容器的一个终端\n\n```\ndocker exec -it [containerID] /bin/bash\n```\n\n> 此种方法启动的终端，即使退出也不会关闭容器\n>\n> 相反 - 如果直接通过端口映射连接 docker 建立的ssh链接，窗口退出后该终端的工作也会一同停止\n\n- 进入容器的主终端\n\n```\ndocker attach [containerID]\n```\n\n> 连接到容器的主终端，该终端退出后容器关闭。\n>\n> 如果不希望退出后关闭，可以加入选项 `--sig-proxy=false`\n\n- 退出终端\n\n```\nctrl p + ctrl q\n```\n\n> 可以在退出终端的同时保持终端继续工作\n\n- 退出容器\n\n```\nexit\n```\n\n> 在容器中运行此命令\n\n- 拷贝容器里的文件到本机\n\n```\ndocker container cp [containerID]:[/path/to/file]\n```\n\n- 提交容器修改到镜像\n\n```\ndocker commit -a [name] -m [comments] -p  [containerID[:TAG]]\n```\n\n> -a: 提交的镜像作者\n>\n> -m: 提交时的说明文字\n>\n> -p: 在commit时，将容器暂停\n\n- 删除镜像\n\n```\ndocker rmi [image]\n```\n\n> 或\n\n```\ndocker image rm [image]\n```\n\n> 支持的子命令如下：\n\n- `-f, -force`: 强制删除镜像，即便有容器引用该镜像；\n- `-no-prune`: 不要删除未带标签的父镜像；\n\n### 参考资料\n\n- http://www.ruanyifeng.com/blog/2018/02/docker-tutorial.html\n- https://www.runoob.com/docker/docker-tutorial.html\n","slug":"docker/docker-intro","published":1,"updated":"2021-08-11T03:54:14.658Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cksa5ksen0009a0x4gq7n8cx7","content":"<blockquote>\n<p>简要介绍Docker，记录Docker常用命令使用方法。</p>\n<p>搬运自师兄的博客 又见苍岚 ：<a href=\"https://www.zywvvd.com/2020/05/06/docker/docker_usage/\">https://www.zywvvd.com/2020/05/06/docker/docker_usage/</a></p>\n</blockquote>\n<h3 id=\"Docker-简介\"><a href=\"#Docker-简介\" class=\"headerlink\" title=\"Docker 简介\"></a>Docker 简介</h3><blockquote>\n<p><strong>Docker 属于 Linux 容器的一种封装，提供简单易用的容器使用接口。</strong>Docker 将应用程序与该程序的依赖，打包在一个文件里面。运行这个文件，就会生成一个虚拟容器。程序在这个虚拟容器里运行，就好像在真实的物理机上运行一样。有了 Docker，就不用担心环境问题。</p>\n</blockquote>\n<h3 id=\"Docker-使用流程\"><a href=\"#Docker-使用流程\" class=\"headerlink\" title=\"Docker 使用流程\"></a>Docker 使用流程</h3><ul>\n<li><a href=\"https://docs.docker.com/desktop/\">安装docker</a></li>\n<li>创建Image</li>\n<li>从Image创建Container</li>\n<li>在Container中工作</li>\n<li>将在Container中做的修改提交给Image</li>\n<li>销毁Container</li>\n</ul>\n<h3 id=\"命令介绍\"><a href=\"#命令介绍\" class=\"headerlink\" title=\"命令介绍\"></a>命令介绍</h3><ul>\n<li>拉取 image</li>\n</ul>\n<figure class=\"highlight apache\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs apache\"><span class=\"hljs-attribute\">docker</span> image pull<span class=\"hljs-meta\"> [docker-url]</span><br></code></pre></td></tr></tbody></table></figure>\n\n<ul>\n<li>获取docker images 列表</li>\n</ul>\n<figure class=\"highlight mel\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mel\">docker images<br>或<br>docker <span class=\"hljs-keyword\">image</span> <span class=\"hljs-keyword\">ls</span><br></code></pre></td></tr></tbody></table></figure>\n\n<ul>\n<li>建立container （nvidia docker)</li>\n</ul>\n<figure class=\"highlight stylus\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs stylus\">NV_GPU=<span class=\"hljs-selector-attr\">[gpu_num]</span> nvidia-docker run -it --name <span class=\"hljs-selector-attr\">[container_name]</span> --shm-size=<span class=\"hljs-selector-attr\">[shm_size]</span> --rm -v <span class=\"hljs-selector-attr\">[current_dir]</span>:<span class=\"hljs-selector-attr\">[container_dir]</span> -<span class=\"hljs-selector-tag\">p</span> <span class=\"hljs-selector-attr\">[current_port]</span>:<span class=\"hljs-selector-attr\">[container_port]</span> <span class=\"hljs-selector-attr\">[image_name]</span>:<span class=\"hljs-selector-attr\">[image_tag]</span>  <span class=\"hljs-selector-attr\">[command]</span> <br></code></pre></td></tr></tbody></table></figure>\n<p>实例：</p>\n<figure class=\"highlight apache\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs apache\"><span class=\"hljs-attribute\">nvidia</span>-docker run -it --name mlfan --shm-size=<span class=\"hljs-number\">10</span>g -v /disk/fanmeilin:/workspace/fanmeilin -p <span class=\"hljs-number\">12345</span>:<span class=\"hljs-number\">22</span> -p <span class=\"hljs-number\">12346</span>:<span class=\"hljs-number\">8080</span> -p <span class=\"hljs-number\">12347</span>:<span class=\"hljs-number\">5678</span> tf-<span class=\"hljs-number\">1</span>.<span class=\"hljs-number\">14</span>-<span class=\"hljs-number\">2</span>.<span class=\"hljs-number\">0</span>-<span class=\"hljs-number\">2</span>.<span class=\"hljs-number\">1</span>:<span class=\"hljs-number\">1</span>.<span class=\"hljs-number\">0</span> bash<br></code></pre></td></tr></tbody></table></figure>\n<p><font color=\"SlateBlue\" size=\"4\">注意不要加 –rm&nbsp; 否则载在container stop之后会自动删除此容器</font></p>\n<blockquote>\n<p>NV_GPU: container中可见的GPU，如果不设置可见所有GPU</p>\n<p>-it: 将容器的 Shell 映射到当前的 Shell，然后你在本机窗口输入的命令，就会传入容器</p>\n<p>–name: 容器名称，如果不设置会随机分配一个名字</p>\n<p>–shm-size: 容器共享内存大小设置。如果不设置默认大小64M，对于需要使用共享内存的情况往往是不够用的，如果设置为10g，这样配置： <code>--ssh-size=\"10g\"</code></p>\n<p>–rm: 容器关闭后自动删除，如果不设置容器不会自动删除</p>\n<p>-v: 驱动器映射，将本机的目录映射到容器的指定文件夹中；需要说明的是，在主机文件夹中的挂载目录在容器中是可见的；需要再说明的是容器启动时主机挂载的目录容器是见不到的；最后说明，容器关闭再打开就可以看到主机挂载的所有文件夹了。</p>\n<p>-p: 暴漏容器的端口到本机的端口上，例如用于ssh连接容器时需要将容器的22端口暴露到主机的端口上(比如3721)，则可以设置 <code>-p 3721:22</code></p>\n<p>image_name, image_tag: 这是docker镜像的名称与标记，如果使用本机镜像可以在docker images列表中查询到</p>\n<p>command: 启动容器后内部执行的第一个命令，一般为 <code>/bin/bash</code></p>\n</blockquote>\n<ul>\n<li>查询container列表</li>\n</ul>\n<figure class=\"highlight jboss-cli\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs jboss-cli\">docker container <span class=\"hljs-keyword\">ls</span> <span class=\"hljs-params\">--all</span><br></code></pre></td></tr></tbody></table></figure>\n\n<blockquote>\n<p>–all: 加上该参数会显示没有在运行的容器，不加的话仅显示运行中的容器</p>\n</blockquote>\n<ul>\n<li>停止指定的容器运行</li>\n</ul>\n<figure class=\"highlight inform7\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs inform7\">docker <span class=\"hljs-keyword\">container</span> kill <span class=\"hljs-comment\">[containerID]</span><br>docker stop <span class=\"hljs-comment\">[containerID]</span><br></code></pre></td></tr></tbody></table></figure>\n\n<blockquote>\n<p><code>docker container kill</code>命令终止容器运行，相当于向容器里面的主进程发出 SIGKILL 信号。<code>docker container stop</code>命令相当于向容器里面的主进程发出 SIGTERM 信号，然后过一段时间再发出 SIGKILL 信号。</p>\n</blockquote>\n<ul>\n<li>启动停止的容器</li>\n</ul>\n<figure class=\"highlight apache\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs apache\"><span class=\"hljs-attribute\">docker</span> start<span class=\"hljs-meta\"> [containerID]</span><br></code></pre></td></tr></tbody></table></figure>\n\n<ul>\n<li>重启运行的容器</li>\n</ul>\n<figure class=\"highlight apache\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs apache\"><span class=\"hljs-attribute\">docker</span> restart<span class=\"hljs-meta\"> [containerID]</span><br></code></pre></td></tr></tbody></table></figure>\n\n<ul>\n<li>删除指定的容器文件（仅在停止运行时可用）</li>\n</ul>\n<figure class=\"highlight inform7\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs inform7\">docker <span class=\"hljs-keyword\">container</span> rm <span class=\"hljs-comment\">[containerID]</span><br></code></pre></td></tr></tbody></table></figure>\n\n<ul>\n<li>查看容器输出</li>\n</ul>\n<figure class=\"highlight inform7\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs inform7\">docker <span class=\"hljs-keyword\">container</span> logs <span class=\"hljs-comment\">[containerID]</span><br></code></pre></td></tr></tbody></table></figure>\n\n<ul>\n<li>启动容器的一个终端</li>\n</ul>\n<figure class=\"highlight awk\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs awk\">docker exec -it [containerID] <span class=\"hljs-regexp\">/bin/</span>bash<br></code></pre></td></tr></tbody></table></figure>\n\n<blockquote>\n<p>此种方法启动的终端，即使退出也不会关闭容器</p>\n<p>相反 - 如果直接通过端口映射连接 docker 建立的ssh链接，窗口退出后该终端的工作也会一同停止</p>\n</blockquote>\n<ul>\n<li>进入容器的主终端</li>\n</ul>\n<figure class=\"highlight apache\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs apache\"><span class=\"hljs-attribute\">docker</span> attach<span class=\"hljs-meta\"> [containerID]</span><br></code></pre></td></tr></tbody></table></figure>\n\n<blockquote>\n<p>连接到容器的主终端，该终端退出后容器关闭。</p>\n<p>如果不希望退出后关闭，可以加入选项 <code>--sig-proxy=false</code></p>\n</blockquote>\n<ul>\n<li>退出终端</li>\n</ul>\n<figure class=\"highlight css\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs css\">ctrl <span class=\"hljs-selector-tag\">p</span> + ctrl <span class=\"hljs-selector-tag\">q</span><br></code></pre></td></tr></tbody></table></figure>\n\n<blockquote>\n<p>可以在退出终端的同时保持终端继续工作</p>\n</blockquote>\n<ul>\n<li>退出容器</li>\n</ul>\n<figure class=\"highlight awk\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs awk\"><span class=\"hljs-keyword\">exit</span><br></code></pre></td></tr></tbody></table></figure>\n\n<blockquote>\n<p>在容器中运行此命令</p>\n</blockquote>\n<ul>\n<li>拷贝容器里的文件到本机</li>\n</ul>\n<figure class=\"highlight gradle\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs gradle\">docker container cp [containerID]:[<span class=\"hljs-regexp\">/path/</span>to/<span class=\"hljs-keyword\">file</span>]<br></code></pre></td></tr></tbody></table></figure>\n\n<ul>\n<li>提交容器修改到镜像</li>\n</ul>\n<figure class=\"highlight css\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs css\">docker commit -<span class=\"hljs-selector-tag\">a</span> <span class=\"hljs-selector-attr\">[name]</span> -m <span class=\"hljs-selector-attr\">[comments]</span> -<span class=\"hljs-selector-tag\">p</span>  <span class=\"hljs-selector-attr\">[containerID[:TAG]</span>]<br></code></pre></td></tr></tbody></table></figure>\n\n<blockquote>\n<p>-a: 提交的镜像作者</p>\n<p>-m: 提交时的说明文字</p>\n<p>-p: 在commit时，将容器暂停</p>\n</blockquote>\n<ul>\n<li>删除镜像</li>\n</ul>\n<figure class=\"highlight apache\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs apache\"><span class=\"hljs-attribute\">docker</span> rmi<span class=\"hljs-meta\"> [image]</span><br></code></pre></td></tr></tbody></table></figure>\n\n<blockquote>\n<p>或</p>\n</blockquote>\n<figure class=\"highlight arduino\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs arduino\">docker image rm [image]<br></code></pre></td></tr></tbody></table></figure>\n\n<blockquote>\n<p>支持的子命令如下：</p>\n</blockquote>\n<ul>\n<li><code>-f, -force</code>: 强制删除镜像，即便有容器引用该镜像；</li>\n<li><code>-no-prune</code>: 不要删除未带标签的父镜像；</li>\n</ul>\n<h3 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h3><ul>\n<li><a href=\"http://www.ruanyifeng.com/blog/2018/02/docker-tutorial.html\">http://www.ruanyifeng.com/blog/2018/02/docker-tutorial.html</a></li>\n<li><a href=\"https://www.runoob.com/docker/docker-tutorial.html\">https://www.runoob.com/docker/docker-tutorial.html</a></li>\n</ul>\n","site":{"data":{"friends":[{"avatar":"http://image.luokangyuan.com/1_qq_27922023.jpg","name":"码酱","introduction":"我不是大佬，只是在追寻大佬的脚步","url":"http://luokangyuan.com/","title":"前去学习"},{"avatar":"http://image.luokangyuan.com/4027734.jpeg","name":"闪烁之狐","introduction":"编程界大佬，技术牛，人还特别好，不懂的都可以请教大佬","url":"https://blinkfox.github.io/","title":"前去学习"},{"avatar":"http://image.luokangyuan.com/avatar.jpg","name":"ja_rome","introduction":"平凡的脚步也可以走出伟大的行程","url":"https://me.csdn.net/jlh912008548","title":"前去学习"}]}},"excerpt":"","more":"<blockquote>\n<p>简要介绍Docker，记录Docker常用命令使用方法。</p>\n<p>搬运自师兄的博客 又见苍岚 ：<a href=\"https://www.zywvvd.com/2020/05/06/docker/docker_usage/\">https://www.zywvvd.com/2020/05/06/docker/docker_usage/</a></p>\n</blockquote>\n<h3 id=\"Docker-简介\"><a href=\"#Docker-简介\" class=\"headerlink\" title=\"Docker 简介\"></a>Docker 简介</h3><blockquote>\n<p><strong>Docker 属于 Linux 容器的一种封装，提供简单易用的容器使用接口。</strong>Docker 将应用程序与该程序的依赖，打包在一个文件里面。运行这个文件，就会生成一个虚拟容器。程序在这个虚拟容器里运行，就好像在真实的物理机上运行一样。有了 Docker，就不用担心环境问题。</p>\n</blockquote>\n<h3 id=\"Docker-使用流程\"><a href=\"#Docker-使用流程\" class=\"headerlink\" title=\"Docker 使用流程\"></a>Docker 使用流程</h3><ul>\n<li><a href=\"https://docs.docker.com/desktop/\">安装docker</a></li>\n<li>创建Image</li>\n<li>从Image创建Container</li>\n<li>在Container中工作</li>\n<li>将在Container中做的修改提交给Image</li>\n<li>销毁Container</li>\n</ul>\n<h3 id=\"命令介绍\"><a href=\"#命令介绍\" class=\"headerlink\" title=\"命令介绍\"></a>命令介绍</h3><ul>\n<li>拉取 image</li>\n</ul>\n<figure class=\"highlight apache\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs apache\"><span class=\"hljs-attribute\">docker</span> image pull<span class=\"hljs-meta\"> [docker-url]</span><br></code></pre></td></tr></table></figure>\n\n<ul>\n<li>获取docker images 列表</li>\n</ul>\n<figure class=\"highlight mel\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mel\">docker images<br>或<br>docker <span class=\"hljs-keyword\">image</span> <span class=\"hljs-keyword\">ls</span><br></code></pre></td></tr></table></figure>\n\n<ul>\n<li>建立container （nvidia docker)</li>\n</ul>\n<figure class=\"highlight stylus\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs stylus\">NV_GPU=<span class=\"hljs-selector-attr\">[gpu_num]</span> nvidia-docker run -it --name <span class=\"hljs-selector-attr\">[container_name]</span> --shm-size=<span class=\"hljs-selector-attr\">[shm_size]</span> --rm -v <span class=\"hljs-selector-attr\">[current_dir]</span>:<span class=\"hljs-selector-attr\">[container_dir]</span> -<span class=\"hljs-selector-tag\">p</span> <span class=\"hljs-selector-attr\">[current_port]</span>:<span class=\"hljs-selector-attr\">[container_port]</span> <span class=\"hljs-selector-attr\">[image_name]</span>:<span class=\"hljs-selector-attr\">[image_tag]</span>  <span class=\"hljs-selector-attr\">[command]</span> <br></code></pre></td></tr></table></figure>\n<p>实例：</p>\n<figure class=\"highlight apache\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs apache\"><span class=\"hljs-attribute\">nvidia</span>-docker run -it --name mlfan --shm-size=<span class=\"hljs-number\">10</span>g -v /disk/fanmeilin:/workspace/fanmeilin -p <span class=\"hljs-number\">12345</span>:<span class=\"hljs-number\">22</span> -p <span class=\"hljs-number\">12346</span>:<span class=\"hljs-number\">8080</span> -p <span class=\"hljs-number\">12347</span>:<span class=\"hljs-number\">5678</span> tf-<span class=\"hljs-number\">1</span>.<span class=\"hljs-number\">14</span>-<span class=\"hljs-number\">2</span>.<span class=\"hljs-number\">0</span>-<span class=\"hljs-number\">2</span>.<span class=\"hljs-number\">1</span>:<span class=\"hljs-number\">1</span>.<span class=\"hljs-number\">0</span> bash<br></code></pre></td></tr></table></figure>\n<p><font color=SlateBlue size=4>注意不要加 –rm  否则载在container stop之后会自动删除此容器</font></p>\n<blockquote>\n<p>NV_GPU: container中可见的GPU，如果不设置可见所有GPU</p>\n<p>-it: 将容器的 Shell 映射到当前的 Shell，然后你在本机窗口输入的命令，就会传入容器</p>\n<p>–name: 容器名称，如果不设置会随机分配一个名字</p>\n<p>–shm-size: 容器共享内存大小设置。如果不设置默认大小64M，对于需要使用共享内存的情况往往是不够用的，如果设置为10g，这样配置： <code>--ssh-size=&quot;10g&quot;</code></p>\n<p>–rm: 容器关闭后自动删除，如果不设置容器不会自动删除</p>\n<p>-v: 驱动器映射，将本机的目录映射到容器的指定文件夹中；需要说明的是，在主机文件夹中的挂载目录在容器中是可见的；需要再说明的是容器启动时主机挂载的目录容器是见不到的；最后说明，容器关闭再打开就可以看到主机挂载的所有文件夹了。</p>\n<p>-p: 暴漏容器的端口到本机的端口上，例如用于ssh连接容器时需要将容器的22端口暴露到主机的端口上(比如3721)，则可以设置 <code>-p 3721:22</code></p>\n<p>image_name, image_tag: 这是docker镜像的名称与标记，如果使用本机镜像可以在docker images列表中查询到</p>\n<p>command: 启动容器后内部执行的第一个命令，一般为 <code>/bin/bash</code></p>\n</blockquote>\n<ul>\n<li>查询container列表</li>\n</ul>\n<figure class=\"highlight jboss-cli\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs jboss-cli\">docker container <span class=\"hljs-keyword\">ls</span> <span class=\"hljs-params\">--all</span><br></code></pre></td></tr></table></figure>\n\n<blockquote>\n<p>–all: 加上该参数会显示没有在运行的容器，不加的话仅显示运行中的容器</p>\n</blockquote>\n<ul>\n<li>停止指定的容器运行</li>\n</ul>\n<figure class=\"highlight inform7\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs inform7\">docker <span class=\"hljs-keyword\">container</span> kill <span class=\"hljs-comment\">[containerID]</span><br>docker stop <span class=\"hljs-comment\">[containerID]</span><br></code></pre></td></tr></table></figure>\n\n<blockquote>\n<p><code>docker container kill</code>命令终止容器运行，相当于向容器里面的主进程发出 SIGKILL 信号。<code>docker container stop</code>命令相当于向容器里面的主进程发出 SIGTERM 信号，然后过一段时间再发出 SIGKILL 信号。</p>\n</blockquote>\n<ul>\n<li>启动停止的容器</li>\n</ul>\n<figure class=\"highlight apache\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs apache\"><span class=\"hljs-attribute\">docker</span> start<span class=\"hljs-meta\"> [containerID]</span><br></code></pre></td></tr></table></figure>\n\n<ul>\n<li>重启运行的容器</li>\n</ul>\n<figure class=\"highlight apache\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs apache\"><span class=\"hljs-attribute\">docker</span> restart<span class=\"hljs-meta\"> [containerID]</span><br></code></pre></td></tr></table></figure>\n\n<ul>\n<li>删除指定的容器文件（仅在停止运行时可用）</li>\n</ul>\n<figure class=\"highlight inform7\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs inform7\">docker <span class=\"hljs-keyword\">container</span> rm <span class=\"hljs-comment\">[containerID]</span><br></code></pre></td></tr></table></figure>\n\n<ul>\n<li>查看容器输出</li>\n</ul>\n<figure class=\"highlight inform7\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs inform7\">docker <span class=\"hljs-keyword\">container</span> logs <span class=\"hljs-comment\">[containerID]</span><br></code></pre></td></tr></table></figure>\n\n<ul>\n<li>启动容器的一个终端</li>\n</ul>\n<figure class=\"highlight awk\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs awk\">docker exec -it [containerID] <span class=\"hljs-regexp\">/bin/</span>bash<br></code></pre></td></tr></table></figure>\n\n<blockquote>\n<p>此种方法启动的终端，即使退出也不会关闭容器</p>\n<p>相反 - 如果直接通过端口映射连接 docker 建立的ssh链接，窗口退出后该终端的工作也会一同停止</p>\n</blockquote>\n<ul>\n<li>进入容器的主终端</li>\n</ul>\n<figure class=\"highlight apache\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs apache\"><span class=\"hljs-attribute\">docker</span> attach<span class=\"hljs-meta\"> [containerID]</span><br></code></pre></td></tr></table></figure>\n\n<blockquote>\n<p>连接到容器的主终端，该终端退出后容器关闭。</p>\n<p>如果不希望退出后关闭，可以加入选项 <code>--sig-proxy=false</code></p>\n</blockquote>\n<ul>\n<li>退出终端</li>\n</ul>\n<figure class=\"highlight css\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs css\">ctrl <span class=\"hljs-selector-tag\">p</span> + ctrl <span class=\"hljs-selector-tag\">q</span><br></code></pre></td></tr></table></figure>\n\n<blockquote>\n<p>可以在退出终端的同时保持终端继续工作</p>\n</blockquote>\n<ul>\n<li>退出容器</li>\n</ul>\n<figure class=\"highlight awk\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs awk\"><span class=\"hljs-keyword\">exit</span><br></code></pre></td></tr></table></figure>\n\n<blockquote>\n<p>在容器中运行此命令</p>\n</blockquote>\n<ul>\n<li>拷贝容器里的文件到本机</li>\n</ul>\n<figure class=\"highlight gradle\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs gradle\">docker container cp [containerID]:[<span class=\"hljs-regexp\">/path/</span>to/<span class=\"hljs-keyword\">file</span>]<br></code></pre></td></tr></table></figure>\n\n<ul>\n<li>提交容器修改到镜像</li>\n</ul>\n<figure class=\"highlight css\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs css\">docker commit -<span class=\"hljs-selector-tag\">a</span> <span class=\"hljs-selector-attr\">[name]</span> -m <span class=\"hljs-selector-attr\">[comments]</span> -<span class=\"hljs-selector-tag\">p</span>  <span class=\"hljs-selector-attr\">[containerID[:TAG]</span>]<br></code></pre></td></tr></table></figure>\n\n<blockquote>\n<p>-a: 提交的镜像作者</p>\n<p>-m: 提交时的说明文字</p>\n<p>-p: 在commit时，将容器暂停</p>\n</blockquote>\n<ul>\n<li>删除镜像</li>\n</ul>\n<figure class=\"highlight apache\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs apache\"><span class=\"hljs-attribute\">docker</span> rmi<span class=\"hljs-meta\"> [image]</span><br></code></pre></td></tr></table></figure>\n\n<blockquote>\n<p>或</p>\n</blockquote>\n<figure class=\"highlight arduino\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs arduino\">docker image rm [image]<br></code></pre></td></tr></table></figure>\n\n<blockquote>\n<p>支持的子命令如下：</p>\n</blockquote>\n<ul>\n<li><code>-f, -force</code>: 强制删除镜像，即便有容器引用该镜像；</li>\n<li><code>-no-prune</code>: 不要删除未带标签的父镜像；</li>\n</ul>\n<h3 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h3><ul>\n<li><a href=\"http://www.ruanyifeng.com/blog/2018/02/docker-tutorial.html\">http://www.ruanyifeng.com/blog/2018/02/docker-tutorial.html</a></li>\n<li><a href=\"https://www.runoob.com/docker/docker-tutorial.html\">https://www.runoob.com/docker/docker-tutorial.html</a></li>\n</ul>\n"},{"title":"docker的ssh相关配置","date":"2021-08-10T09:07:14.000Z","_content":"\n>参考师兄博客：https://www.zywvvd.com/2020/11/02/windows/win_ssh_linux_docker/win_ssh_linux_docker/\n\n> ssh是较可靠，专为远程登录会话和其他网络服务提供安全性的协议，广泛用于远程登录的场景，也是远程调试代码的神兵利器。在开发中经常会在服务器启动自己的 docker 容器进行开发，又需要调试代码，vim的调试环境配置起来门槛又太高。于是就有了使用Windows直接ssh打通docker进行调试的需求。本文记录Windows远程登录Linux服务器docker容器的方法。\n\n## 环境说明\n\n- 登录主机操作系统 Win 10\n- 被登录主机操作系统 docker container in Linux\n- 主机与被登录主机（此处指服务器，不是docker）网络联通，IP在同一网段\n- 服务器与docker的IP在同一网段\n\n## 配置方法\n\n### 建立docker与Linux服务器的端口映射\n\n> ssh协议链接时默认使用22端口，Windows与docker的端口往往不能直接进行映射（很可能不在一个网段），因此需要将docker的22端口映射到Linux服务器的某个端口，此时需要在建立docker容器时进行[配置](https://www.zywvvd.com/2020/05/14/coding/environment/wingide-remote-docker/wingide-remote-docker/#docker配置)：\n\n```\n$ docker run -it --name vvd -p 3721:22 -v /root/tmp:/root/tmp my_docker bash\n```\n\n- 其中 `-p` 的部分表示将本机（服务器）的3721端口映射到容器的22端口。\n\n### 容器内部安装ssh服务\n\n> 需要在被登录的容器内部建立并启动ssh服务。\n\n- 首先需要安装：\n\n```\napt-get update\napt-get install openssh-server\napt-get install openssh-client\n```\n\n- 安装完成后需要容器每次启动时自动运行相关服务，可以在 `~/.bashrc`中加入：\n\n```\n/etc/init.d/ssh start\n```\n\n> 这样就保证了docker容器自动启动该服务。\n\n- 查看ssh运行状态\n\n```\n/etc/init.d/ssh status\n```\n\n> 如果是 `* sshd is running` 说明ssh正常运行\n\n### 修改容器内root用户登录设置\n\n> 有的容器默认不支持root用户远程使用ssh协议进行密码登录的，此时需要更改设置。\n\n- 打开 `/etc/ssh/sshd_config`文件：\n\n```\n# PermitRootLogin prohibit-password # 默认打开 禁止root用户使用密码登陆，需要将其注释\nRSAAuthentication yes #启用 RSA 认证\nPubkeyAuthentication yes #启用公钥私钥配对认证方式\nPermitRootLogin yes #允许root用户使用ssh登录\n```\n\n- 将 `PermitRootLogin` 设置为 yes\n\n### 修改root密码\n\n> 远程登录时需要使用系统的用户密码，我们就直接使用root用户登录好了，需要设置新建容器的密码：\n\n```\npasswd root\n```\n\n### 设置SSH\n\n- [本地生成ssh key](https://www.zywvvd.com/2020/02/23/git/link_github/Git-connect-remote-pos/#创建SSH密钥)\n- 将.pub 内容复制粘贴加入到远程 ~/.ssh/authorized_keys\n\n### SSH连接服务器\n\n> 需要用户名（被登录端用户）与被登录的主机ip和端口号\n>\n> 例如： 用户名- root ip：192.168.10.12 端口映射为 3721\n\n- linux\n\n```\nssh root@192.168.10.12:3721\n```\n\n- Windows\n\n```\nssh -p 3721 root@192.168.10.12\n```\n\n![img](https://photos.zywvvd.com/images_matrixtime/20201102200256.png)\n\n- 如果不清楚Linux系统端口映射配置情况：\n\n```\niptables -t nat -L -n\n```\n\n### X-shell配置\n\n> 命令行ssh登录成功后就可以在X-shell中建立配置信息方便地连接了。\n\n- 新建会话，填写名称、IP、端口号（我们刚刚配置过的）：\n\n![img](https://photos.zywvvd.com/images_matrixtime/20201102200522.png)\n\n- 用户身份认证，填入用户名密码（刚刚配置过的）：\n\n![img](https://photos.zywvvd.com/images_matrixtime/20201102200640.png)\n\n- 随后就可以使用该会话直接登录docker容器了，为远程调试打下了坚实的基础：\n\n![img](https://photos.zywvvd.com/images_matrixtime/20201102200804.png)\n\n### 填坑\n\n- ssh: Could not resolve hostname 192.168.10.12:3721: Name or service not known\n\n  > 这是在Windows中使用了Linux格式的SSH登录命令导致的解析错误\n  >\n  > 将命令语法更换为Windows的格式即可\n\n- root 用户无论如何密码不被接受\n\n  > 需要在被登录主机 /etc/ssh/sshd_config 中设置：\n  >\n  > ```\n  > # PermitRootLogin prohibit-password # 默认打开 禁止root用户使用密码登陆，需要将其注释\n  > RSAAuthentication yes #启用 RSA 认证\n  > PubkeyAuthentication yes #启用公钥私钥配对认证方式\n  > PermitRootLogin yes #允许root用户使用ssh登录\n  > ```\n  >\n  > - 重点：**PermitRootLogin yes**\n\n- Connection to 192.168.10.12 closed.\n\n- 或\n\n- Connection closed by foreign host.\n\n  > 意思是 断开主机链接了，出现这种问题，跟你的IPTABLES，防火墙什么的都没关系。\n  >\n  > 造成这个原 因是因为原来连接到SSHD服务器进程的22端口，当你的客户端突然断开时，服务器端的TCP连接就处于一个半打开状态。当下一次同一客户机再次建立 TCP连接时，服务器检测到这个半打开的TCP连接，并向客户机回传一个置位RST的TCP报文，客户机就会显示connection closed by foreign host。\n  > 这是TCP协议本身的一个保护措施，并不是什么错误，你只要再重新连接服务器就能连上。\n  >\n  > ——— http://www.pooy.net/connection-closed-foreign-host.html\n  >\n  > 总结一下解决方案： **关机重启**\n\n### 关于ssh的相关配置\n\n#### 修改配置文件\n\n```\ncd /etc/ssh\nvi ssh_config #可设置ssh的默认端口（22）\nvi sshd_config\n```\n\nssh_config和sshd_config都是ssh服务器的配置文件，二者区别在于，前者是针对客户端的配置文件，后者则是针对服务端的配置文件。两个配置文件都允许你通过设置不同的选项来改变客户端程序的运行方式。\n\n#### 重启ssh服务\n\n```\nservice sshd restart\n```\n\n如果报错 sshd: unrecognized service 则需要开启ssh服务。\n\n```\n/etc/init.d/ssh start\n```\n\n## vscode连接远程服务器\n\n- 正确的ssh服务\n\n- 密码设置完成（passwd root）\n\n### 安装插件\n\n- 安装 Remote Development 插件\n\n  > 会自动安装 Remote-WSL / Containers / SSH 等插件。\n\n![img](https://photos.zywvvd.com/images_matrixtime/20201028143530.png)\n\n### 配置主机信息\n\n> ctrl + shift + p\n\n![img](https://photos.zywvvd.com/images_matrixtime/20201028174129.png)\n\n![img](https://photos.zywvvd.com/images_matrixtime/20201028175152.png)\n\n```\nHost Enter\n  HostName 192.168.10.15\n  Port 12345\n  User root\n  IdentityFile ~\\.ssh\\id_rsa\n  IdentitiesOnly yes\n```\n\n### vs code 连接远程主机\n\n![img](https://photos.zywvvd.com/images_matrixtime/20201028175324.png)\n\n> 之后选择目标主机的操作系统。\n\n- 成功连接到远程主机：\n\n- 打开文件夹运行程序时，选择使用的Python环境：\n\n#### 相对路径的设置\n\n在读取文件时，可能使用相对路径出现错误。\n\n> python 插件设置中没有设置`终端执行命令时使用文件的路径代替现在打开的目录`。\n\n### 解决方案\n\n- 搜索配置 `execute in file`：\n\n![img](https://photos.zywvvd.com/win11-mt/20210717114300.png)\n","source":"_posts/docker/docker-ssh.md","raw":"---\ntitle: docker的ssh相关配置\ntags: [docker,远程配置,ssh]\ncategories: docker\ndate: 2021-08-10 17:07:14\n---\n\n>参考师兄博客：https://www.zywvvd.com/2020/11/02/windows/win_ssh_linux_docker/win_ssh_linux_docker/\n\n> ssh是较可靠，专为远程登录会话和其他网络服务提供安全性的协议，广泛用于远程登录的场景，也是远程调试代码的神兵利器。在开发中经常会在服务器启动自己的 docker 容器进行开发，又需要调试代码，vim的调试环境配置起来门槛又太高。于是就有了使用Windows直接ssh打通docker进行调试的需求。本文记录Windows远程登录Linux服务器docker容器的方法。\n\n## 环境说明\n\n- 登录主机操作系统 Win 10\n- 被登录主机操作系统 docker container in Linux\n- 主机与被登录主机（此处指服务器，不是docker）网络联通，IP在同一网段\n- 服务器与docker的IP在同一网段\n\n## 配置方法\n\n### 建立docker与Linux服务器的端口映射\n\n> ssh协议链接时默认使用22端口，Windows与docker的端口往往不能直接进行映射（很可能不在一个网段），因此需要将docker的22端口映射到Linux服务器的某个端口，此时需要在建立docker容器时进行[配置](https://www.zywvvd.com/2020/05/14/coding/environment/wingide-remote-docker/wingide-remote-docker/#docker配置)：\n\n```\n$ docker run -it --name vvd -p 3721:22 -v /root/tmp:/root/tmp my_docker bash\n```\n\n- 其中 `-p` 的部分表示将本机（服务器）的3721端口映射到容器的22端口。\n\n### 容器内部安装ssh服务\n\n> 需要在被登录的容器内部建立并启动ssh服务。\n\n- 首先需要安装：\n\n```\napt-get update\napt-get install openssh-server\napt-get install openssh-client\n```\n\n- 安装完成后需要容器每次启动时自动运行相关服务，可以在 `~/.bashrc`中加入：\n\n```\n/etc/init.d/ssh start\n```\n\n> 这样就保证了docker容器自动启动该服务。\n\n- 查看ssh运行状态\n\n```\n/etc/init.d/ssh status\n```\n\n> 如果是 `* sshd is running` 说明ssh正常运行\n\n### 修改容器内root用户登录设置\n\n> 有的容器默认不支持root用户远程使用ssh协议进行密码登录的，此时需要更改设置。\n\n- 打开 `/etc/ssh/sshd_config`文件：\n\n```\n# PermitRootLogin prohibit-password # 默认打开 禁止root用户使用密码登陆，需要将其注释\nRSAAuthentication yes #启用 RSA 认证\nPubkeyAuthentication yes #启用公钥私钥配对认证方式\nPermitRootLogin yes #允许root用户使用ssh登录\n```\n\n- 将 `PermitRootLogin` 设置为 yes\n\n### 修改root密码\n\n> 远程登录时需要使用系统的用户密码，我们就直接使用root用户登录好了，需要设置新建容器的密码：\n\n```\npasswd root\n```\n\n### 设置SSH\n\n- [本地生成ssh key](https://www.zywvvd.com/2020/02/23/git/link_github/Git-connect-remote-pos/#创建SSH密钥)\n- 将.pub 内容复制粘贴加入到远程 ~/.ssh/authorized_keys\n\n### SSH连接服务器\n\n> 需要用户名（被登录端用户）与被登录的主机ip和端口号\n>\n> 例如： 用户名- root ip：192.168.10.12 端口映射为 3721\n\n- linux\n\n```\nssh root@192.168.10.12:3721\n```\n\n- Windows\n\n```\nssh -p 3721 root@192.168.10.12\n```\n\n![img](https://photos.zywvvd.com/images_matrixtime/20201102200256.png)\n\n- 如果不清楚Linux系统端口映射配置情况：\n\n```\niptables -t nat -L -n\n```\n\n### X-shell配置\n\n> 命令行ssh登录成功后就可以在X-shell中建立配置信息方便地连接了。\n\n- 新建会话，填写名称、IP、端口号（我们刚刚配置过的）：\n\n![img](https://photos.zywvvd.com/images_matrixtime/20201102200522.png)\n\n- 用户身份认证，填入用户名密码（刚刚配置过的）：\n\n![img](https://photos.zywvvd.com/images_matrixtime/20201102200640.png)\n\n- 随后就可以使用该会话直接登录docker容器了，为远程调试打下了坚实的基础：\n\n![img](https://photos.zywvvd.com/images_matrixtime/20201102200804.png)\n\n### 填坑\n\n- ssh: Could not resolve hostname 192.168.10.12:3721: Name or service not known\n\n  > 这是在Windows中使用了Linux格式的SSH登录命令导致的解析错误\n  >\n  > 将命令语法更换为Windows的格式即可\n\n- root 用户无论如何密码不被接受\n\n  > 需要在被登录主机 /etc/ssh/sshd_config 中设置：\n  >\n  > ```\n  > # PermitRootLogin prohibit-password # 默认打开 禁止root用户使用密码登陆，需要将其注释\n  > RSAAuthentication yes #启用 RSA 认证\n  > PubkeyAuthentication yes #启用公钥私钥配对认证方式\n  > PermitRootLogin yes #允许root用户使用ssh登录\n  > ```\n  >\n  > - 重点：**PermitRootLogin yes**\n\n- Connection to 192.168.10.12 closed.\n\n- 或\n\n- Connection closed by foreign host.\n\n  > 意思是 断开主机链接了，出现这种问题，跟你的IPTABLES，防火墙什么的都没关系。\n  >\n  > 造成这个原 因是因为原来连接到SSHD服务器进程的22端口，当你的客户端突然断开时，服务器端的TCP连接就处于一个半打开状态。当下一次同一客户机再次建立 TCP连接时，服务器检测到这个半打开的TCP连接，并向客户机回传一个置位RST的TCP报文，客户机就会显示connection closed by foreign host。\n  > 这是TCP协议本身的一个保护措施，并不是什么错误，你只要再重新连接服务器就能连上。\n  >\n  > ——— http://www.pooy.net/connection-closed-foreign-host.html\n  >\n  > 总结一下解决方案： **关机重启**\n\n### 关于ssh的相关配置\n\n#### 修改配置文件\n\n```\ncd /etc/ssh\nvi ssh_config #可设置ssh的默认端口（22）\nvi sshd_config\n```\n\nssh_config和sshd_config都是ssh服务器的配置文件，二者区别在于，前者是针对客户端的配置文件，后者则是针对服务端的配置文件。两个配置文件都允许你通过设置不同的选项来改变客户端程序的运行方式。\n\n#### 重启ssh服务\n\n```\nservice sshd restart\n```\n\n如果报错 sshd: unrecognized service 则需要开启ssh服务。\n\n```\n/etc/init.d/ssh start\n```\n\n## vscode连接远程服务器\n\n- 正确的ssh服务\n\n- 密码设置完成（passwd root）\n\n### 安装插件\n\n- 安装 Remote Development 插件\n\n  > 会自动安装 Remote-WSL / Containers / SSH 等插件。\n\n![img](https://photos.zywvvd.com/images_matrixtime/20201028143530.png)\n\n### 配置主机信息\n\n> ctrl + shift + p\n\n![img](https://photos.zywvvd.com/images_matrixtime/20201028174129.png)\n\n![img](https://photos.zywvvd.com/images_matrixtime/20201028175152.png)\n\n```\nHost Enter\n  HostName 192.168.10.15\n  Port 12345\n  User root\n  IdentityFile ~\\.ssh\\id_rsa\n  IdentitiesOnly yes\n```\n\n### vs code 连接远程主机\n\n![img](https://photos.zywvvd.com/images_matrixtime/20201028175324.png)\n\n> 之后选择目标主机的操作系统。\n\n- 成功连接到远程主机：\n\n- 打开文件夹运行程序时，选择使用的Python环境：\n\n#### 相对路径的设置\n\n在读取文件时，可能使用相对路径出现错误。\n\n> python 插件设置中没有设置`终端执行命令时使用文件的路径代替现在打开的目录`。\n\n### 解决方案\n\n- 搜索配置 `execute in file`：\n\n![img](https://photos.zywvvd.com/win11-mt/20210717114300.png)\n","slug":"docker/docker-ssh","published":1,"updated":"2021-08-10T09:23:49.324Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cksa5kseo000ba0x4ffzx0scr","content":"<blockquote>\n<p>参考师兄博客：<a href=\"https://www.zywvvd.com/2020/11/02/windows/win_ssh_linux_docker/win_ssh_linux_docker/\">https://www.zywvvd.com/2020/11/02/windows/win_ssh_linux_docker/win_ssh_linux_docker/</a></p>\n</blockquote>\n<blockquote>\n<p>ssh是较可靠，专为远程登录会话和其他网络服务提供安全性的协议，广泛用于远程登录的场景，也是远程调试代码的神兵利器。在开发中经常会在服务器启动自己的 docker 容器进行开发，又需要调试代码，vim的调试环境配置起来门槛又太高。于是就有了使用Windows直接ssh打通docker进行调试的需求。本文记录Windows远程登录Linux服务器docker容器的方法。</p>\n</blockquote>\n<h2 id=\"环境说明\"><a href=\"#环境说明\" class=\"headerlink\" title=\"环境说明\"></a>环境说明</h2><ul>\n<li>登录主机操作系统 Win 10</li>\n<li>被登录主机操作系统 docker container in Linux</li>\n<li>主机与被登录主机（此处指服务器，不是docker）网络联通，IP在同一网段</li>\n<li>服务器与docker的IP在同一网段</li>\n</ul>\n<h2 id=\"配置方法\"><a href=\"#配置方法\" class=\"headerlink\" title=\"配置方法\"></a>配置方法</h2><h3 id=\"建立docker与Linux服务器的端口映射\"><a href=\"#建立docker与Linux服务器的端口映射\" class=\"headerlink\" title=\"建立docker与Linux服务器的端口映射\"></a>建立docker与Linux服务器的端口映射</h3><blockquote>\n<p>ssh协议链接时默认使用22端口，Windows与docker的端口往往不能直接进行映射（很可能不在一个网段），因此需要将docker的22端口映射到Linux服务器的某个端口，此时需要在建立docker容器时进行<a href=\"https://www.zywvvd.com/2020/05/14/coding/environment/wingide-remote-docker/wingide-remote-docker/#docker%E9%85%8D%E7%BD%AE\">配置</a>：</p>\n</blockquote>\n<figure class=\"highlight awk\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs awk\">$ docker run -it --name vvd -p <span class=\"hljs-number\">3721</span>:<span class=\"hljs-number\">22</span> -v <span class=\"hljs-regexp\">/root/</span>tmp:<span class=\"hljs-regexp\">/root/</span>tmp my_docker bash<br></code></pre></td></tr></tbody></table></figure>\n\n<ul>\n<li>其中 <code>-p</code> 的部分表示将本机（服务器）的3721端口映射到容器的22端口。</li>\n</ul>\n<h3 id=\"容器内部安装ssh服务\"><a href=\"#容器内部安装ssh服务\" class=\"headerlink\" title=\"容器内部安装ssh服务\"></a>容器内部安装ssh服务</h3><blockquote>\n<p>需要在被登录的容器内部建立并启动ssh服务。</p>\n</blockquote>\n<ul>\n<li>首先需要安装：</li>\n</ul>\n<figure class=\"highlight routeros\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs routeros\">apt-<span class=\"hljs-builtin-name\">get</span> update<br>apt-<span class=\"hljs-builtin-name\">get</span> install openssh-server<br>apt-<span class=\"hljs-builtin-name\">get</span> install openssh-client<br></code></pre></td></tr></tbody></table></figure>\n\n<ul>\n<li>安装完成后需要容器每次启动时自动运行相关服务，可以在 <code>~/.bashrc</code>中加入：</li>\n</ul>\n<figure class=\"highlight awk\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs awk\"><span class=\"hljs-regexp\">/etc/i</span>nit.d/ssh start<br></code></pre></td></tr></tbody></table></figure>\n\n<blockquote>\n<p>这样就保证了docker容器自动启动该服务。</p>\n</blockquote>\n<ul>\n<li>查看ssh运行状态</li>\n</ul>\n<figure class=\"highlight awk\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs awk\"><span class=\"hljs-regexp\">/etc/i</span>nit.d/ssh status<br></code></pre></td></tr></tbody></table></figure>\n\n<blockquote>\n<p>如果是 <code>* sshd is running</code> 说明ssh正常运行</p>\n</blockquote>\n<h3 id=\"修改容器内root用户登录设置\"><a href=\"#修改容器内root用户登录设置\" class=\"headerlink\" title=\"修改容器内root用户登录设置\"></a>修改容器内root用户登录设置</h3><blockquote>\n<p>有的容器默认不支持root用户远程使用ssh协议进行密码登录的，此时需要更改设置。</p>\n</blockquote>\n<ul>\n<li>打开 <code>/etc/ssh/sshd_config</code>文件：</li>\n</ul>\n<figure class=\"highlight nginx\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs nginx\"><span class=\"hljs-comment\"># PermitRootLogin prohibit-password # 默认打开 禁止root用户使用密码登陆，需要将其注释</span><br><span class=\"hljs-attribute\">RSAAuthentication</span> <span class=\"hljs-literal\">yes</span> <span class=\"hljs-comment\">#启用 RSA 认证</span><br>PubkeyAuthentication <span class=\"hljs-literal\">yes</span> <span class=\"hljs-comment\">#启用公钥私钥配对认证方式</span><br>PermitRootLogin <span class=\"hljs-literal\">yes</span> <span class=\"hljs-comment\">#允许root用户使用ssh登录</span><br></code></pre></td></tr></tbody></table></figure>\n\n<ul>\n<li>将 <code>PermitRootLogin</code> 设置为 yes</li>\n</ul>\n<h3 id=\"修改root密码\"><a href=\"#修改root密码\" class=\"headerlink\" title=\"修改root密码\"></a>修改root密码</h3><blockquote>\n<p>远程登录时需要使用系统的用户密码，我们就直接使用root用户登录好了，需要设置新建容器的密码：</p>\n</blockquote>\n<figure class=\"highlight ebnf\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs ebnf\"><span class=\"hljs-attribute\">passwd root</span><br></code></pre></td></tr></tbody></table></figure>\n\n<h3 id=\"设置SSH\"><a href=\"#设置SSH\" class=\"headerlink\" title=\"设置SSH\"></a>设置SSH</h3><ul>\n<li><a href=\"https://www.zywvvd.com/2020/02/23/git/link_github/Git-connect-remote-pos/#%E5%88%9B%E5%BB%BASSH%E5%AF%86%E9%92%A5\">本地生成ssh key</a></li>\n<li>将.pub 内容复制粘贴加入到远程 ~/.ssh/authorized_keys</li>\n</ul>\n<h3 id=\"SSH连接服务器\"><a href=\"#SSH连接服务器\" class=\"headerlink\" title=\"SSH连接服务器\"></a>SSH连接服务器</h3><blockquote>\n<p>需要用户名（被登录端用户）与被登录的主机ip和端口号</p>\n<p>例如： 用户名- root ip：192.168.10.12 端口映射为 3721</p>\n</blockquote>\n<ul>\n<li>linux</li>\n</ul>\n<figure class=\"highlight nginx\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs nginx\"><span class=\"hljs-attribute\">ssh</span> root@<span class=\"hljs-number\">192.168.10.12:3721</span><br></code></pre></td></tr></tbody></table></figure>\n\n<ul>\n<li>Windows</li>\n</ul>\n<figure class=\"highlight apache\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs apache\"><span class=\"hljs-attribute\">ssh</span> -p <span class=\"hljs-number\">3721</span> root@<span class=\"hljs-number\">192.168.10.12</span><br></code></pre></td></tr></tbody></table></figure>\n\n<p><img src=\"https://photos.zywvvd.com/images_matrixtime/20201102200256.png\" alt=\"img\"></p>\n<ul>\n<li>如果不清楚Linux系统端口映射配置情况：</li>\n</ul>\n<figure class=\"highlight excel\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs excel\">iptables -<span class=\"hljs-built_in\">t</span> nat -L -<span class=\"hljs-built_in\">n</span><br></code></pre></td></tr></tbody></table></figure>\n\n<h3 id=\"X-shell配置\"><a href=\"#X-shell配置\" class=\"headerlink\" title=\"X-shell配置\"></a>X-shell配置</h3><blockquote>\n<p>命令行ssh登录成功后就可以在X-shell中建立配置信息方便地连接了。</p>\n</blockquote>\n<ul>\n<li>新建会话，填写名称、IP、端口号（我们刚刚配置过的）：</li>\n</ul>\n<p><img src=\"https://photos.zywvvd.com/images_matrixtime/20201102200522.png\" alt=\"img\"></p>\n<ul>\n<li>用户身份认证，填入用户名密码（刚刚配置过的）：</li>\n</ul>\n<p><img src=\"https://photos.zywvvd.com/images_matrixtime/20201102200640.png\" alt=\"img\"></p>\n<ul>\n<li>随后就可以使用该会话直接登录docker容器了，为远程调试打下了坚实的基础：</li>\n</ul>\n<p><img src=\"https://photos.zywvvd.com/images_matrixtime/20201102200804.png\" alt=\"img\"></p>\n<h3 id=\"填坑\"><a href=\"#填坑\" class=\"headerlink\" title=\"填坑\"></a>填坑</h3><ul>\n<li><p>ssh: Could not resolve hostname 192.168.10.12:3721: Name or service not known</p>\n<blockquote>\n<p>这是在Windows中使用了Linux格式的SSH登录命令导致的解析错误</p>\n<p>将命令语法更换为Windows的格式即可</p>\n</blockquote>\n</li>\n<li><p>root 用户无论如何密码不被接受</p>\n<blockquote>\n<p>需要在被登录主机 /etc/ssh/sshd_config 中设置：</p>\n<figure class=\"highlight nginx\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs nginx\"><span class=\"hljs-comment\"># PermitRootLogin prohibit-password # 默认打开 禁止root用户使用密码登陆，需要将其注释</span><br><span class=\"hljs-attribute\">RSAAuthentication</span> <span class=\"hljs-literal\">yes</span> <span class=\"hljs-comment\">#启用 RSA 认证</span><br>PubkeyAuthentication <span class=\"hljs-literal\">yes</span> <span class=\"hljs-comment\">#启用公钥私钥配对认证方式</span><br>PermitRootLogin <span class=\"hljs-literal\">yes</span> <span class=\"hljs-comment\">#允许root用户使用ssh登录</span><br></code></pre></td></tr></tbody></table></figure>\n\n<ul>\n<li>重点：<strong>PermitRootLogin yes</strong></li>\n</ul>\n</blockquote>\n</li>\n<li><p>Connection to 192.168.10.12 closed.</p>\n</li>\n<li><p>或</p>\n</li>\n<li><p>Connection closed by foreign host.</p>\n<blockquote>\n<p>意思是 断开主机链接了，出现这种问题，跟你的IPTABLES，防火墙什么的都没关系。</p>\n<p>造成这个原 因是因为原来连接到SSHD服务器进程的22端口，当你的客户端突然断开时，服务器端的TCP连接就处于一个半打开状态。当下一次同一客户机再次建立 TCP连接时，服务器检测到这个半打开的TCP连接，并向客户机回传一个置位RST的TCP报文，客户机就会显示connection closed by foreign host。<br>这是TCP协议本身的一个保护措施，并不是什么错误，你只要再重新连接服务器就能连上。</p>\n<p>——— <a href=\"http://www.pooy.net/connection-closed-foreign-host.html\">http://www.pooy.net/connection-closed-foreign-host.html</a></p>\n<p>总结一下解决方案： <strong>关机重启</strong></p>\n</blockquote>\n</li>\n</ul>\n<h3 id=\"关于ssh的相关配置\"><a href=\"#关于ssh的相关配置\" class=\"headerlink\" title=\"关于ssh的相关配置\"></a>关于ssh的相关配置</h3><h4 id=\"修改配置文件\"><a href=\"#修改配置文件\" class=\"headerlink\" title=\"修改配置文件\"></a>修改配置文件</h4><figure class=\"highlight awk\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs awk\">cd <span class=\"hljs-regexp\">/etc/</span>ssh<br>vi ssh_config <span class=\"hljs-comment\">#可设置ssh的默认端口（22）</span><br>vi sshd_config<br></code></pre></td></tr></tbody></table></figure>\n\n<p>ssh_config和sshd_config都是ssh服务器的配置文件，二者区别在于，前者是针对客户端的配置文件，后者则是针对服务端的配置文件。两个配置文件都允许你通过设置不同的选项来改变客户端程序的运行方式。</p>\n<h4 id=\"重启ssh服务\"><a href=\"#重启ssh服务\" class=\"headerlink\" title=\"重启ssh服务\"></a>重启ssh服务</h4><figure class=\"highlight ebnf\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs ebnf\"><span class=\"hljs-attribute\">service sshd restart</span><br></code></pre></td></tr></tbody></table></figure>\n\n<p>如果报错 sshd: unrecognized service 则需要开启ssh服务。</p>\n<figure class=\"highlight awk\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs awk\"><span class=\"hljs-regexp\">/etc/i</span>nit.d/ssh start<br></code></pre></td></tr></tbody></table></figure>\n\n<h2 id=\"vscode连接远程服务器\"><a href=\"#vscode连接远程服务器\" class=\"headerlink\" title=\"vscode连接远程服务器\"></a>vscode连接远程服务器</h2><ul>\n<li><p>正确的ssh服务</p>\n</li>\n<li><p>密码设置完成（passwd root）</p>\n</li>\n</ul>\n<h3 id=\"安装插件\"><a href=\"#安装插件\" class=\"headerlink\" title=\"安装插件\"></a>安装插件</h3><ul>\n<li><p>安装 Remote Development 插件</p>\n<blockquote>\n<p>会自动安装 Remote-WSL / Containers / SSH 等插件。</p>\n</blockquote>\n</li>\n</ul>\n<p><img src=\"https://photos.zywvvd.com/images_matrixtime/20201028143530.png\" alt=\"img\"></p>\n<h3 id=\"配置主机信息\"><a href=\"#配置主机信息\" class=\"headerlink\" title=\"配置主机信息\"></a>配置主机信息</h3><blockquote>\n<p>ctrl + shift + p</p>\n</blockquote>\n<p><img src=\"https://photos.zywvvd.com/images_matrixtime/20201028174129.png\" alt=\"img\"></p>\n<p><img src=\"https://photos.zywvvd.com/images_matrixtime/20201028175152.png\" alt=\"img\"></p>\n<figure class=\"highlight crmsh\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs crmsh\">Host Enter<br>  HostName <span class=\"hljs-number\">192.168</span>.<span class=\"hljs-number\">10.15</span><br>  Port <span class=\"hljs-number\">12345</span><br>  <span class=\"hljs-keyword\">User</span> <span class=\"hljs-title\">root</span><br>  IdentityFile ~\\.ssh\\id_rsa<br>  IdentitiesOnly yes<br></code></pre></td></tr></tbody></table></figure>\n\n<h3 id=\"vs-code-连接远程主机\"><a href=\"#vs-code-连接远程主机\" class=\"headerlink\" title=\"vs code 连接远程主机\"></a>vs code 连接远程主机</h3><p><img src=\"https://photos.zywvvd.com/images_matrixtime/20201028175324.png\" alt=\"img\"></p>\n<blockquote>\n<p>之后选择目标主机的操作系统。</p>\n</blockquote>\n<ul>\n<li><p>成功连接到远程主机：</p>\n</li>\n<li><p>打开文件夹运行程序时，选择使用的Python环境：</p>\n</li>\n</ul>\n<h4 id=\"相对路径的设置\"><a href=\"#相对路径的设置\" class=\"headerlink\" title=\"相对路径的设置\"></a>相对路径的设置</h4><p>在读取文件时，可能使用相对路径出现错误。</p>\n<blockquote>\n<p>python 插件设置中没有设置<code>终端执行命令时使用文件的路径代替现在打开的目录</code>。</p>\n</blockquote>\n<h3 id=\"解决方案\"><a href=\"#解决方案\" class=\"headerlink\" title=\"解决方案\"></a>解决方案</h3><ul>\n<li>搜索配置 <code>execute in file</code>：</li>\n</ul>\n<p><img src=\"https://photos.zywvvd.com/win11-mt/20210717114300.png\" alt=\"img\"></p>\n","site":{"data":{"friends":[{"avatar":"http://image.luokangyuan.com/1_qq_27922023.jpg","name":"码酱","introduction":"我不是大佬，只是在追寻大佬的脚步","url":"http://luokangyuan.com/","title":"前去学习"},{"avatar":"http://image.luokangyuan.com/4027734.jpeg","name":"闪烁之狐","introduction":"编程界大佬，技术牛，人还特别好，不懂的都可以请教大佬","url":"https://blinkfox.github.io/","title":"前去学习"},{"avatar":"http://image.luokangyuan.com/avatar.jpg","name":"ja_rome","introduction":"平凡的脚步也可以走出伟大的行程","url":"https://me.csdn.net/jlh912008548","title":"前去学习"}]}},"excerpt":"","more":"<blockquote>\n<p>参考师兄博客：<a href=\"https://www.zywvvd.com/2020/11/02/windows/win_ssh_linux_docker/win_ssh_linux_docker/\">https://www.zywvvd.com/2020/11/02/windows/win_ssh_linux_docker/win_ssh_linux_docker/</a></p>\n</blockquote>\n<blockquote>\n<p>ssh是较可靠，专为远程登录会话和其他网络服务提供安全性的协议，广泛用于远程登录的场景，也是远程调试代码的神兵利器。在开发中经常会在服务器启动自己的 docker 容器进行开发，又需要调试代码，vim的调试环境配置起来门槛又太高。于是就有了使用Windows直接ssh打通docker进行调试的需求。本文记录Windows远程登录Linux服务器docker容器的方法。</p>\n</blockquote>\n<h2 id=\"环境说明\"><a href=\"#环境说明\" class=\"headerlink\" title=\"环境说明\"></a>环境说明</h2><ul>\n<li>登录主机操作系统 Win 10</li>\n<li>被登录主机操作系统 docker container in Linux</li>\n<li>主机与被登录主机（此处指服务器，不是docker）网络联通，IP在同一网段</li>\n<li>服务器与docker的IP在同一网段</li>\n</ul>\n<h2 id=\"配置方法\"><a href=\"#配置方法\" class=\"headerlink\" title=\"配置方法\"></a>配置方法</h2><h3 id=\"建立docker与Linux服务器的端口映射\"><a href=\"#建立docker与Linux服务器的端口映射\" class=\"headerlink\" title=\"建立docker与Linux服务器的端口映射\"></a>建立docker与Linux服务器的端口映射</h3><blockquote>\n<p>ssh协议链接时默认使用22端口，Windows与docker的端口往往不能直接进行映射（很可能不在一个网段），因此需要将docker的22端口映射到Linux服务器的某个端口，此时需要在建立docker容器时进行<a href=\"https://www.zywvvd.com/2020/05/14/coding/environment/wingide-remote-docker/wingide-remote-docker/#docker%E9%85%8D%E7%BD%AE\">配置</a>：</p>\n</blockquote>\n<figure class=\"highlight awk\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs awk\">$ docker run -it --name vvd -p <span class=\"hljs-number\">3721</span>:<span class=\"hljs-number\">22</span> -v <span class=\"hljs-regexp\">/root/</span>tmp:<span class=\"hljs-regexp\">/root/</span>tmp my_docker bash<br></code></pre></td></tr></table></figure>\n\n<ul>\n<li>其中 <code>-p</code> 的部分表示将本机（服务器）的3721端口映射到容器的22端口。</li>\n</ul>\n<h3 id=\"容器内部安装ssh服务\"><a href=\"#容器内部安装ssh服务\" class=\"headerlink\" title=\"容器内部安装ssh服务\"></a>容器内部安装ssh服务</h3><blockquote>\n<p>需要在被登录的容器内部建立并启动ssh服务。</p>\n</blockquote>\n<ul>\n<li>首先需要安装：</li>\n</ul>\n<figure class=\"highlight routeros\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs routeros\">apt-<span class=\"hljs-builtin-name\">get</span> update<br>apt-<span class=\"hljs-builtin-name\">get</span> install openssh-server<br>apt-<span class=\"hljs-builtin-name\">get</span> install openssh-client<br></code></pre></td></tr></table></figure>\n\n<ul>\n<li>安装完成后需要容器每次启动时自动运行相关服务，可以在 <code>~/.bashrc</code>中加入：</li>\n</ul>\n<figure class=\"highlight awk\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs awk\"><span class=\"hljs-regexp\">/etc/i</span>nit.d/ssh start<br></code></pre></td></tr></table></figure>\n\n<blockquote>\n<p>这样就保证了docker容器自动启动该服务。</p>\n</blockquote>\n<ul>\n<li>查看ssh运行状态</li>\n</ul>\n<figure class=\"highlight awk\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs awk\"><span class=\"hljs-regexp\">/etc/i</span>nit.d/ssh status<br></code></pre></td></tr></table></figure>\n\n<blockquote>\n<p>如果是 <code>* sshd is running</code> 说明ssh正常运行</p>\n</blockquote>\n<h3 id=\"修改容器内root用户登录设置\"><a href=\"#修改容器内root用户登录设置\" class=\"headerlink\" title=\"修改容器内root用户登录设置\"></a>修改容器内root用户登录设置</h3><blockquote>\n<p>有的容器默认不支持root用户远程使用ssh协议进行密码登录的，此时需要更改设置。</p>\n</blockquote>\n<ul>\n<li>打开 <code>/etc/ssh/sshd_config</code>文件：</li>\n</ul>\n<figure class=\"highlight nginx\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs nginx\"><span class=\"hljs-comment\"># PermitRootLogin prohibit-password # 默认打开 禁止root用户使用密码登陆，需要将其注释</span><br><span class=\"hljs-attribute\">RSAAuthentication</span> <span class=\"hljs-literal\">yes</span> <span class=\"hljs-comment\">#启用 RSA 认证</span><br>PubkeyAuthentication <span class=\"hljs-literal\">yes</span> <span class=\"hljs-comment\">#启用公钥私钥配对认证方式</span><br>PermitRootLogin <span class=\"hljs-literal\">yes</span> <span class=\"hljs-comment\">#允许root用户使用ssh登录</span><br></code></pre></td></tr></table></figure>\n\n<ul>\n<li>将 <code>PermitRootLogin</code> 设置为 yes</li>\n</ul>\n<h3 id=\"修改root密码\"><a href=\"#修改root密码\" class=\"headerlink\" title=\"修改root密码\"></a>修改root密码</h3><blockquote>\n<p>远程登录时需要使用系统的用户密码，我们就直接使用root用户登录好了，需要设置新建容器的密码：</p>\n</blockquote>\n<figure class=\"highlight ebnf\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs ebnf\"><span class=\"hljs-attribute\">passwd root</span><br></code></pre></td></tr></table></figure>\n\n<h3 id=\"设置SSH\"><a href=\"#设置SSH\" class=\"headerlink\" title=\"设置SSH\"></a>设置SSH</h3><ul>\n<li><a href=\"https://www.zywvvd.com/2020/02/23/git/link_github/Git-connect-remote-pos/#%E5%88%9B%E5%BB%BASSH%E5%AF%86%E9%92%A5\">本地生成ssh key</a></li>\n<li>将.pub 内容复制粘贴加入到远程 ~/.ssh/authorized_keys</li>\n</ul>\n<h3 id=\"SSH连接服务器\"><a href=\"#SSH连接服务器\" class=\"headerlink\" title=\"SSH连接服务器\"></a>SSH连接服务器</h3><blockquote>\n<p>需要用户名（被登录端用户）与被登录的主机ip和端口号</p>\n<p>例如： 用户名- root ip：192.168.10.12 端口映射为 3721</p>\n</blockquote>\n<ul>\n<li>linux</li>\n</ul>\n<figure class=\"highlight nginx\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs nginx\"><span class=\"hljs-attribute\">ssh</span> root@<span class=\"hljs-number\">192.168.10.12:3721</span><br></code></pre></td></tr></table></figure>\n\n<ul>\n<li>Windows</li>\n</ul>\n<figure class=\"highlight apache\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs apache\"><span class=\"hljs-attribute\">ssh</span> -p <span class=\"hljs-number\">3721</span> root@<span class=\"hljs-number\">192.168.10.12</span><br></code></pre></td></tr></table></figure>\n\n<p><img src=\"https://photos.zywvvd.com/images_matrixtime/20201102200256.png\" alt=\"img\"></p>\n<ul>\n<li>如果不清楚Linux系统端口映射配置情况：</li>\n</ul>\n<figure class=\"highlight excel\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs excel\">iptables -<span class=\"hljs-built_in\">t</span> nat -L -<span class=\"hljs-built_in\">n</span><br></code></pre></td></tr></table></figure>\n\n<h3 id=\"X-shell配置\"><a href=\"#X-shell配置\" class=\"headerlink\" title=\"X-shell配置\"></a>X-shell配置</h3><blockquote>\n<p>命令行ssh登录成功后就可以在X-shell中建立配置信息方便地连接了。</p>\n</blockquote>\n<ul>\n<li>新建会话，填写名称、IP、端口号（我们刚刚配置过的）：</li>\n</ul>\n<p><img src=\"https://photos.zywvvd.com/images_matrixtime/20201102200522.png\" alt=\"img\"></p>\n<ul>\n<li>用户身份认证，填入用户名密码（刚刚配置过的）：</li>\n</ul>\n<p><img src=\"https://photos.zywvvd.com/images_matrixtime/20201102200640.png\" alt=\"img\"></p>\n<ul>\n<li>随后就可以使用该会话直接登录docker容器了，为远程调试打下了坚实的基础：</li>\n</ul>\n<p><img src=\"https://photos.zywvvd.com/images_matrixtime/20201102200804.png\" alt=\"img\"></p>\n<h3 id=\"填坑\"><a href=\"#填坑\" class=\"headerlink\" title=\"填坑\"></a>填坑</h3><ul>\n<li><p>ssh: Could not resolve hostname 192.168.10.12:3721: Name or service not known</p>\n<blockquote>\n<p>这是在Windows中使用了Linux格式的SSH登录命令导致的解析错误</p>\n<p>将命令语法更换为Windows的格式即可</p>\n</blockquote>\n</li>\n<li><p>root 用户无论如何密码不被接受</p>\n<blockquote>\n<p>需要在被登录主机 /etc/ssh/sshd_config 中设置：</p>\n<figure class=\"highlight nginx\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs nginx\"><span class=\"hljs-comment\"># PermitRootLogin prohibit-password # 默认打开 禁止root用户使用密码登陆，需要将其注释</span><br><span class=\"hljs-attribute\">RSAAuthentication</span> <span class=\"hljs-literal\">yes</span> <span class=\"hljs-comment\">#启用 RSA 认证</span><br>PubkeyAuthentication <span class=\"hljs-literal\">yes</span> <span class=\"hljs-comment\">#启用公钥私钥配对认证方式</span><br>PermitRootLogin <span class=\"hljs-literal\">yes</span> <span class=\"hljs-comment\">#允许root用户使用ssh登录</span><br></code></pre></td></tr></table></figure>\n\n<ul>\n<li>重点：<strong>PermitRootLogin yes</strong></li>\n</ul>\n</blockquote>\n</li>\n<li><p>Connection to 192.168.10.12 closed.</p>\n</li>\n<li><p>或</p>\n</li>\n<li><p>Connection closed by foreign host.</p>\n<blockquote>\n<p>意思是 断开主机链接了，出现这种问题，跟你的IPTABLES，防火墙什么的都没关系。</p>\n<p>造成这个原 因是因为原来连接到SSHD服务器进程的22端口，当你的客户端突然断开时，服务器端的TCP连接就处于一个半打开状态。当下一次同一客户机再次建立 TCP连接时，服务器检测到这个半打开的TCP连接，并向客户机回传一个置位RST的TCP报文，客户机就会显示connection closed by foreign host。<br>这是TCP协议本身的一个保护措施，并不是什么错误，你只要再重新连接服务器就能连上。</p>\n<p>——— <a href=\"http://www.pooy.net/connection-closed-foreign-host.html\">http://www.pooy.net/connection-closed-foreign-host.html</a></p>\n<p>总结一下解决方案： <strong>关机重启</strong></p>\n</blockquote>\n</li>\n</ul>\n<h3 id=\"关于ssh的相关配置\"><a href=\"#关于ssh的相关配置\" class=\"headerlink\" title=\"关于ssh的相关配置\"></a>关于ssh的相关配置</h3><h4 id=\"修改配置文件\"><a href=\"#修改配置文件\" class=\"headerlink\" title=\"修改配置文件\"></a>修改配置文件</h4><figure class=\"highlight awk\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs awk\">cd <span class=\"hljs-regexp\">/etc/</span>ssh<br>vi ssh_config <span class=\"hljs-comment\">#可设置ssh的默认端口（22）</span><br>vi sshd_config<br></code></pre></td></tr></table></figure>\n\n<p>ssh_config和sshd_config都是ssh服务器的配置文件，二者区别在于，前者是针对客户端的配置文件，后者则是针对服务端的配置文件。两个配置文件都允许你通过设置不同的选项来改变客户端程序的运行方式。</p>\n<h4 id=\"重启ssh服务\"><a href=\"#重启ssh服务\" class=\"headerlink\" title=\"重启ssh服务\"></a>重启ssh服务</h4><figure class=\"highlight ebnf\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs ebnf\"><span class=\"hljs-attribute\">service sshd restart</span><br></code></pre></td></tr></table></figure>\n\n<p>如果报错 sshd: unrecognized service 则需要开启ssh服务。</p>\n<figure class=\"highlight awk\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs awk\"><span class=\"hljs-regexp\">/etc/i</span>nit.d/ssh start<br></code></pre></td></tr></table></figure>\n\n<h2 id=\"vscode连接远程服务器\"><a href=\"#vscode连接远程服务器\" class=\"headerlink\" title=\"vscode连接远程服务器\"></a>vscode连接远程服务器</h2><ul>\n<li><p>正确的ssh服务</p>\n</li>\n<li><p>密码设置完成（passwd root）</p>\n</li>\n</ul>\n<h3 id=\"安装插件\"><a href=\"#安装插件\" class=\"headerlink\" title=\"安装插件\"></a>安装插件</h3><ul>\n<li><p>安装 Remote Development 插件</p>\n<blockquote>\n<p>会自动安装 Remote-WSL / Containers / SSH 等插件。</p>\n</blockquote>\n</li>\n</ul>\n<p><img src=\"https://photos.zywvvd.com/images_matrixtime/20201028143530.png\" alt=\"img\"></p>\n<h3 id=\"配置主机信息\"><a href=\"#配置主机信息\" class=\"headerlink\" title=\"配置主机信息\"></a>配置主机信息</h3><blockquote>\n<p>ctrl + shift + p</p>\n</blockquote>\n<p><img src=\"https://photos.zywvvd.com/images_matrixtime/20201028174129.png\" alt=\"img\"></p>\n<p><img src=\"https://photos.zywvvd.com/images_matrixtime/20201028175152.png\" alt=\"img\"></p>\n<figure class=\"highlight crmsh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs crmsh\">Host Enter<br>  HostName <span class=\"hljs-number\">192.168</span>.<span class=\"hljs-number\">10.15</span><br>  Port <span class=\"hljs-number\">12345</span><br>  <span class=\"hljs-keyword\">User</span> <span class=\"hljs-title\">root</span><br>  IdentityFile ~\\.ssh\\id_rsa<br>  IdentitiesOnly yes<br></code></pre></td></tr></table></figure>\n\n<h3 id=\"vs-code-连接远程主机\"><a href=\"#vs-code-连接远程主机\" class=\"headerlink\" title=\"vs code 连接远程主机\"></a>vs code 连接远程主机</h3><p><img src=\"https://photos.zywvvd.com/images_matrixtime/20201028175324.png\" alt=\"img\"></p>\n<blockquote>\n<p>之后选择目标主机的操作系统。</p>\n</blockquote>\n<ul>\n<li><p>成功连接到远程主机：</p>\n</li>\n<li><p>打开文件夹运行程序时，选择使用的Python环境：</p>\n</li>\n</ul>\n<h4 id=\"相对路径的设置\"><a href=\"#相对路径的设置\" class=\"headerlink\" title=\"相对路径的设置\"></a>相对路径的设置</h4><p>在读取文件时，可能使用相对路径出现错误。</p>\n<blockquote>\n<p>python 插件设置中没有设置<code>终端执行命令时使用文件的路径代替现在打开的目录</code>。</p>\n</blockquote>\n<h3 id=\"解决方案\"><a href=\"#解决方案\" class=\"headerlink\" title=\"解决方案\"></a>解决方案</h3><ul>\n<li>搜索配置 <code>execute in file</code>：</li>\n</ul>\n<p><img src=\"https://photos.zywvvd.com/win11-mt/20210717114300.png\" alt=\"img\"></p>\n"},{"title":"dvc相关设置","date":"2021-08-10T09:36:32.000Z","_content":"\n>\n\n运行 sh setup.sh detection报错：\n\n> (base) root@9b1a4b217508:/workspace/fanmeilin/project/task/ai_lab# sh setup.sh detection\n> setup.sh: 12: setup.sh: dvc: not found\n> cp: failed to get attributes of 'assets/examples': No such file or directory\n> [*] copy DETECTION skeleton scripts to upper directory\n\n原因是未安装dvc，运行下面的命令安装dvc\n\n```\npip install dvc==2.3.0\npip install 'dvc[s3]'\n```\n\n> 在Win平台下可能会报错：\n>\n> ```\n> ERROR: Cannot uninstall 'ruamel-yaml'. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall.\n> ```\n>\n> 此时需要进入python 的lib/site-packages 中删除 ‘ruamel-yaml’ 相关的文件\n\n**注意：** dvc 2.3.0 版本与之后的hash计算方法不同，不能混用\n\n再次执行 sh setup.sh detection报错\n\n> ERROR: unexpected error - Cannot connect to host ceph01:80 ssl:default [Name or service not known]: [Errno -2] Name or service not known  \n\n则修改etc/hosts文件\n\n- 配置hosts文件，在hosts文件中增加以下内容\n  `192.168.10.91 ceph01`\n\n##### *详细dvc的各种操作，可移步* [师兄博客 DVC 使用手册](https://www.zywvvd.com/2020/12/17/dvc/dvc/)\n\n","source":"_posts/dvc/dvc-config.md","raw":"---\ntitle: dvc相关设置\ntags: [dvc]\ncategories: dvc\ndate: 2021-08-10 17:36:32\n---\n\n>\n\n运行 sh setup.sh detection报错：\n\n> (base) root@9b1a4b217508:/workspace/fanmeilin/project/task/ai_lab# sh setup.sh detection\n> setup.sh: 12: setup.sh: dvc: not found\n> cp: failed to get attributes of 'assets/examples': No such file or directory\n> [*] copy DETECTION skeleton scripts to upper directory\n\n原因是未安装dvc，运行下面的命令安装dvc\n\n```\npip install dvc==2.3.0\npip install 'dvc[s3]'\n```\n\n> 在Win平台下可能会报错：\n>\n> ```\n> ERROR: Cannot uninstall 'ruamel-yaml'. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall.\n> ```\n>\n> 此时需要进入python 的lib/site-packages 中删除 ‘ruamel-yaml’ 相关的文件\n\n**注意：** dvc 2.3.0 版本与之后的hash计算方法不同，不能混用\n\n再次执行 sh setup.sh detection报错\n\n> ERROR: unexpected error - Cannot connect to host ceph01:80 ssl:default [Name or service not known]: [Errno -2] Name or service not known  \n\n则修改etc/hosts文件\n\n- 配置hosts文件，在hosts文件中增加以下内容\n  `192.168.10.91 ceph01`\n\n##### *详细dvc的各种操作，可移步* [师兄博客 DVC 使用手册](https://www.zywvvd.com/2020/12/17/dvc/dvc/)\n\n","slug":"dvc/dvc-config","published":1,"updated":"2021-08-10T10:05:45.404Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cksa5kseq000ga0x43jjy6zi6","content":"<blockquote>\n</blockquote>\n<p>运行 sh setup.sh detection报错：</p>\n<blockquote>\n<p>(base) root@9b1a4b217508:/workspace/fanmeilin/project/task/ai_lab# sh setup.sh detection<br>setup.sh: 12: setup.sh: dvc: not found<br>cp: failed to get attributes of ‘assets/examples’: No such file or directory<br>[*] copy DETECTION skeleton scripts to upper directory</p>\n</blockquote>\n<p>原因是未安装dvc，运行下面的命令安装dvc</p>\n<figure class=\"highlight apache\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs apache\"><span class=\"hljs-attribute\">pip</span> install dvc==<span class=\"hljs-number\">2</span>.<span class=\"hljs-number\">3</span>.<span class=\"hljs-number\">0</span><br><span class=\"hljs-attribute\">pip</span> install 'dvc[s<span class=\"hljs-number\">3</span>]'<br></code></pre></td></tr></tbody></table></figure>\n\n<blockquote>\n<p>在Win平台下可能会报错：</p>\n<figure class=\"highlight subunit\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs subunit\"><span class=\"hljs-keyword\">ERROR: </span>Cannot uninstall 'ruamel-yaml'. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall.<br></code></pre></td></tr></tbody></table></figure>\n\n<p>此时需要进入python 的lib/site-packages 中删除 ‘ruamel-yaml’ 相关的文件</p>\n</blockquote>\n<p><strong>注意：</strong> dvc 2.3.0 版本与之后的hash计算方法不同，不能混用</p>\n<p>再次执行 sh setup.sh detection报错</p>\n<blockquote>\n<p>ERROR: unexpected error - Cannot connect to host ceph01:80 ssl:default [Name or service not known]: [Errno -2] Name or service not known  </p>\n</blockquote>\n<p>则修改etc/hosts文件</p>\n<ul>\n<li>配置hosts文件，在hosts文件中增加以下内容<br><code>192.168.10.91 ceph01</code></li>\n</ul>\n<h5 id=\"详细dvc的各种操作，可移步-师兄博客-DVC-使用手册\"><a href=\"#详细dvc的各种操作，可移步-师兄博客-DVC-使用手册\" class=\"headerlink\" title=\"详细dvc的各种操作，可移步 师兄博客 DVC 使用手册\"></a><em>详细dvc的各种操作，可移步</em> <a href=\"https://www.zywvvd.com/2020/12/17/dvc/dvc/\">师兄博客 DVC 使用手册</a></h5>","site":{"data":{"friends":[{"avatar":"http://image.luokangyuan.com/1_qq_27922023.jpg","name":"码酱","introduction":"我不是大佬，只是在追寻大佬的脚步","url":"http://luokangyuan.com/","title":"前去学习"},{"avatar":"http://image.luokangyuan.com/4027734.jpeg","name":"闪烁之狐","introduction":"编程界大佬，技术牛，人还特别好，不懂的都可以请教大佬","url":"https://blinkfox.github.io/","title":"前去学习"},{"avatar":"http://image.luokangyuan.com/avatar.jpg","name":"ja_rome","introduction":"平凡的脚步也可以走出伟大的行程","url":"https://me.csdn.net/jlh912008548","title":"前去学习"}]}},"excerpt":"","more":"<blockquote>\n</blockquote>\n<p>运行 sh setup.sh detection报错：</p>\n<blockquote>\n<p>(base) root@9b1a4b217508:/workspace/fanmeilin/project/task/ai_lab# sh setup.sh detection<br>setup.sh: 12: setup.sh: dvc: not found<br>cp: failed to get attributes of ‘assets/examples’: No such file or directory<br>[*] copy DETECTION skeleton scripts to upper directory</p>\n</blockquote>\n<p>原因是未安装dvc，运行下面的命令安装dvc</p>\n<figure class=\"highlight apache\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs apache\"><span class=\"hljs-attribute\">pip</span> install dvc==<span class=\"hljs-number\">2</span>.<span class=\"hljs-number\">3</span>.<span class=\"hljs-number\">0</span><br><span class=\"hljs-attribute\">pip</span> install &#x27;dvc[s<span class=\"hljs-number\">3</span>]&#x27;<br></code></pre></td></tr></table></figure>\n\n<blockquote>\n<p>在Win平台下可能会报错：</p>\n<figure class=\"highlight subunit\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs subunit\"><span class=\"hljs-keyword\">ERROR: </span>Cannot uninstall &#x27;ruamel-yaml&#x27;. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall.<br></code></pre></td></tr></table></figure>\n\n<p>此时需要进入python 的lib/site-packages 中删除 ‘ruamel-yaml’ 相关的文件</p>\n</blockquote>\n<p><strong>注意：</strong> dvc 2.3.0 版本与之后的hash计算方法不同，不能混用</p>\n<p>再次执行 sh setup.sh detection报错</p>\n<blockquote>\n<p>ERROR: unexpected error - Cannot connect to host ceph01:80 ssl:default [Name or service not known]: [Errno -2] Name or service not known  </p>\n</blockquote>\n<p>则修改etc/hosts文件</p>\n<ul>\n<li>配置hosts文件，在hosts文件中增加以下内容<br><code>192.168.10.91 ceph01</code></li>\n</ul>\n<h5 id=\"详细dvc的各种操作，可移步-师兄博客-DVC-使用手册\"><a href=\"#详细dvc的各种操作，可移步-师兄博客-DVC-使用手册\" class=\"headerlink\" title=\"详细dvc的各种操作，可移步 师兄博客 DVC 使用手册\"></a><em>详细dvc的各种操作，可移步</em> <a href=\"https://www.zywvvd.com/2020/12/17/dvc/dvc/\">师兄博客 DVC 使用手册</a></h5>"},{"title":"hexo中公式显示","date":"2021-08-05T12:38:51.000Z","math":true,"_content":"\n> 公式的显示问题。Hexo中Mathjax是用于显示公式的插件，但是多行显示会出现问题，有时还会出现乱码的情况。\n\n### 配置\n\n在根目录下的config\\_fluid.yml​文件中打开math的相关配置。\n\n```yaml\n  # 数学公式，开启之前需要更换 Markdown 渲染器，否则复杂公式会有兼容问题，具体请见：https://hexo.fluid-dev.com/docs/guide/##latex-数学公式\n  # Mathematical formula. If enable, you need to change the Markdown renderer, see: https://hexo.fluid-dev.com/docs/en/guide/#math\n  math:\n    # 开启后文章默认可用，自定义页面如需使用，需在 Front-matter 中指定 `math: true`\n    # If you want to use math on the custom page, you need to set `math: true` in Front-matter\n    enable: true\n\n    # 开启后，只有在文章 Front-matter 里指定 `math: true` 才会在文章页启动公式转换，以便在页面不包含公式时提高加载速度\n    # If true, only set `math: true` in Front-matter will enable math, to load faster when the page does not contain math\n    specific: true\n\n    # Options: mathjax | katex\n    engine: mathjax\n\n```\n\n### 出现的问题\n\n#### 问题1\n\n- 由于hexo解码时关注{{，}}，%% 等连续字符，会将这部分代码解读为其他带有特殊含义的内容\n- 如果公式中恰巧出现了此类字符，会报出上述错误\n\n#### 问题2\n\n- 由于hexo在公式中的`\\\\`错会成了转义符，也就是说他只看见了一个反斜杠，不会执行换行命令，导致公式堆成一行\n\n### 解决方案\n\n#### 临时方案\n\n##### 针对问题1\n\n- 可以在连续的 `{` `}` `%`中间插入空格，分开就没事了\n\n##### 针对问题2\n\n- 可以将`\\\\`换成`\\\\\\\\`，可以实现公式的多行正确显示\n\n#### 终极方案\n\n- 在官方文档中提到了可以为hexo提供标记，阻止其按照自己的规则解释我们的字符串，显示其原本的含义\n\n- 标记为\n\n  ```\n  {% raw %}\n  $$\n  ...\n  $$\n  {% endraw %}\n  ```\n\n### 多行显示和对齐\n- 默认是显示为一行要实现公式多行和对齐可以使用{aligned}模式，使用\"&\"来标记对齐位置。\"\\\\\\\\\"表示换行\n\n    ```\n    $$\n    \\begin{aligned}\n    \\boldsymbol{x}^{\\mathrm{T}}C\\boldsymbol{x}\t&=\\boldsymbol{x}^{\\mathrm{T}}\\mathrm{E}\\left[\\left(X-\\mu\\right)\\left(X-\\mu\\right)^{\\mathrm{T}}\\right]\\boldsymbol{x} \t\n    \\\\&=\\mathrm{E}\\left[\\boldsymbol{x}^{\\mathrm{T}}\\left(X-\\mu\\right)\\left(X-\\mu\\right)^{\\mathrm{T}}\\boldsymbol{x}\\right] \t\\\\&=\\mathrm{E}\\left[\\left(\\left(X-\\mu\\right)^{\\mathrm{T}}\\boldsymbol{x}\\right)^{\\mathrm{T}}\\left(\\left(X-\\mu\\right)^{\\mathrm{T}}\\boldsymbol{x}\\right)\\right] \t\n    \\\\&=\\mathrm{E}\\left(\\left\\Vert \\left(X-\\mu\\right)^{\\mathrm{T}}\\boldsymbol{x}\\right\\Vert ^{2}\\right) \t\n    \\\\&=\\sigma_{X}^{2}\n    \\end{aligned}\n    $$\n    ```\n\n- 显示为\n\n{% raw %}\n$$\n\\begin{aligned}\n\\boldsymbol{x}^{\\mathrm{T}}C\\boldsymbol{x}\t&=\\boldsymbol{x}^{\\mathrm{T}}\\mathrm{E}\\left[\\left(X-\\mu\\right)\\left(X-\\mu\\right)^{\\mathrm{T}}\\right]\\boldsymbol{x} \t\n\\\\&=\\mathrm{E}\\left[\\boldsymbol{x}^{\\mathrm{T}}\\left(X-\\mu\\right)\\left(X-\\mu\\right)^{\\mathrm{T}}\\boldsymbol{x}\\right] \t\\\\&=\\mathrm{E}\\left[\\left(\\left(X-\\mu\\right)^{\\mathrm{T}}\\boldsymbol{x}\\right)^{\\mathrm{T}}\\left(\\left(X-\\mu\\right)^{\\mathrm{T}}\\boldsymbol{x}\\right)\\right] \t\n\\\\&=\\mathrm{E}\\left(\\left\\Vert \\left(X-\\mu\\right)^{\\mathrm{T}}\\boldsymbol{x}\\right\\Vert ^{2}\\right) \t\n\\\\&=\\sigma_{X}^{2}\n\\end{aligned}\n$$\n{% endraw %}\n\n","source":"_posts/hexo_config/hexo-math-config.md","raw":"---\ntitle: hexo中公式显示\ndate: 2021-08-05 20:38:51\ntags: [hexo,fluid,配置]\ncategories: [配置,hexo]\nmath: true\n---\n\n> 公式的显示问题。Hexo中Mathjax是用于显示公式的插件，但是多行显示会出现问题，有时还会出现乱码的情况。\n\n### 配置\n\n在根目录下的config\\_fluid.yml​文件中打开math的相关配置。\n\n```yaml\n  # 数学公式，开启之前需要更换 Markdown 渲染器，否则复杂公式会有兼容问题，具体请见：https://hexo.fluid-dev.com/docs/guide/##latex-数学公式\n  # Mathematical formula. If enable, you need to change the Markdown renderer, see: https://hexo.fluid-dev.com/docs/en/guide/#math\n  math:\n    # 开启后文章默认可用，自定义页面如需使用，需在 Front-matter 中指定 `math: true`\n    # If you want to use math on the custom page, you need to set `math: true` in Front-matter\n    enable: true\n\n    # 开启后，只有在文章 Front-matter 里指定 `math: true` 才会在文章页启动公式转换，以便在页面不包含公式时提高加载速度\n    # If true, only set `math: true` in Front-matter will enable math, to load faster when the page does not contain math\n    specific: true\n\n    # Options: mathjax | katex\n    engine: mathjax\n\n```\n\n### 出现的问题\n\n#### 问题1\n\n- 由于hexo解码时关注{{，}}，%% 等连续字符，会将这部分代码解读为其他带有特殊含义的内容\n- 如果公式中恰巧出现了此类字符，会报出上述错误\n\n#### 问题2\n\n- 由于hexo在公式中的`\\\\`错会成了转义符，也就是说他只看见了一个反斜杠，不会执行换行命令，导致公式堆成一行\n\n### 解决方案\n\n#### 临时方案\n\n##### 针对问题1\n\n- 可以在连续的 `{` `}` `%`中间插入空格，分开就没事了\n\n##### 针对问题2\n\n- 可以将`\\\\`换成`\\\\\\\\`，可以实现公式的多行正确显示\n\n#### 终极方案\n\n- 在官方文档中提到了可以为hexo提供标记，阻止其按照自己的规则解释我们的字符串，显示其原本的含义\n\n- 标记为\n\n  ```\n  {% raw %}\n  $$\n  ...\n  $$\n  {% endraw %}\n  ```\n\n### 多行显示和对齐\n- 默认是显示为一行要实现公式多行和对齐可以使用{aligned}模式，使用\"&\"来标记对齐位置。\"\\\\\\\\\"表示换行\n\n    ```\n    $$\n    \\begin{aligned}\n    \\boldsymbol{x}^{\\mathrm{T}}C\\boldsymbol{x}\t&=\\boldsymbol{x}^{\\mathrm{T}}\\mathrm{E}\\left[\\left(X-\\mu\\right)\\left(X-\\mu\\right)^{\\mathrm{T}}\\right]\\boldsymbol{x} \t\n    \\\\&=\\mathrm{E}\\left[\\boldsymbol{x}^{\\mathrm{T}}\\left(X-\\mu\\right)\\left(X-\\mu\\right)^{\\mathrm{T}}\\boldsymbol{x}\\right] \t\\\\&=\\mathrm{E}\\left[\\left(\\left(X-\\mu\\right)^{\\mathrm{T}}\\boldsymbol{x}\\right)^{\\mathrm{T}}\\left(\\left(X-\\mu\\right)^{\\mathrm{T}}\\boldsymbol{x}\\right)\\right] \t\n    \\\\&=\\mathrm{E}\\left(\\left\\Vert \\left(X-\\mu\\right)^{\\mathrm{T}}\\boldsymbol{x}\\right\\Vert ^{2}\\right) \t\n    \\\\&=\\sigma_{X}^{2}\n    \\end{aligned}\n    $$\n    ```\n\n- 显示为\n\n{% raw %}\n$$\n\\begin{aligned}\n\\boldsymbol{x}^{\\mathrm{T}}C\\boldsymbol{x}\t&=\\boldsymbol{x}^{\\mathrm{T}}\\mathrm{E}\\left[\\left(X-\\mu\\right)\\left(X-\\mu\\right)^{\\mathrm{T}}\\right]\\boldsymbol{x} \t\n\\\\&=\\mathrm{E}\\left[\\boldsymbol{x}^{\\mathrm{T}}\\left(X-\\mu\\right)\\left(X-\\mu\\right)^{\\mathrm{T}}\\boldsymbol{x}\\right] \t\\\\&=\\mathrm{E}\\left[\\left(\\left(X-\\mu\\right)^{\\mathrm{T}}\\boldsymbol{x}\\right)^{\\mathrm{T}}\\left(\\left(X-\\mu\\right)^{\\mathrm{T}}\\boldsymbol{x}\\right)\\right] \t\n\\\\&=\\mathrm{E}\\left(\\left\\Vert \\left(X-\\mu\\right)^{\\mathrm{T}}\\boldsymbol{x}\\right\\Vert ^{2}\\right) \t\n\\\\&=\\sigma_{X}^{2}\n\\end{aligned}\n$$\n{% endraw %}\n\n","slug":"hexo_config/hexo-math-config","published":1,"updated":"2021-08-06T08:06:48.572Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cksa5kser000ha0x42o9ncw4n","content":"<blockquote>\n<p>公式的显示问题。Hexo中Mathjax是用于显示公式的插件，但是多行显示会出现问题，有时还会出现乱码的情况。</p>\n</blockquote>\n<h3 id=\"配置\"><a href=\"#配置\" class=\"headerlink\" title=\"配置\"></a>配置</h3><p>在根目录下的config_fluid.yml​文件中打开math的相关配置。</p>\n<figure class=\"highlight yaml\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs yaml\"><span class=\"hljs-comment\"># 数学公式，开启之前需要更换 Markdown 渲染器，否则复杂公式会有兼容问题，具体请见：https://hexo.fluid-dev.com/docs/guide/##latex-数学公式</span><br><span class=\"hljs-comment\"># Mathematical formula. If enable, you need to change the Markdown renderer, see: https://hexo.fluid-dev.com/docs/en/guide/#math</span><br><span class=\"hljs-attr\">math:</span><br>  <span class=\"hljs-comment\"># 开启后文章默认可用，自定义页面如需使用，需在 Front-matter 中指定 `math: true`</span><br>  <span class=\"hljs-comment\"># If you want to use math on the custom page, you need to set `math: true` in Front-matter</span><br>  <span class=\"hljs-attr\">enable:</span> <span class=\"hljs-literal\">true</span><br><br>  <span class=\"hljs-comment\"># 开启后，只有在文章 Front-matter 里指定 `math: true` 才会在文章页启动公式转换，以便在页面不包含公式时提高加载速度</span><br>  <span class=\"hljs-comment\"># If true, only set `math: true` in Front-matter will enable math, to load faster when the page does not contain math</span><br>  <span class=\"hljs-attr\">specific:</span> <span class=\"hljs-literal\">true</span><br><br>  <span class=\"hljs-comment\"># Options: mathjax | katex</span><br>  <span class=\"hljs-attr\">engine:</span> <span class=\"hljs-string\">mathjax</span><br><br></code></pre></td></tr></tbody></table></figure>\n\n<h3 id=\"出现的问题\"><a href=\"#出现的问题\" class=\"headerlink\" title=\"出现的问题\"></a>出现的问题</h3><h4 id=\"问题1\"><a href=\"#问题1\" class=\"headerlink\" title=\"问题1\"></a>问题1</h4><ul>\n<li>由于hexo解码时关注，%% 等连续字符，会将这部分代码解读为其他带有特殊含义的内容</li>\n<li>如果公式中恰巧出现了此类字符，会报出上述错误</li>\n</ul>\n<h4 id=\"问题2\"><a href=\"#问题2\" class=\"headerlink\" title=\"问题2\"></a>问题2</h4><ul>\n<li>由于hexo在公式中的<code>\\\\</code>错会成了转义符，也就是说他只看见了一个反斜杠，不会执行换行命令，导致公式堆成一行</li>\n</ul>\n<h3 id=\"解决方案\"><a href=\"#解决方案\" class=\"headerlink\" title=\"解决方案\"></a>解决方案</h3><h4 id=\"临时方案\"><a href=\"#临时方案\" class=\"headerlink\" title=\"临时方案\"></a>临时方案</h4><h5 id=\"针对问题1\"><a href=\"#针对问题1\" class=\"headerlink\" title=\"针对问题1\"></a>针对问题1</h5><ul>\n<li>可以在连续的 <code>{</code> <code>}</code> <code>%</code>中间插入空格，分开就没事了</li>\n</ul>\n<h5 id=\"针对问题2\"><a href=\"#针对问题2\" class=\"headerlink\" title=\"针对问题2\"></a>针对问题2</h5><ul>\n<li>可以将<code>\\\\</code>换成<code>\\\\\\\\</code>，可以实现公式的多行正确显示</li>\n</ul>\n<h4 id=\"终极方案\"><a href=\"#终极方案\" class=\"headerlink\" title=\"终极方案\"></a>终极方案</h4><ul>\n<li><p>在官方文档中提到了可以为hexo提供标记，阻止其按照自己的规则解释我们的字符串，显示其原本的含义</p>\n</li>\n<li><p>标记为</p>\n<figure class=\"highlight django\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs django\"><span class=\"hljs-template-tag\">{% <span class=\"hljs-name\">raw</span> %}</span><span class=\"xml\"></span><br><span class=\"xml\">$$</span><br><span class=\"xml\">...</span><br><span class=\"xml\">$$</span><br><span class=\"xml\"></span><span class=\"hljs-template-tag\">{% <span class=\"hljs-name\">endraw</span> %}</span><br></code></pre></td></tr></tbody></table></figure></li>\n</ul>\n<h3 id=\"多行显示和对齐\"><a href=\"#多行显示和对齐\" class=\"headerlink\" title=\"多行显示和对齐\"></a>多行显示和对齐</h3><ul>\n<li><p>默认是显示为一行要实现公式多行和对齐可以使用{aligned}模式，使用”&amp;”来标记对齐位置。”\\\\“表示换行</p>\n  <figure class=\"highlight taggerscript\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs taggerscript\">$$<br><span class=\"hljs-symbol\">\\b</span>egin{aligned}<br><span class=\"hljs-symbol\">\\b</span>oldsymbol{x}^{<span class=\"hljs-symbol\">\\m</span>athrm{T}}C<span class=\"hljs-symbol\">\\b</span>oldsymbol{x}\t&amp;=<span class=\"hljs-symbol\">\\b</span>oldsymbol{x}^{<span class=\"hljs-symbol\">\\m</span>athrm{T}}<span class=\"hljs-symbol\">\\m</span>athrm{E}<span class=\"hljs-symbol\">\\l</span>eft[<span class=\"hljs-symbol\">\\l</span>eft(X-<span class=\"hljs-symbol\">\\m</span>u<span class=\"hljs-symbol\">\\r</span>ight)<span class=\"hljs-symbol\">\\l</span>eft(X-<span class=\"hljs-symbol\">\\m</span>u<span class=\"hljs-symbol\">\\r</span>ight)^{<span class=\"hljs-symbol\">\\m</span>athrm{T}}<span class=\"hljs-symbol\">\\r</span>ight]<span class=\"hljs-symbol\">\\b</span>oldsymbol{x} \t<br><span class=\"hljs-symbol\">\\\\</span>&amp;=<span class=\"hljs-symbol\">\\m</span>athrm{E}<span class=\"hljs-symbol\">\\l</span>eft[<span class=\"hljs-symbol\">\\b</span>oldsymbol{x}^{<span class=\"hljs-symbol\">\\m</span>athrm{T}}<span class=\"hljs-symbol\">\\l</span>eft(X-<span class=\"hljs-symbol\">\\m</span>u<span class=\"hljs-symbol\">\\r</span>ight)<span class=\"hljs-symbol\">\\l</span>eft(X-<span class=\"hljs-symbol\">\\m</span>u<span class=\"hljs-symbol\">\\r</span>ight)^{<span class=\"hljs-symbol\">\\m</span>athrm{T}}<span class=\"hljs-symbol\">\\b</span>oldsymbol{x}<span class=\"hljs-symbol\">\\r</span>ight] \t<span class=\"hljs-symbol\">\\\\</span>&amp;=<span class=\"hljs-symbol\">\\m</span>athrm{E}<span class=\"hljs-symbol\">\\l</span>eft[<span class=\"hljs-symbol\">\\l</span>eft(<span class=\"hljs-symbol\">\\l</span>eft(X-<span class=\"hljs-symbol\">\\m</span>u<span class=\"hljs-symbol\">\\r</span>ight)^{<span class=\"hljs-symbol\">\\m</span>athrm{T}}<span class=\"hljs-symbol\">\\b</span>oldsymbol{x}<span class=\"hljs-symbol\">\\r</span>ight)^{<span class=\"hljs-symbol\">\\m</span>athrm{T}}<span class=\"hljs-symbol\">\\l</span>eft(<span class=\"hljs-symbol\">\\l</span>eft(X-<span class=\"hljs-symbol\">\\m</span>u<span class=\"hljs-symbol\">\\r</span>ight)^{<span class=\"hljs-symbol\">\\m</span>athrm{T}}<span class=\"hljs-symbol\">\\b</span>oldsymbol{x}<span class=\"hljs-symbol\">\\r</span>ight)<span class=\"hljs-symbol\">\\r</span>ight] \t<br><span class=\"hljs-symbol\">\\\\</span>&amp;=<span class=\"hljs-symbol\">\\m</span>athrm{E}<span class=\"hljs-symbol\">\\l</span>eft(<span class=\"hljs-symbol\">\\l</span>eft<span class=\"hljs-symbol\">\\V</span>ert <span class=\"hljs-symbol\">\\l</span>eft(X-<span class=\"hljs-symbol\">\\m</span>u<span class=\"hljs-symbol\">\\r</span>ight)^{<span class=\"hljs-symbol\">\\m</span>athrm{T}}<span class=\"hljs-symbol\">\\b</span>oldsymbol{x}<span class=\"hljs-symbol\">\\r</span>ight<span class=\"hljs-symbol\">\\V</span>ert ^{2}<span class=\"hljs-symbol\">\\r</span>ight) \t<br><span class=\"hljs-symbol\">\\\\</span>&amp;=<span class=\"hljs-symbol\">\\s</span>igma_{X}^{2}<br><span class=\"hljs-symbol\">\\e</span>nd{aligned}<br>$$<br></code></pre></td></tr></tbody></table></figure></li>\n<li><p>显示为</p>\n</li>\n</ul>\n\n$$\n\\begin{aligned}\n\\boldsymbol{x}^{\\mathrm{T}}C\\boldsymbol{x}\t&amp;=\\boldsymbol{x}^{\\mathrm{T}}\\mathrm{E}\\left[\\left(X-\\mu\\right)\\left(X-\\mu\\right)^{\\mathrm{T}}\\right]\\boldsymbol{x} \t\n\\\\&amp;=\\mathrm{E}\\left[\\boldsymbol{x}^{\\mathrm{T}}\\left(X-\\mu\\right)\\left(X-\\mu\\right)^{\\mathrm{T}}\\boldsymbol{x}\\right] \t\\\\&amp;=\\mathrm{E}\\left[\\left(\\left(X-\\mu\\right)^{\\mathrm{T}}\\boldsymbol{x}\\right)^{\\mathrm{T}}\\left(\\left(X-\\mu\\right)^{\\mathrm{T}}\\boldsymbol{x}\\right)\\right] \t\n\\\\&amp;=\\mathrm{E}\\left(\\left\\Vert \\left(X-\\mu\\right)^{\\mathrm{T}}\\boldsymbol{x}\\right\\Vert ^{2}\\right) \t\n\\\\&amp;=\\sigma_{X}^{2}\n\\end{aligned}\n$$\n\n\n","site":{"data":{"friends":[{"avatar":"http://image.luokangyuan.com/1_qq_27922023.jpg","name":"码酱","introduction":"我不是大佬，只是在追寻大佬的脚步","url":"http://luokangyuan.com/","title":"前去学习"},{"avatar":"http://image.luokangyuan.com/4027734.jpeg","name":"闪烁之狐","introduction":"编程界大佬，技术牛，人还特别好，不懂的都可以请教大佬","url":"https://blinkfox.github.io/","title":"前去学习"},{"avatar":"http://image.luokangyuan.com/avatar.jpg","name":"ja_rome","introduction":"平凡的脚步也可以走出伟大的行程","url":"https://me.csdn.net/jlh912008548","title":"前去学习"}]}},"excerpt":"","more":"<blockquote>\n<p>公式的显示问题。Hexo中Mathjax是用于显示公式的插件，但是多行显示会出现问题，有时还会出现乱码的情况。</p>\n</blockquote>\n<h3 id=\"配置\"><a href=\"#配置\" class=\"headerlink\" title=\"配置\"></a>配置</h3><p>在根目录下的config_fluid.yml​文件中打开math的相关配置。</p>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs yaml\"><span class=\"hljs-comment\"># 数学公式，开启之前需要更换 Markdown 渲染器，否则复杂公式会有兼容问题，具体请见：https://hexo.fluid-dev.com/docs/guide/##latex-数学公式</span><br><span class=\"hljs-comment\"># Mathematical formula. If enable, you need to change the Markdown renderer, see: https://hexo.fluid-dev.com/docs/en/guide/#math</span><br><span class=\"hljs-attr\">math:</span><br>  <span class=\"hljs-comment\"># 开启后文章默认可用，自定义页面如需使用，需在 Front-matter 中指定 `math: true`</span><br>  <span class=\"hljs-comment\"># If you want to use math on the custom page, you need to set `math: true` in Front-matter</span><br>  <span class=\"hljs-attr\">enable:</span> <span class=\"hljs-literal\">true</span><br><br>  <span class=\"hljs-comment\"># 开启后，只有在文章 Front-matter 里指定 `math: true` 才会在文章页启动公式转换，以便在页面不包含公式时提高加载速度</span><br>  <span class=\"hljs-comment\"># If true, only set `math: true` in Front-matter will enable math, to load faster when the page does not contain math</span><br>  <span class=\"hljs-attr\">specific:</span> <span class=\"hljs-literal\">true</span><br><br>  <span class=\"hljs-comment\"># Options: mathjax | katex</span><br>  <span class=\"hljs-attr\">engine:</span> <span class=\"hljs-string\">mathjax</span><br><br></code></pre></td></tr></table></figure>\n\n<h3 id=\"出现的问题\"><a href=\"#出现的问题\" class=\"headerlink\" title=\"出现的问题\"></a>出现的问题</h3><h4 id=\"问题1\"><a href=\"#问题1\" class=\"headerlink\" title=\"问题1\"></a>问题1</h4><ul>\n<li>由于hexo解码时关注，%% 等连续字符，会将这部分代码解读为其他带有特殊含义的内容</li>\n<li>如果公式中恰巧出现了此类字符，会报出上述错误</li>\n</ul>\n<h4 id=\"问题2\"><a href=\"#问题2\" class=\"headerlink\" title=\"问题2\"></a>问题2</h4><ul>\n<li>由于hexo在公式中的<code>\\\\</code>错会成了转义符，也就是说他只看见了一个反斜杠，不会执行换行命令，导致公式堆成一行</li>\n</ul>\n<h3 id=\"解决方案\"><a href=\"#解决方案\" class=\"headerlink\" title=\"解决方案\"></a>解决方案</h3><h4 id=\"临时方案\"><a href=\"#临时方案\" class=\"headerlink\" title=\"临时方案\"></a>临时方案</h4><h5 id=\"针对问题1\"><a href=\"#针对问题1\" class=\"headerlink\" title=\"针对问题1\"></a>针对问题1</h5><ul>\n<li>可以在连续的 <code>&#123;</code> <code>&#125;</code> <code>%</code>中间插入空格，分开就没事了</li>\n</ul>\n<h5 id=\"针对问题2\"><a href=\"#针对问题2\" class=\"headerlink\" title=\"针对问题2\"></a>针对问题2</h5><ul>\n<li>可以将<code>\\\\</code>换成<code>\\\\\\\\</code>，可以实现公式的多行正确显示</li>\n</ul>\n<h4 id=\"终极方案\"><a href=\"#终极方案\" class=\"headerlink\" title=\"终极方案\"></a>终极方案</h4><ul>\n<li><p>在官方文档中提到了可以为hexo提供标记，阻止其按照自己的规则解释我们的字符串，显示其原本的含义</p>\n</li>\n<li><p>标记为</p>\n<figure class=\"highlight django\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs django\"><span class=\"hljs-template-tag\">&#123;% <span class=\"hljs-name\">raw</span> %&#125;</span><span class=\"xml\"></span><br><span class=\"xml\">$$</span><br><span class=\"xml\">...</span><br><span class=\"xml\">$$</span><br><span class=\"xml\"></span><span class=\"hljs-template-tag\">&#123;% <span class=\"hljs-name\">endraw</span> %&#125;</span><br></code></pre></td></tr></table></figure></li>\n</ul>\n<h3 id=\"多行显示和对齐\"><a href=\"#多行显示和对齐\" class=\"headerlink\" title=\"多行显示和对齐\"></a>多行显示和对齐</h3><ul>\n<li><p>默认是显示为一行要实现公式多行和对齐可以使用{aligned}模式，使用”&amp;”来标记对齐位置。”\\\\“表示换行</p>\n  <figure class=\"highlight taggerscript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs taggerscript\">$$<br><span class=\"hljs-symbol\">\\b</span>egin&#123;aligned&#125;<br><span class=\"hljs-symbol\">\\b</span>oldsymbol&#123;x&#125;^&#123;<span class=\"hljs-symbol\">\\m</span>athrm&#123;T&#125;&#125;C<span class=\"hljs-symbol\">\\b</span>oldsymbol&#123;x&#125;\t&amp;=<span class=\"hljs-symbol\">\\b</span>oldsymbol&#123;x&#125;^&#123;<span class=\"hljs-symbol\">\\m</span>athrm&#123;T&#125;&#125;<span class=\"hljs-symbol\">\\m</span>athrm&#123;E&#125;<span class=\"hljs-symbol\">\\l</span>eft[<span class=\"hljs-symbol\">\\l</span>eft(X-<span class=\"hljs-symbol\">\\m</span>u<span class=\"hljs-symbol\">\\r</span>ight)<span class=\"hljs-symbol\">\\l</span>eft(X-<span class=\"hljs-symbol\">\\m</span>u<span class=\"hljs-symbol\">\\r</span>ight)^&#123;<span class=\"hljs-symbol\">\\m</span>athrm&#123;T&#125;&#125;<span class=\"hljs-symbol\">\\r</span>ight]<span class=\"hljs-symbol\">\\b</span>oldsymbol&#123;x&#125; \t<br><span class=\"hljs-symbol\">\\\\</span>&amp;=<span class=\"hljs-symbol\">\\m</span>athrm&#123;E&#125;<span class=\"hljs-symbol\">\\l</span>eft[<span class=\"hljs-symbol\">\\b</span>oldsymbol&#123;x&#125;^&#123;<span class=\"hljs-symbol\">\\m</span>athrm&#123;T&#125;&#125;<span class=\"hljs-symbol\">\\l</span>eft(X-<span class=\"hljs-symbol\">\\m</span>u<span class=\"hljs-symbol\">\\r</span>ight)<span class=\"hljs-symbol\">\\l</span>eft(X-<span class=\"hljs-symbol\">\\m</span>u<span class=\"hljs-symbol\">\\r</span>ight)^&#123;<span class=\"hljs-symbol\">\\m</span>athrm&#123;T&#125;&#125;<span class=\"hljs-symbol\">\\b</span>oldsymbol&#123;x&#125;<span class=\"hljs-symbol\">\\r</span>ight] \t<span class=\"hljs-symbol\">\\\\</span>&amp;=<span class=\"hljs-symbol\">\\m</span>athrm&#123;E&#125;<span class=\"hljs-symbol\">\\l</span>eft[<span class=\"hljs-symbol\">\\l</span>eft(<span class=\"hljs-symbol\">\\l</span>eft(X-<span class=\"hljs-symbol\">\\m</span>u<span class=\"hljs-symbol\">\\r</span>ight)^&#123;<span class=\"hljs-symbol\">\\m</span>athrm&#123;T&#125;&#125;<span class=\"hljs-symbol\">\\b</span>oldsymbol&#123;x&#125;<span class=\"hljs-symbol\">\\r</span>ight)^&#123;<span class=\"hljs-symbol\">\\m</span>athrm&#123;T&#125;&#125;<span class=\"hljs-symbol\">\\l</span>eft(<span class=\"hljs-symbol\">\\l</span>eft(X-<span class=\"hljs-symbol\">\\m</span>u<span class=\"hljs-symbol\">\\r</span>ight)^&#123;<span class=\"hljs-symbol\">\\m</span>athrm&#123;T&#125;&#125;<span class=\"hljs-symbol\">\\b</span>oldsymbol&#123;x&#125;<span class=\"hljs-symbol\">\\r</span>ight)<span class=\"hljs-symbol\">\\r</span>ight] \t<br><span class=\"hljs-symbol\">\\\\</span>&amp;=<span class=\"hljs-symbol\">\\m</span>athrm&#123;E&#125;<span class=\"hljs-symbol\">\\l</span>eft(<span class=\"hljs-symbol\">\\l</span>eft<span class=\"hljs-symbol\">\\V</span>ert <span class=\"hljs-symbol\">\\l</span>eft(X-<span class=\"hljs-symbol\">\\m</span>u<span class=\"hljs-symbol\">\\r</span>ight)^&#123;<span class=\"hljs-symbol\">\\m</span>athrm&#123;T&#125;&#125;<span class=\"hljs-symbol\">\\b</span>oldsymbol&#123;x&#125;<span class=\"hljs-symbol\">\\r</span>ight<span class=\"hljs-symbol\">\\V</span>ert ^&#123;2&#125;<span class=\"hljs-symbol\">\\r</span>ight) \t<br><span class=\"hljs-symbol\">\\\\</span>&amp;=<span class=\"hljs-symbol\">\\s</span>igma_&#123;X&#125;^&#123;2&#125;<br><span class=\"hljs-symbol\">\\e</span>nd&#123;aligned&#125;<br>$$<br></code></pre></td></tr></table></figure></li>\n<li><p>显示为</p>\n</li>\n</ul>\n\n$$\n\\begin{aligned}\n\\boldsymbol{x}^{\\mathrm{T}}C\\boldsymbol{x}\t&=\\boldsymbol{x}^{\\mathrm{T}}\\mathrm{E}\\left[\\left(X-\\mu\\right)\\left(X-\\mu\\right)^{\\mathrm{T}}\\right]\\boldsymbol{x} \t\n\\\\&=\\mathrm{E}\\left[\\boldsymbol{x}^{\\mathrm{T}}\\left(X-\\mu\\right)\\left(X-\\mu\\right)^{\\mathrm{T}}\\boldsymbol{x}\\right] \t\\\\&=\\mathrm{E}\\left[\\left(\\left(X-\\mu\\right)^{\\mathrm{T}}\\boldsymbol{x}\\right)^{\\mathrm{T}}\\left(\\left(X-\\mu\\right)^{\\mathrm{T}}\\boldsymbol{x}\\right)\\right] \t\n\\\\&=\\mathrm{E}\\left(\\left\\Vert \\left(X-\\mu\\right)^{\\mathrm{T}}\\boldsymbol{x}\\right\\Vert ^{2}\\right) \t\n\\\\&=\\sigma_{X}^{2}\n\\end{aligned}\n$$\n\n\n"},{"title":"子模块为空的解决方案","date":"2021-08-05T18:09:00.000Z","_content":"\n> 针对子模块文件夹为空的情况，采取下列解决方案。\n>\n> 当一个 git 项目包含子模块（submodule) 时，直接克隆下来的子模块目录里面是空的。\n\n**有两种方法解决**：\n\n### 方法一\n\n如果项目已经克隆到了本地，执行下面的步骤：\n\n1. 初始化本地子模块配置文件\n\n   ```\n   git submodule init\n   ```\n   \n2. 更新项目，抓取子模块内容。\n\n   ```\n   git submodule update\n   ```\n\n### 方法二\n\n另外一种更简单的方法，就是在执行 `git clone` 时加上 `--recursive` 参数。它会自动初始化并更新每一个子模块。例如：\n\n```\ngit clone --recursive https://github.com/example/example.git\n```\n\n","source":"_posts/git_config/git-submodule.md","raw":"---\ntitle: 子模块为空的解决方案\ndate: 2021-08-06 02:09:00\ntags: git\ncategories: git\n---\n\n> 针对子模块文件夹为空的情况，采取下列解决方案。\n>\n> 当一个 git 项目包含子模块（submodule) 时，直接克隆下来的子模块目录里面是空的。\n\n**有两种方法解决**：\n\n### 方法一\n\n如果项目已经克隆到了本地，执行下面的步骤：\n\n1. 初始化本地子模块配置文件\n\n   ```\n   git submodule init\n   ```\n   \n2. 更新项目，抓取子模块内容。\n\n   ```\n   git submodule update\n   ```\n\n### 方法二\n\n另外一种更简单的方法，就是在执行 `git clone` 时加上 `--recursive` 参数。它会自动初始化并更新每一个子模块。例如：\n\n```\ngit clone --recursive https://github.com/example/example.git\n```\n\n","slug":"git_config/git-submodule","published":1,"updated":"2021-08-10T08:44:08.797Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cksa5kset000la0x48z6n6nu5","content":"<blockquote>\n<p>针对子模块文件夹为空的情况，采取下列解决方案。</p>\n<p>当一个 git 项目包含子模块（submodule) 时，直接克隆下来的子模块目录里面是空的。</p>\n</blockquote>\n<p><strong>有两种方法解决</strong>：</p>\n<h3 id=\"方法一\"><a href=\"#方法一\" class=\"headerlink\" title=\"方法一\"></a>方法一</h3><p>如果项目已经克隆到了本地，执行下面的步骤：</p>\n<ol>\n<li><p>初始化本地子模块配置文件</p>\n<figure class=\"highlight csharp\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs csharp\">git submodule <span class=\"hljs-keyword\">init</span><br></code></pre></td></tr></tbody></table></figure></li>\n<li><p>更新项目，抓取子模块内容。</p>\n<figure class=\"highlight ebnf\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs ebnf\"><span class=\"hljs-attribute\">git submodule update</span><br></code></pre></td></tr></tbody></table></figure></li>\n</ol>\n<h3 id=\"方法二\"><a href=\"#方法二\" class=\"headerlink\" title=\"方法二\"></a>方法二</h3><p>另外一种更简单的方法，就是在执行 <code>git clone</code> 时加上 <code>--recursive</code> 参数。它会自动初始化并更新每一个子模块。例如：</p>\n<figure class=\"highlight awk\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs awk\">git clone --recursive https:<span class=\"hljs-regexp\">//gi</span>thub.com<span class=\"hljs-regexp\">/example/</span>example.git<br></code></pre></td></tr></tbody></table></figure>\n\n","site":{"data":{"friends":[{"avatar":"http://image.luokangyuan.com/1_qq_27922023.jpg","name":"码酱","introduction":"我不是大佬，只是在追寻大佬的脚步","url":"http://luokangyuan.com/","title":"前去学习"},{"avatar":"http://image.luokangyuan.com/4027734.jpeg","name":"闪烁之狐","introduction":"编程界大佬，技术牛，人还特别好，不懂的都可以请教大佬","url":"https://blinkfox.github.io/","title":"前去学习"},{"avatar":"http://image.luokangyuan.com/avatar.jpg","name":"ja_rome","introduction":"平凡的脚步也可以走出伟大的行程","url":"https://me.csdn.net/jlh912008548","title":"前去学习"}]}},"excerpt":"","more":"<blockquote>\n<p>针对子模块文件夹为空的情况，采取下列解决方案。</p>\n<p>当一个 git 项目包含子模块（submodule) 时，直接克隆下来的子模块目录里面是空的。</p>\n</blockquote>\n<p><strong>有两种方法解决</strong>：</p>\n<h3 id=\"方法一\"><a href=\"#方法一\" class=\"headerlink\" title=\"方法一\"></a>方法一</h3><p>如果项目已经克隆到了本地，执行下面的步骤：</p>\n<ol>\n<li><p>初始化本地子模块配置文件</p>\n<figure class=\"highlight csharp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs csharp\">git submodule <span class=\"hljs-keyword\">init</span><br></code></pre></td></tr></table></figure></li>\n<li><p>更新项目，抓取子模块内容。</p>\n<figure class=\"highlight ebnf\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs ebnf\"><span class=\"hljs-attribute\">git submodule update</span><br></code></pre></td></tr></table></figure></li>\n</ol>\n<h3 id=\"方法二\"><a href=\"#方法二\" class=\"headerlink\" title=\"方法二\"></a>方法二</h3><p>另外一种更简单的方法，就是在执行 <code>git clone</code> 时加上 <code>--recursive</code> 参数。它会自动初始化并更新每一个子模块。例如：</p>\n<figure class=\"highlight awk\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs awk\">git clone --recursive https:<span class=\"hljs-regexp\">//gi</span>thub.com<span class=\"hljs-regexp\">/example/</span>example.git<br></code></pre></td></tr></table></figure>\n\n"},{"title":"剑指offer03 数组中重复的数字","date":"2021-08-11T02:53:45.000Z","_content":"\n>数组中重复的数字\n\n## 题目\n\n找出数组中重复的数字。\n\n\n在一个长度为 n 的数组 nums 里的所有数字都在 0～n-1 的范围内。数组中某些数字是重复的，但不知道有几个数字重复了，也不知道每个数字重复了几次。请找出数组中任意一个重复的数字。\n\n#### 示例 1：\n\n```\n输入：\n[2, 3, 1, 0, 2, 5, 3]\n输出：2 或 3 \n```\n\n##### 提示：\n\n- 2 <= n <= 100000\n\n#### 题解\n\n创建一个flag数组进行标记；\n\n指定大小的数组创建\n\n- 一维\n\n  a = [0 for _ in range(n)]  《=》  a = [0] * n \n\n- 二维\n\n  a = [[0 for col in range(m)] for row in range(n)]  *# 创建一个n\\*m的二维矩阵a，每个初值都是0*   《=》  a = [[0] \\*m] \\*n \n\n```python\nclass Solution:\n    def findRepeatNumber(self, nums: List[int]) -> int:\n        flag = [0 for _ in range(len(nums))] #创建长度为nums的数组 也可以用[0]*n\n        for x in nums:\n            flag[x] += 1\n            if(flag[x]>1):\n                return x\n```\n\n<font color=purple size=4>实际上无需构建新的数组进行标记，可以直接使用set的长度进行判断。或者使用sort，使用list的sort方法。判断相邻的元素是否相等。</font>\n\n方法1：利用python set的无序不重复特性：利用Python中的set集合为无序不重复集合，通过判断temp_set的长度确定是否是重复数字。\n\n```python\nclass Solution:\n    def findRepeatNumber(self, nums: List[int]) -> int:\n        temp_set = set()\n        repeat = -1\n        for i in range(len(nums)):\n            temp_set.add(nums[i])\n            if len(temp_set) < i + 1:\n                repeat = nums[i]\n                break\n        return repeat\n```\n\n方法2：利用python的sort函数排序，然后计算相邻两个数据是否相等即可。\n\n```python\nclass Solution:\n    def findRepeatNumber(self, nums: List[int]) -> int:\n        nums.sort()\n        for i in range(len(nums)-1):\n            if nums[i]==nums[i+1]:\n                return nums[i]\n```\n","source":"_posts/leetcode/leetcode-offer03.md","raw":"---\ntitle: 剑指offer03 数组中重复的数字\ntags: [剑指,数组]\ncategories: 剑指\ndate: 2021-08-11 10:53:45\n---\n\n>数组中重复的数字\n\n## 题目\n\n找出数组中重复的数字。\n\n\n在一个长度为 n 的数组 nums 里的所有数字都在 0～n-1 的范围内。数组中某些数字是重复的，但不知道有几个数字重复了，也不知道每个数字重复了几次。请找出数组中任意一个重复的数字。\n\n#### 示例 1：\n\n```\n输入：\n[2, 3, 1, 0, 2, 5, 3]\n输出：2 或 3 \n```\n\n##### 提示：\n\n- 2 <= n <= 100000\n\n#### 题解\n\n创建一个flag数组进行标记；\n\n指定大小的数组创建\n\n- 一维\n\n  a = [0 for _ in range(n)]  《=》  a = [0] * n \n\n- 二维\n\n  a = [[0 for col in range(m)] for row in range(n)]  *# 创建一个n\\*m的二维矩阵a，每个初值都是0*   《=》  a = [[0] \\*m] \\*n \n\n```python\nclass Solution:\n    def findRepeatNumber(self, nums: List[int]) -> int:\n        flag = [0 for _ in range(len(nums))] #创建长度为nums的数组 也可以用[0]*n\n        for x in nums:\n            flag[x] += 1\n            if(flag[x]>1):\n                return x\n```\n\n<font color=purple size=4>实际上无需构建新的数组进行标记，可以直接使用set的长度进行判断。或者使用sort，使用list的sort方法。判断相邻的元素是否相等。</font>\n\n方法1：利用python set的无序不重复特性：利用Python中的set集合为无序不重复集合，通过判断temp_set的长度确定是否是重复数字。\n\n```python\nclass Solution:\n    def findRepeatNumber(self, nums: List[int]) -> int:\n        temp_set = set()\n        repeat = -1\n        for i in range(len(nums)):\n            temp_set.add(nums[i])\n            if len(temp_set) < i + 1:\n                repeat = nums[i]\n                break\n        return repeat\n```\n\n方法2：利用python的sort函数排序，然后计算相邻两个数据是否相等即可。\n\n```python\nclass Solution:\n    def findRepeatNumber(self, nums: List[int]) -> int:\n        nums.sort()\n        for i in range(len(nums)-1):\n            if nums[i]==nums[i+1]:\n                return nums[i]\n```\n","slug":"leetcode/leetcode-offer03","published":1,"updated":"2021-08-11T03:23:54.386Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cksa5kseu000na0x4edtzed9i","content":"<blockquote>\n<p>数组中重复的数字</p>\n</blockquote>\n<h2 id=\"题目\"><a href=\"#题目\" class=\"headerlink\" title=\"题目\"></a>题目</h2><p>找出数组中重复的数字。</p>\n<p>在一个长度为 n 的数组 nums 里的所有数字都在 0～n-1 的范围内。数组中某些数字是重复的，但不知道有几个数字重复了，也不知道每个数字重复了几次。请找出数组中任意一个重复的数字。</p>\n<h4 id=\"示例-1：\"><a href=\"#示例-1：\" class=\"headerlink\" title=\"示例 1：\"></a>示例 1：</h4><figure class=\"highlight accesslog\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs accesslog\">输入：<br><span class=\"hljs-string\">[2, 3, 1, 0, 2, 5, 3]</span><br>输出：<span class=\"hljs-number\">2</span> 或 <span class=\"hljs-number\">3</span> <br></code></pre></td></tr></tbody></table></figure>\n\n<h5 id=\"提示：\"><a href=\"#提示：\" class=\"headerlink\" title=\"提示：\"></a>提示：</h5><ul>\n<li>2 &lt;= n &lt;= 100000</li>\n</ul>\n<h4 id=\"题解\"><a href=\"#题解\" class=\"headerlink\" title=\"题解\"></a>题解</h4><p>创建一个flag数组进行标记；</p>\n<p>指定大小的数组创建</p>\n<ul>\n<li><p>一维</p>\n<p>a = [0 for _ in range(n)]  《=》  a = [0] * n </p>\n</li>\n<li><p>二维</p>\n<p>a = [[0 for col in range(m)] for row in range(n)]  <em># 创建一个n*m的二维矩阵a，每个初值都是0</em>   《=》  a = [[0] *m] *n </p>\n</li>\n</ul>\n<figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">Solution</span>:</span><br>    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">findRepeatNumber</span>(<span class=\"hljs-params\">self, nums: <span class=\"hljs-type\">List</span>[<span class=\"hljs-built_in\">int</span>]</span>) -&gt; <span class=\"hljs-built_in\">int</span>:</span><br>        flag = [<span class=\"hljs-number\">0</span> <span class=\"hljs-keyword\">for</span> _ <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(<span class=\"hljs-built_in\">len</span>(nums))] <span class=\"hljs-comment\">#创建长度为nums的数组 也可以用[0]*n</span><br>        <span class=\"hljs-keyword\">for</span> x <span class=\"hljs-keyword\">in</span> nums:<br>            flag[x] += <span class=\"hljs-number\">1</span><br>            <span class=\"hljs-keyword\">if</span>(flag[x]&gt;<span class=\"hljs-number\">1</span>):<br>                <span class=\"hljs-keyword\">return</span> x<br></code></pre></td></tr></tbody></table></figure>\n\n<p><font color=\"purple\" size=\"4\">实际上无需构建新的数组进行标记，可以直接使用set的长度进行判断。或者使用sort，使用list的sort方法。判断相邻的元素是否相等。</font></p>\n<p>方法1：利用python set的无序不重复特性：利用Python中的set集合为无序不重复集合，通过判断temp_set的长度确定是否是重复数字。</p>\n<figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">Solution</span>:</span><br>    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">findRepeatNumber</span>(<span class=\"hljs-params\">self, nums: <span class=\"hljs-type\">List</span>[<span class=\"hljs-built_in\">int</span>]</span>) -&gt; <span class=\"hljs-built_in\">int</span>:</span><br>        temp_set = <span class=\"hljs-built_in\">set</span>()<br>        repeat = -<span class=\"hljs-number\">1</span><br>        <span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(<span class=\"hljs-built_in\">len</span>(nums)):<br>            temp_set.add(nums[i])<br>            <span class=\"hljs-keyword\">if</span> <span class=\"hljs-built_in\">len</span>(temp_set) &lt; i + <span class=\"hljs-number\">1</span>:<br>                repeat = nums[i]<br>                <span class=\"hljs-keyword\">break</span><br>        <span class=\"hljs-keyword\">return</span> repeat<br></code></pre></td></tr></tbody></table></figure>\n\n<p>方法2：利用python的sort函数排序，然后计算相邻两个数据是否相等即可。</p>\n<figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">Solution</span>:</span><br>    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">findRepeatNumber</span>(<span class=\"hljs-params\">self, nums: <span class=\"hljs-type\">List</span>[<span class=\"hljs-built_in\">int</span>]</span>) -&gt; <span class=\"hljs-built_in\">int</span>:</span><br>        nums.sort()<br>        <span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(<span class=\"hljs-built_in\">len</span>(nums)-<span class=\"hljs-number\">1</span>):<br>            <span class=\"hljs-keyword\">if</span> nums[i]==nums[i+<span class=\"hljs-number\">1</span>]:<br>                <span class=\"hljs-keyword\">return</span> nums[i]<br></code></pre></td></tr></tbody></table></figure>\n","site":{"data":{"friends":[{"avatar":"http://image.luokangyuan.com/1_qq_27922023.jpg","name":"码酱","introduction":"我不是大佬，只是在追寻大佬的脚步","url":"http://luokangyuan.com/","title":"前去学习"},{"avatar":"http://image.luokangyuan.com/4027734.jpeg","name":"闪烁之狐","introduction":"编程界大佬，技术牛，人还特别好，不懂的都可以请教大佬","url":"https://blinkfox.github.io/","title":"前去学习"},{"avatar":"http://image.luokangyuan.com/avatar.jpg","name":"ja_rome","introduction":"平凡的脚步也可以走出伟大的行程","url":"https://me.csdn.net/jlh912008548","title":"前去学习"}]}},"excerpt":"","more":"<blockquote>\n<p>数组中重复的数字</p>\n</blockquote>\n<h2 id=\"题目\"><a href=\"#题目\" class=\"headerlink\" title=\"题目\"></a>题目</h2><p>找出数组中重复的数字。</p>\n<p>在一个长度为 n 的数组 nums 里的所有数字都在 0～n-1 的范围内。数组中某些数字是重复的，但不知道有几个数字重复了，也不知道每个数字重复了几次。请找出数组中任意一个重复的数字。</p>\n<h4 id=\"示例-1：\"><a href=\"#示例-1：\" class=\"headerlink\" title=\"示例 1：\"></a>示例 1：</h4><figure class=\"highlight accesslog\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs accesslog\">输入：<br><span class=\"hljs-string\">[2, 3, 1, 0, 2, 5, 3]</span><br>输出：<span class=\"hljs-number\">2</span> 或 <span class=\"hljs-number\">3</span> <br></code></pre></td></tr></table></figure>\n\n<h5 id=\"提示：\"><a href=\"#提示：\" class=\"headerlink\" title=\"提示：\"></a>提示：</h5><ul>\n<li>2 &lt;= n &lt;= 100000</li>\n</ul>\n<h4 id=\"题解\"><a href=\"#题解\" class=\"headerlink\" title=\"题解\"></a>题解</h4><p>创建一个flag数组进行标记；</p>\n<p>指定大小的数组创建</p>\n<ul>\n<li><p>一维</p>\n<p>a = [0 for _ in range(n)]  《=》  a = [0] * n </p>\n</li>\n<li><p>二维</p>\n<p>a = [[0 for col in range(m)] for row in range(n)]  <em># 创建一个n*m的二维矩阵a，每个初值都是0</em>   《=》  a = [[0] *m] *n </p>\n</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">Solution</span>:</span><br>    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">findRepeatNumber</span>(<span class=\"hljs-params\">self, nums: <span class=\"hljs-type\">List</span>[<span class=\"hljs-built_in\">int</span>]</span>) -&gt; <span class=\"hljs-built_in\">int</span>:</span><br>        flag = [<span class=\"hljs-number\">0</span> <span class=\"hljs-keyword\">for</span> _ <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(<span class=\"hljs-built_in\">len</span>(nums))] <span class=\"hljs-comment\">#创建长度为nums的数组 也可以用[0]*n</span><br>        <span class=\"hljs-keyword\">for</span> x <span class=\"hljs-keyword\">in</span> nums:<br>            flag[x] += <span class=\"hljs-number\">1</span><br>            <span class=\"hljs-keyword\">if</span>(flag[x]&gt;<span class=\"hljs-number\">1</span>):<br>                <span class=\"hljs-keyword\">return</span> x<br></code></pre></td></tr></table></figure>\n\n<p><font color=purple size=4>实际上无需构建新的数组进行标记，可以直接使用set的长度进行判断。或者使用sort，使用list的sort方法。判断相邻的元素是否相等。</font></p>\n<p>方法1：利用python set的无序不重复特性：利用Python中的set集合为无序不重复集合，通过判断temp_set的长度确定是否是重复数字。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">Solution</span>:</span><br>    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">findRepeatNumber</span>(<span class=\"hljs-params\">self, nums: <span class=\"hljs-type\">List</span>[<span class=\"hljs-built_in\">int</span>]</span>) -&gt; <span class=\"hljs-built_in\">int</span>:</span><br>        temp_set = <span class=\"hljs-built_in\">set</span>()<br>        repeat = -<span class=\"hljs-number\">1</span><br>        <span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(<span class=\"hljs-built_in\">len</span>(nums)):<br>            temp_set.add(nums[i])<br>            <span class=\"hljs-keyword\">if</span> <span class=\"hljs-built_in\">len</span>(temp_set) &lt; i + <span class=\"hljs-number\">1</span>:<br>                repeat = nums[i]<br>                <span class=\"hljs-keyword\">break</span><br>        <span class=\"hljs-keyword\">return</span> repeat<br></code></pre></td></tr></table></figure>\n\n<p>方法2：利用python的sort函数排序，然后计算相邻两个数据是否相等即可。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">Solution</span>:</span><br>    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">findRepeatNumber</span>(<span class=\"hljs-params\">self, nums: <span class=\"hljs-type\">List</span>[<span class=\"hljs-built_in\">int</span>]</span>) -&gt; <span class=\"hljs-built_in\">int</span>:</span><br>        nums.sort()<br>        <span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(<span class=\"hljs-built_in\">len</span>(nums)-<span class=\"hljs-number\">1</span>):<br>            <span class=\"hljs-keyword\">if</span> nums[i]==nums[i+<span class=\"hljs-number\">1</span>]:<br>                <span class=\"hljs-keyword\">return</span> nums[i]<br></code></pre></td></tr></table></figure>\n"},{"title":"剑指offer05 替换空格","date":"2021-08-11T10:36:13.000Z","_content":"\n>替换空格\n\n## 题目\n\n请实现一个函数，把字符串 `s` 中的每个空格替换成\"%20\"。\n\n#### 示例 1：\n\n```\n输入：s = \"We are happy.\"\n输出：\"We%20are%20happy.\"\n```\n\n##### 提示：\n\n- 0 <= s 的长度 <= 10000\n\n#### 题解\n\n直接替换即可。相当于使用replace方法\n\n```python\nclass Solution:\n    def replaceSpace(self, s: str) -> str:\n       #相当于现成函数 return s.replace(\" \",\"%20\")\n        result = \"\"\n        for x in s:\n            if x==' ':\n                x = \"%20\"\n            result += x\n        return result\n```\n\n","source":"_posts/leetcode/leetcode-offer05.md","raw":"---\ntitle: 剑指offer05 替换空格\ntags: [剑指,字符串]\ncategories: 剑指\ndate: 2021-08-11 18:36:13\n---\n\n>替换空格\n\n## 题目\n\n请实现一个函数，把字符串 `s` 中的每个空格替换成\"%20\"。\n\n#### 示例 1：\n\n```\n输入：s = \"We are happy.\"\n输出：\"We%20are%20happy.\"\n```\n\n##### 提示：\n\n- 0 <= s 的长度 <= 10000\n\n#### 题解\n\n直接替换即可。相当于使用replace方法\n\n```python\nclass Solution:\n    def replaceSpace(self, s: str) -> str:\n       #相当于现成函数 return s.replace(\" \",\"%20\")\n        result = \"\"\n        for x in s:\n            if x==' ':\n                x = \"%20\"\n            result += x\n        return result\n```\n\n","slug":"leetcode/leetcode-offer05","published":1,"updated":"2021-08-11T10:39:06.988Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cksa5ksex000ra0x46zonflea","content":"<blockquote>\n<p>替换空格</p>\n</blockquote>\n<h2 id=\"题目\"><a href=\"#题目\" class=\"headerlink\" title=\"题目\"></a>题目</h2><p>请实现一个函数，把字符串 <code>s</code> 中的每个空格替换成”%20”。</p>\n<h4 id=\"示例-1：\"><a href=\"#示例-1：\" class=\"headerlink\" title=\"示例 1：\"></a>示例 1：</h4><figure class=\"highlight perl\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs perl\">输入：s = <span class=\"hljs-string\">\"We are happy.\"</span><br>输出：<span class=\"hljs-string\">\"We%20are%20happy.\"</span><br></code></pre></td></tr></tbody></table></figure>\n\n<h5 id=\"提示：\"><a href=\"#提示：\" class=\"headerlink\" title=\"提示：\"></a>提示：</h5><ul>\n<li>0 &lt;= s 的长度 &lt;= 10000</li>\n</ul>\n<h4 id=\"题解\"><a href=\"#题解\" class=\"headerlink\" title=\"题解\"></a>题解</h4><p>直接替换即可。相当于使用replace方法</p>\n<figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">Solution</span>:</span><br>    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">replaceSpace</span>(<span class=\"hljs-params\">self, s: <span class=\"hljs-built_in\">str</span></span>) -&gt; <span class=\"hljs-built_in\">str</span>:</span><br>       <span class=\"hljs-comment\">#相当于现成函数 return s.replace(\" \",\"%20\")</span><br>        result = <span class=\"hljs-string\">\"\"</span><br>        <span class=\"hljs-keyword\">for</span> x <span class=\"hljs-keyword\">in</span> s:<br>            <span class=\"hljs-keyword\">if</span> x==<span class=\"hljs-string\">' '</span>:<br>                x = <span class=\"hljs-string\">\"%20\"</span><br>            result += x<br>        <span class=\"hljs-keyword\">return</span> result<br></code></pre></td></tr></tbody></table></figure>\n\n","site":{"data":{"friends":[{"avatar":"http://image.luokangyuan.com/1_qq_27922023.jpg","name":"码酱","introduction":"我不是大佬，只是在追寻大佬的脚步","url":"http://luokangyuan.com/","title":"前去学习"},{"avatar":"http://image.luokangyuan.com/4027734.jpeg","name":"闪烁之狐","introduction":"编程界大佬，技术牛，人还特别好，不懂的都可以请教大佬","url":"https://blinkfox.github.io/","title":"前去学习"},{"avatar":"http://image.luokangyuan.com/avatar.jpg","name":"ja_rome","introduction":"平凡的脚步也可以走出伟大的行程","url":"https://me.csdn.net/jlh912008548","title":"前去学习"}]}},"excerpt":"","more":"<blockquote>\n<p>替换空格</p>\n</blockquote>\n<h2 id=\"题目\"><a href=\"#题目\" class=\"headerlink\" title=\"题目\"></a>题目</h2><p>请实现一个函数，把字符串 <code>s</code> 中的每个空格替换成”%20”。</p>\n<h4 id=\"示例-1：\"><a href=\"#示例-1：\" class=\"headerlink\" title=\"示例 1：\"></a>示例 1：</h4><figure class=\"highlight perl\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs perl\">输入：s = <span class=\"hljs-string\">&quot;We are happy.&quot;</span><br>输出：<span class=\"hljs-string\">&quot;We%20are%20happy.&quot;</span><br></code></pre></td></tr></table></figure>\n\n<h5 id=\"提示：\"><a href=\"#提示：\" class=\"headerlink\" title=\"提示：\"></a>提示：</h5><ul>\n<li>0 &lt;= s 的长度 &lt;= 10000</li>\n</ul>\n<h4 id=\"题解\"><a href=\"#题解\" class=\"headerlink\" title=\"题解\"></a>题解</h4><p>直接替换即可。相当于使用replace方法</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">Solution</span>:</span><br>    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">replaceSpace</span>(<span class=\"hljs-params\">self, s: <span class=\"hljs-built_in\">str</span></span>) -&gt; <span class=\"hljs-built_in\">str</span>:</span><br>       <span class=\"hljs-comment\">#相当于现成函数 return s.replace(&quot; &quot;,&quot;%20&quot;)</span><br>        result = <span class=\"hljs-string\">&quot;&quot;</span><br>        <span class=\"hljs-keyword\">for</span> x <span class=\"hljs-keyword\">in</span> s:<br>            <span class=\"hljs-keyword\">if</span> x==<span class=\"hljs-string\">&#x27; &#x27;</span>:<br>                x = <span class=\"hljs-string\">&quot;%20&quot;</span><br>            result += x<br>        <span class=\"hljs-keyword\">return</span> result<br></code></pre></td></tr></table></figure>\n\n"},{"title":"剑指offer04 二维数组中的查找","date":"2021-08-11T10:07:12.000Z","_content":"\n>二维数组中的查找\n\n## 题目\n\n在一个 n * m 的二维数组中，每一行都按照从左到右递增的顺序排序，每一列都按照从上到下递增的顺序排序。请完成一个高效的函数，输入这样的一个二维数组和一个整数，判断数组中是否含有该整数。\n\n#### 示例 1：\n\n现有矩阵 matrix 如下：\n\n```\n[\n  [1,   4,  7, 11, 15],\n  [2,   5,  8, 12, 19],\n  [3,   6,  9, 16, 22],\n  [10, 13, 14, 17, 24],\n  [18, 21, 23, 26, 30]\n]\n```\n\n给定 target = `5`，返回 `true`。\n\n给定 target = `20`，返回 `false`。\n\n##### 提示：\n\n- 0 <= n <= 1000\n- 0 <= m <= 1000\n\n#### 题解\n\n当开始想要采用二分法的思想进行判断。但是发现二分只能考虑到左上和右下块的内容。右上和左下的内容无法判断其大小划分。所以会有视觉盲区无法二分缩小区域。\n\n<font color=purple>二维数组无法用二分法，因为其“二分”是分为4份，无法充分涵盖进行判断，会出现错误。</font>\n\n```python\nclass Solution:\n    def findNumberIn2DArray(self, matrix: List[List[int]], target: int) -> bool:\n        if not(matrix): return False\n        si,sj = 0,0\n        ei,ej = len(matrix)-1,len(matrix[0])-1\n        def isExit(matrix: List[List[int]], si, sj, ei, ej, target: int):\n            if not (si<=ei and sj<=ej): #先判断范围\n                return False\n            if(target<matrix[si][sj] or target>matrix[ei][ej]): return False\n            if(target==matrix[si][sj] or target==matrix[ei][ej]): return True\n            mi,mj = int((si+ei)/2),int((sj+ej)/2)\n            if(target==matrix[mi][mj]):\n                return True\n            elif (target>matrix[mi][mj]):\n                return isExit(matrix,mi+1,mj,ei,ej,target) or isExit(matrix,mi,mj+1,ei,ej,target)\n            else:\n                return isExit(matrix,si,sj,mi-1,mj,target) or isExit(matrix,si,sj,mi,mj-1,target)\n        return isExit(matrix,si,sj,ei,ej,target)\n```\n使用线性查找的方法，可以使得复杂度从暴力的O(n*m)到O(n+m)\n思想是选取左下角或者右上角，周围不均衡的点开始进行判断，这样才知道应该向哪个方向缩小区域.\n\n<font color=hotpink>例如此处是选取左下角作为初始，向上此列逐渐变小，向右此行逐渐变大。因此target如果比此点小，就向上移动查找，如果比此点大，就向右查找。</font>\n\n```python\nclass Solution:\n    def findNumberIn2DArray(self, matrix: List[List[int]], target: int) -> bool:\n        if not(matrix): return False\n        i,j = len(matrix)-1,0\n        while(i>=0 and j<=len(matrix[0])-1):\n            if(target==matrix[i][j]):return True\n            elif(target>matrix[i][j]):j += 1\n            else:i -= 1\n        return False\n```\n\n","source":"_posts/leetcode/leetcode-offer04.md","raw":"---\ntitle: 剑指offer04 二维数组中的查找\ntags: [剑指,数组查找]\ncategories: 剑指\ndate: 2021-08-11 18:07:12\n---\n\n>二维数组中的查找\n\n## 题目\n\n在一个 n * m 的二维数组中，每一行都按照从左到右递增的顺序排序，每一列都按照从上到下递增的顺序排序。请完成一个高效的函数，输入这样的一个二维数组和一个整数，判断数组中是否含有该整数。\n\n#### 示例 1：\n\n现有矩阵 matrix 如下：\n\n```\n[\n  [1,   4,  7, 11, 15],\n  [2,   5,  8, 12, 19],\n  [3,   6,  9, 16, 22],\n  [10, 13, 14, 17, 24],\n  [18, 21, 23, 26, 30]\n]\n```\n\n给定 target = `5`，返回 `true`。\n\n给定 target = `20`，返回 `false`。\n\n##### 提示：\n\n- 0 <= n <= 1000\n- 0 <= m <= 1000\n\n#### 题解\n\n当开始想要采用二分法的思想进行判断。但是发现二分只能考虑到左上和右下块的内容。右上和左下的内容无法判断其大小划分。所以会有视觉盲区无法二分缩小区域。\n\n<font color=purple>二维数组无法用二分法，因为其“二分”是分为4份，无法充分涵盖进行判断，会出现错误。</font>\n\n```python\nclass Solution:\n    def findNumberIn2DArray(self, matrix: List[List[int]], target: int) -> bool:\n        if not(matrix): return False\n        si,sj = 0,0\n        ei,ej = len(matrix)-1,len(matrix[0])-1\n        def isExit(matrix: List[List[int]], si, sj, ei, ej, target: int):\n            if not (si<=ei and sj<=ej): #先判断范围\n                return False\n            if(target<matrix[si][sj] or target>matrix[ei][ej]): return False\n            if(target==matrix[si][sj] or target==matrix[ei][ej]): return True\n            mi,mj = int((si+ei)/2),int((sj+ej)/2)\n            if(target==matrix[mi][mj]):\n                return True\n            elif (target>matrix[mi][mj]):\n                return isExit(matrix,mi+1,mj,ei,ej,target) or isExit(matrix,mi,mj+1,ei,ej,target)\n            else:\n                return isExit(matrix,si,sj,mi-1,mj,target) or isExit(matrix,si,sj,mi,mj-1,target)\n        return isExit(matrix,si,sj,ei,ej,target)\n```\n使用线性查找的方法，可以使得复杂度从暴力的O(n*m)到O(n+m)\n思想是选取左下角或者右上角，周围不均衡的点开始进行判断，这样才知道应该向哪个方向缩小区域.\n\n<font color=hotpink>例如此处是选取左下角作为初始，向上此列逐渐变小，向右此行逐渐变大。因此target如果比此点小，就向上移动查找，如果比此点大，就向右查找。</font>\n\n```python\nclass Solution:\n    def findNumberIn2DArray(self, matrix: List[List[int]], target: int) -> bool:\n        if not(matrix): return False\n        i,j = len(matrix)-1,0\n        while(i>=0 and j<=len(matrix[0])-1):\n            if(target==matrix[i][j]):return True\n            elif(target>matrix[i][j]):j += 1\n            else:i -= 1\n        return False\n```\n\n","slug":"leetcode/leetcode-offer04","published":1,"updated":"2021-08-11T10:39:14.713Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cksa5ksey000sa0x40r216wc0","content":"<blockquote>\n<p>二维数组中的查找</p>\n</blockquote>\n<h2 id=\"题目\"><a href=\"#题目\" class=\"headerlink\" title=\"题目\"></a>题目</h2><p>在一个 n * m 的二维数组中，每一行都按照从左到右递增的顺序排序，每一列都按照从上到下递增的顺序排序。请完成一个高效的函数，输入这样的一个二维数组和一个整数，判断数组中是否含有该整数。</p>\n<h4 id=\"示例-1：\"><a href=\"#示例-1：\" class=\"headerlink\" title=\"示例 1：\"></a>示例 1：</h4><p>现有矩阵 matrix 如下：</p>\n<figure class=\"highlight json\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs json\">[<br>  [<span class=\"hljs-number\">1</span>,   <span class=\"hljs-number\">4</span>,  <span class=\"hljs-number\">7</span>, <span class=\"hljs-number\">11</span>, <span class=\"hljs-number\">15</span>],<br>  [<span class=\"hljs-number\">2</span>,   <span class=\"hljs-number\">5</span>,  <span class=\"hljs-number\">8</span>, <span class=\"hljs-number\">12</span>, <span class=\"hljs-number\">19</span>],<br>  [<span class=\"hljs-number\">3</span>,   <span class=\"hljs-number\">6</span>,  <span class=\"hljs-number\">9</span>, <span class=\"hljs-number\">16</span>, <span class=\"hljs-number\">22</span>],<br>  [<span class=\"hljs-number\">10</span>, <span class=\"hljs-number\">13</span>, <span class=\"hljs-number\">14</span>, <span class=\"hljs-number\">17</span>, <span class=\"hljs-number\">24</span>],<br>  [<span class=\"hljs-number\">18</span>, <span class=\"hljs-number\">21</span>, <span class=\"hljs-number\">23</span>, <span class=\"hljs-number\">26</span>, <span class=\"hljs-number\">30</span>]<br>]<br></code></pre></td></tr></tbody></table></figure>\n\n<p>给定 target = <code>5</code>，返回 <code>true</code>。</p>\n<p>给定 target = <code>20</code>，返回 <code>false</code>。</p>\n<h5 id=\"提示：\"><a href=\"#提示：\" class=\"headerlink\" title=\"提示：\"></a>提示：</h5><ul>\n<li>0 &lt;= n &lt;= 1000</li>\n<li>0 &lt;= m &lt;= 1000</li>\n</ul>\n<h4 id=\"题解\"><a href=\"#题解\" class=\"headerlink\" title=\"题解\"></a>题解</h4><p>当开始想要采用二分法的思想进行判断。但是发现二分只能考虑到左上和右下块的内容。右上和左下的内容无法判断其大小划分。所以会有视觉盲区无法二分缩小区域。</p>\n<p><font color=\"purple\">二维数组无法用二分法，因为其“二分”是分为4份，无法充分涵盖进行判断，会出现错误。</font></p>\n<figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">Solution</span>:</span><br>    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">findNumberIn2DArray</span>(<span class=\"hljs-params\">self, matrix: <span class=\"hljs-type\">List</span>[<span class=\"hljs-type\">List</span>[<span class=\"hljs-built_in\">int</span>]], target: <span class=\"hljs-built_in\">int</span></span>) -&gt; <span class=\"hljs-built_in\">bool</span>:</span><br>        <span class=\"hljs-keyword\">if</span> <span class=\"hljs-keyword\">not</span>(matrix): <span class=\"hljs-keyword\">return</span> <span class=\"hljs-literal\">False</span><br>        si,sj = <span class=\"hljs-number\">0</span>,<span class=\"hljs-number\">0</span><br>        ei,ej = <span class=\"hljs-built_in\">len</span>(matrix)-<span class=\"hljs-number\">1</span>,<span class=\"hljs-built_in\">len</span>(matrix[<span class=\"hljs-number\">0</span>])-<span class=\"hljs-number\">1</span><br>        <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">isExit</span>(<span class=\"hljs-params\">matrix: <span class=\"hljs-type\">List</span>[<span class=\"hljs-type\">List</span>[<span class=\"hljs-built_in\">int</span>]], si, sj, ei, ej, target: <span class=\"hljs-built_in\">int</span></span>):</span><br>            <span class=\"hljs-keyword\">if</span> <span class=\"hljs-keyword\">not</span> (si&lt;=ei <span class=\"hljs-keyword\">and</span> sj&lt;=ej): <span class=\"hljs-comment\">#先判断范围</span><br>                <span class=\"hljs-keyword\">return</span> <span class=\"hljs-literal\">False</span><br>            <span class=\"hljs-keyword\">if</span>(target&lt;matrix[si][sj] <span class=\"hljs-keyword\">or</span> target&gt;matrix[ei][ej]): <span class=\"hljs-keyword\">return</span> <span class=\"hljs-literal\">False</span><br>            <span class=\"hljs-keyword\">if</span>(target==matrix[si][sj] <span class=\"hljs-keyword\">or</span> target==matrix[ei][ej]): <span class=\"hljs-keyword\">return</span> <span class=\"hljs-literal\">True</span><br>            mi,mj = <span class=\"hljs-built_in\">int</span>((si+ei)/<span class=\"hljs-number\">2</span>),<span class=\"hljs-built_in\">int</span>((sj+ej)/<span class=\"hljs-number\">2</span>)<br>            <span class=\"hljs-keyword\">if</span>(target==matrix[mi][mj]):<br>                <span class=\"hljs-keyword\">return</span> <span class=\"hljs-literal\">True</span><br>            <span class=\"hljs-keyword\">elif</span> (target&gt;matrix[mi][mj]):<br>                <span class=\"hljs-keyword\">return</span> isExit(matrix,mi+<span class=\"hljs-number\">1</span>,mj,ei,ej,target) <span class=\"hljs-keyword\">or</span> isExit(matrix,mi,mj+<span class=\"hljs-number\">1</span>,ei,ej,target)<br>            <span class=\"hljs-keyword\">else</span>:<br>                <span class=\"hljs-keyword\">return</span> isExit(matrix,si,sj,mi-<span class=\"hljs-number\">1</span>,mj,target) <span class=\"hljs-keyword\">or</span> isExit(matrix,si,sj,mi,mj-<span class=\"hljs-number\">1</span>,target)<br>        <span class=\"hljs-keyword\">return</span> isExit(matrix,si,sj,ei,ej,target)<br></code></pre></td></tr></tbody></table></figure>\n<p>使用线性查找的方法，可以使得复杂度从暴力的O(n*m)到O(n+m)<br>思想是选取左下角或者右上角，周围不均衡的点开始进行判断，这样才知道应该向哪个方向缩小区域.</p>\n<p><font color=\"hotpink\">例如此处是选取左下角作为初始，向上此列逐渐变小，向右此行逐渐变大。因此target如果比此点小，就向上移动查找，如果比此点大，就向右查找。</font></p>\n<figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">Solution</span>:</span><br>    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">findNumberIn2DArray</span>(<span class=\"hljs-params\">self, matrix: <span class=\"hljs-type\">List</span>[<span class=\"hljs-type\">List</span>[<span class=\"hljs-built_in\">int</span>]], target: <span class=\"hljs-built_in\">int</span></span>) -&gt; <span class=\"hljs-built_in\">bool</span>:</span><br>        <span class=\"hljs-keyword\">if</span> <span class=\"hljs-keyword\">not</span>(matrix): <span class=\"hljs-keyword\">return</span> <span class=\"hljs-literal\">False</span><br>        i,j = <span class=\"hljs-built_in\">len</span>(matrix)-<span class=\"hljs-number\">1</span>,<span class=\"hljs-number\">0</span><br>        <span class=\"hljs-keyword\">while</span>(i&gt;=<span class=\"hljs-number\">0</span> <span class=\"hljs-keyword\">and</span> j&lt;=<span class=\"hljs-built_in\">len</span>(matrix[<span class=\"hljs-number\">0</span>])-<span class=\"hljs-number\">1</span>):<br>            <span class=\"hljs-keyword\">if</span>(target==matrix[i][j]):<span class=\"hljs-keyword\">return</span> <span class=\"hljs-literal\">True</span><br>            <span class=\"hljs-keyword\">elif</span>(target&gt;matrix[i][j]):j += <span class=\"hljs-number\">1</span><br>            <span class=\"hljs-keyword\">else</span>:i -= <span class=\"hljs-number\">1</span><br>        <span class=\"hljs-keyword\">return</span> <span class=\"hljs-literal\">False</span><br></code></pre></td></tr></tbody></table></figure>\n\n","site":{"data":{"friends":[{"avatar":"http://image.luokangyuan.com/1_qq_27922023.jpg","name":"码酱","introduction":"我不是大佬，只是在追寻大佬的脚步","url":"http://luokangyuan.com/","title":"前去学习"},{"avatar":"http://image.luokangyuan.com/4027734.jpeg","name":"闪烁之狐","introduction":"编程界大佬，技术牛，人还特别好，不懂的都可以请教大佬","url":"https://blinkfox.github.io/","title":"前去学习"},{"avatar":"http://image.luokangyuan.com/avatar.jpg","name":"ja_rome","introduction":"平凡的脚步也可以走出伟大的行程","url":"https://me.csdn.net/jlh912008548","title":"前去学习"}]}},"excerpt":"","more":"<blockquote>\n<p>二维数组中的查找</p>\n</blockquote>\n<h2 id=\"题目\"><a href=\"#题目\" class=\"headerlink\" title=\"题目\"></a>题目</h2><p>在一个 n * m 的二维数组中，每一行都按照从左到右递增的顺序排序，每一列都按照从上到下递增的顺序排序。请完成一个高效的函数，输入这样的一个二维数组和一个整数，判断数组中是否含有该整数。</p>\n<h4 id=\"示例-1：\"><a href=\"#示例-1：\" class=\"headerlink\" title=\"示例 1：\"></a>示例 1：</h4><p>现有矩阵 matrix 如下：</p>\n<figure class=\"highlight json\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs json\">[<br>  [<span class=\"hljs-number\">1</span>,   <span class=\"hljs-number\">4</span>,  <span class=\"hljs-number\">7</span>, <span class=\"hljs-number\">11</span>, <span class=\"hljs-number\">15</span>],<br>  [<span class=\"hljs-number\">2</span>,   <span class=\"hljs-number\">5</span>,  <span class=\"hljs-number\">8</span>, <span class=\"hljs-number\">12</span>, <span class=\"hljs-number\">19</span>],<br>  [<span class=\"hljs-number\">3</span>,   <span class=\"hljs-number\">6</span>,  <span class=\"hljs-number\">9</span>, <span class=\"hljs-number\">16</span>, <span class=\"hljs-number\">22</span>],<br>  [<span class=\"hljs-number\">10</span>, <span class=\"hljs-number\">13</span>, <span class=\"hljs-number\">14</span>, <span class=\"hljs-number\">17</span>, <span class=\"hljs-number\">24</span>],<br>  [<span class=\"hljs-number\">18</span>, <span class=\"hljs-number\">21</span>, <span class=\"hljs-number\">23</span>, <span class=\"hljs-number\">26</span>, <span class=\"hljs-number\">30</span>]<br>]<br></code></pre></td></tr></table></figure>\n\n<p>给定 target = <code>5</code>，返回 <code>true</code>。</p>\n<p>给定 target = <code>20</code>，返回 <code>false</code>。</p>\n<h5 id=\"提示：\"><a href=\"#提示：\" class=\"headerlink\" title=\"提示：\"></a>提示：</h5><ul>\n<li>0 &lt;= n &lt;= 1000</li>\n<li>0 &lt;= m &lt;= 1000</li>\n</ul>\n<h4 id=\"题解\"><a href=\"#题解\" class=\"headerlink\" title=\"题解\"></a>题解</h4><p>当开始想要采用二分法的思想进行判断。但是发现二分只能考虑到左上和右下块的内容。右上和左下的内容无法判断其大小划分。所以会有视觉盲区无法二分缩小区域。</p>\n<p><font color=purple>二维数组无法用二分法，因为其“二分”是分为4份，无法充分涵盖进行判断，会出现错误。</font></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">Solution</span>:</span><br>    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">findNumberIn2DArray</span>(<span class=\"hljs-params\">self, matrix: <span class=\"hljs-type\">List</span>[<span class=\"hljs-type\">List</span>[<span class=\"hljs-built_in\">int</span>]], target: <span class=\"hljs-built_in\">int</span></span>) -&gt; <span class=\"hljs-built_in\">bool</span>:</span><br>        <span class=\"hljs-keyword\">if</span> <span class=\"hljs-keyword\">not</span>(matrix): <span class=\"hljs-keyword\">return</span> <span class=\"hljs-literal\">False</span><br>        si,sj = <span class=\"hljs-number\">0</span>,<span class=\"hljs-number\">0</span><br>        ei,ej = <span class=\"hljs-built_in\">len</span>(matrix)-<span class=\"hljs-number\">1</span>,<span class=\"hljs-built_in\">len</span>(matrix[<span class=\"hljs-number\">0</span>])-<span class=\"hljs-number\">1</span><br>        <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">isExit</span>(<span class=\"hljs-params\">matrix: <span class=\"hljs-type\">List</span>[<span class=\"hljs-type\">List</span>[<span class=\"hljs-built_in\">int</span>]], si, sj, ei, ej, target: <span class=\"hljs-built_in\">int</span></span>):</span><br>            <span class=\"hljs-keyword\">if</span> <span class=\"hljs-keyword\">not</span> (si&lt;=ei <span class=\"hljs-keyword\">and</span> sj&lt;=ej): <span class=\"hljs-comment\">#先判断范围</span><br>                <span class=\"hljs-keyword\">return</span> <span class=\"hljs-literal\">False</span><br>            <span class=\"hljs-keyword\">if</span>(target&lt;matrix[si][sj] <span class=\"hljs-keyword\">or</span> target&gt;matrix[ei][ej]): <span class=\"hljs-keyword\">return</span> <span class=\"hljs-literal\">False</span><br>            <span class=\"hljs-keyword\">if</span>(target==matrix[si][sj] <span class=\"hljs-keyword\">or</span> target==matrix[ei][ej]): <span class=\"hljs-keyword\">return</span> <span class=\"hljs-literal\">True</span><br>            mi,mj = <span class=\"hljs-built_in\">int</span>((si+ei)/<span class=\"hljs-number\">2</span>),<span class=\"hljs-built_in\">int</span>((sj+ej)/<span class=\"hljs-number\">2</span>)<br>            <span class=\"hljs-keyword\">if</span>(target==matrix[mi][mj]):<br>                <span class=\"hljs-keyword\">return</span> <span class=\"hljs-literal\">True</span><br>            <span class=\"hljs-keyword\">elif</span> (target&gt;matrix[mi][mj]):<br>                <span class=\"hljs-keyword\">return</span> isExit(matrix,mi+<span class=\"hljs-number\">1</span>,mj,ei,ej,target) <span class=\"hljs-keyword\">or</span> isExit(matrix,mi,mj+<span class=\"hljs-number\">1</span>,ei,ej,target)<br>            <span class=\"hljs-keyword\">else</span>:<br>                <span class=\"hljs-keyword\">return</span> isExit(matrix,si,sj,mi-<span class=\"hljs-number\">1</span>,mj,target) <span class=\"hljs-keyword\">or</span> isExit(matrix,si,sj,mi,mj-<span class=\"hljs-number\">1</span>,target)<br>        <span class=\"hljs-keyword\">return</span> isExit(matrix,si,sj,ei,ej,target)<br></code></pre></td></tr></table></figure>\n<p>使用线性查找的方法，可以使得复杂度从暴力的O(n*m)到O(n+m)<br>思想是选取左下角或者右上角，周围不均衡的点开始进行判断，这样才知道应该向哪个方向缩小区域.</p>\n<p><font color=hotpink>例如此处是选取左下角作为初始，向上此列逐渐变小，向右此行逐渐变大。因此target如果比此点小，就向上移动查找，如果比此点大，就向右查找。</font></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">Solution</span>:</span><br>    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">findNumberIn2DArray</span>(<span class=\"hljs-params\">self, matrix: <span class=\"hljs-type\">List</span>[<span class=\"hljs-type\">List</span>[<span class=\"hljs-built_in\">int</span>]], target: <span class=\"hljs-built_in\">int</span></span>) -&gt; <span class=\"hljs-built_in\">bool</span>:</span><br>        <span class=\"hljs-keyword\">if</span> <span class=\"hljs-keyword\">not</span>(matrix): <span class=\"hljs-keyword\">return</span> <span class=\"hljs-literal\">False</span><br>        i,j = <span class=\"hljs-built_in\">len</span>(matrix)-<span class=\"hljs-number\">1</span>,<span class=\"hljs-number\">0</span><br>        <span class=\"hljs-keyword\">while</span>(i&gt;=<span class=\"hljs-number\">0</span> <span class=\"hljs-keyword\">and</span> j&lt;=<span class=\"hljs-built_in\">len</span>(matrix[<span class=\"hljs-number\">0</span>])-<span class=\"hljs-number\">1</span>):<br>            <span class=\"hljs-keyword\">if</span>(target==matrix[i][j]):<span class=\"hljs-keyword\">return</span> <span class=\"hljs-literal\">True</span><br>            <span class=\"hljs-keyword\">elif</span>(target&gt;matrix[i][j]):j += <span class=\"hljs-number\">1</span><br>            <span class=\"hljs-keyword\">else</span>:i -= <span class=\"hljs-number\">1</span><br>        <span class=\"hljs-keyword\">return</span> <span class=\"hljs-literal\">False</span><br></code></pre></td></tr></table></figure>\n\n"},{"title":"剑指offer09 用两个栈实现队列","date":"2021-08-10T02:46:28.000Z","_content":"\n> 用两个栈实现队列\n\n## 题目\n\n用两个栈实现一个队列。队列的声明如下，请实现它的两个函数 appendTail 和 deleteHead ，分别完成在队列尾部插入整数和在队列头部删除整数的功能。(若队列中没有元素，deleteHead 操作返回 -1 )\n\n#### 示例 1：\n\n```\n输入：\n[\"CQueue\",\"appendTail\",\"deleteHead\",\"deleteHead\"]\n[[],[3],[],[]]\n输出：[null,null,3,-1]\n```\n\n#### 示例 2：\n\n```\n输入：\n[\"CQueue\",\"deleteHead\",\"appendTail\",\"appendTail\",\"deleteHead\",\"deleteHead\"]\n[[],[],[5],[2],[],[]]\n输出：[null,-1,null,null,5,2]\n```\n\n##### 提示：\n\n- 1 <= values <= 10000\n- 最多会对 appendTail、deleteHead 进行 10000 次调用\n\n#### 题解\n\n使用两个栈，*一个作为插入栈，一个作为删除栈*。`使用list进行相关操作（append，pop）`；在插入时直接对stack1进行append操作，删除时首先需要构建删除栈内容，再进行判断，最后同步到插入栈中（此时删除栈又为空）。\n\n```python\nclass CQueue:\n\n    def __init__(self):\n        # stack1是insert栈 stack2是delete栈\n        self.stack1 = [] #list作用和stack类似\n        self.stack2 = []\n\n    def appendTail(self, value: int) -> None:\n        self.stack1.append(value) # 直接插入栈顶\n\n    def deleteHead(self) -> int:\n        while self.stack1: #首先更新delete栈\n            self.stack2.append(self.stack1.pop())\n        #进行deleteHead操作\n        if not self.stack2: \n            return -1\n        popitem = self.stack2.pop()\n        # 将更新结果写回stack1中 保持一致\n        while self.stack2:\n            self.stack1.append(self.stack2.pop())\n        return popitem\n\n# Your CQueue object will be instantiated and called as such:\n# obj = CQueue()\n# obj.appendTail(value)\n# param_2 = obj.deleteHead()\n```\n\n","source":"_posts/leetcode/leetcode-offer09.md","raw":"---\ntitle: 剑指offer09 用两个栈实现队列\ndate: 2021-08-10 10:46:28\ntags: [剑指,栈]\ncategories: 剑指\n---\n\n> 用两个栈实现队列\n\n## 题目\n\n用两个栈实现一个队列。队列的声明如下，请实现它的两个函数 appendTail 和 deleteHead ，分别完成在队列尾部插入整数和在队列头部删除整数的功能。(若队列中没有元素，deleteHead 操作返回 -1 )\n\n#### 示例 1：\n\n```\n输入：\n[\"CQueue\",\"appendTail\",\"deleteHead\",\"deleteHead\"]\n[[],[3],[],[]]\n输出：[null,null,3,-1]\n```\n\n#### 示例 2：\n\n```\n输入：\n[\"CQueue\",\"deleteHead\",\"appendTail\",\"appendTail\",\"deleteHead\",\"deleteHead\"]\n[[],[],[5],[2],[],[]]\n输出：[null,-1,null,null,5,2]\n```\n\n##### 提示：\n\n- 1 <= values <= 10000\n- 最多会对 appendTail、deleteHead 进行 10000 次调用\n\n#### 题解\n\n使用两个栈，*一个作为插入栈，一个作为删除栈*。`使用list进行相关操作（append，pop）`；在插入时直接对stack1进行append操作，删除时首先需要构建删除栈内容，再进行判断，最后同步到插入栈中（此时删除栈又为空）。\n\n```python\nclass CQueue:\n\n    def __init__(self):\n        # stack1是insert栈 stack2是delete栈\n        self.stack1 = [] #list作用和stack类似\n        self.stack2 = []\n\n    def appendTail(self, value: int) -> None:\n        self.stack1.append(value) # 直接插入栈顶\n\n    def deleteHead(self) -> int:\n        while self.stack1: #首先更新delete栈\n            self.stack2.append(self.stack1.pop())\n        #进行deleteHead操作\n        if not self.stack2: \n            return -1\n        popitem = self.stack2.pop()\n        # 将更新结果写回stack1中 保持一致\n        while self.stack2:\n            self.stack1.append(self.stack2.pop())\n        return popitem\n\n# Your CQueue object will be instantiated and called as such:\n# obj = CQueue()\n# obj.appendTail(value)\n# param_2 = obj.deleteHead()\n```\n\n","slug":"leetcode/leetcode-offer09","published":1,"updated":"2021-08-10T06:25:45.543Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cksa5ksez000wa0x428so4bu3","content":"<blockquote>\n<p>用两个栈实现队列</p>\n</blockquote>\n<h2 id=\"题目\"><a href=\"#题目\" class=\"headerlink\" title=\"题目\"></a>题目</h2><p>用两个栈实现一个队列。队列的声明如下，请实现它的两个函数 appendTail 和 deleteHead ，分别完成在队列尾部插入整数和在队列头部删除整数的功能。(若队列中没有元素，deleteHead 操作返回 -1 )</p>\n<h4 id=\"示例-1：\"><a href=\"#示例-1：\" class=\"headerlink\" title=\"示例 1：\"></a>示例 1：</h4><figure class=\"highlight prolog\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs prolog\">输入：<br>[<span class=\"hljs-string\">\"CQueue\"</span>,<span class=\"hljs-string\">\"appendTail\"</span>,<span class=\"hljs-string\">\"deleteHead\"</span>,<span class=\"hljs-string\">\"deleteHead\"</span>]<br>[[],[<span class=\"hljs-number\">3</span>],[],[]]<br>输出：[null,null,<span class=\"hljs-number\">3</span>,<span class=\"hljs-number\">-1</span>]<br></code></pre></td></tr></tbody></table></figure>\n\n<h4 id=\"示例-2：\"><a href=\"#示例-2：\" class=\"headerlink\" title=\"示例 2：\"></a>示例 2：</h4><figure class=\"highlight prolog\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs prolog\">输入：<br>[<span class=\"hljs-string\">\"CQueue\"</span>,<span class=\"hljs-string\">\"deleteHead\"</span>,<span class=\"hljs-string\">\"appendTail\"</span>,<span class=\"hljs-string\">\"appendTail\"</span>,<span class=\"hljs-string\">\"deleteHead\"</span>,<span class=\"hljs-string\">\"deleteHead\"</span>]<br>[[],[],[<span class=\"hljs-number\">5</span>],[<span class=\"hljs-number\">2</span>],[],[]]<br>输出：[null,<span class=\"hljs-number\">-1</span>,null,null,<span class=\"hljs-number\">5</span>,<span class=\"hljs-number\">2</span>]<br></code></pre></td></tr></tbody></table></figure>\n\n<h5 id=\"提示：\"><a href=\"#提示：\" class=\"headerlink\" title=\"提示：\"></a>提示：</h5><ul>\n<li>1 &lt;= values &lt;= 10000</li>\n<li>最多会对 appendTail、deleteHead 进行 10000 次调用</li>\n</ul>\n<h4 id=\"题解\"><a href=\"#题解\" class=\"headerlink\" title=\"题解\"></a>题解</h4><p>使用两个栈，<em>一个作为插入栈，一个作为删除栈</em>。<code>使用list进行相关操作（append，pop）</code>；在插入时直接对stack1进行append操作，删除时首先需要构建删除栈内容，再进行判断，最后同步到插入栈中（此时删除栈又为空）。</p>\n<figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">CQueue</span>:</span><br><br>    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">__init__</span>(<span class=\"hljs-params\">self</span>):</span><br>        <span class=\"hljs-comment\"># stack1是insert栈 stack2是delete栈</span><br>        self.stack1 = [] <span class=\"hljs-comment\">#list作用和stack类似</span><br>        self.stack2 = []<br><br>    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">appendTail</span>(<span class=\"hljs-params\">self, value: <span class=\"hljs-built_in\">int</span></span>) -&gt; <span class=\"hljs-literal\">None</span>:</span><br>        self.stack1.append(value) <span class=\"hljs-comment\"># 直接插入栈顶</span><br><br>    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">deleteHead</span>(<span class=\"hljs-params\">self</span>) -&gt; <span class=\"hljs-built_in\">int</span>:</span><br>        <span class=\"hljs-keyword\">while</span> self.stack1: <span class=\"hljs-comment\">#首先更新delete栈</span><br>            self.stack2.append(self.stack1.pop())<br>        <span class=\"hljs-comment\">#进行deleteHead操作</span><br>        <span class=\"hljs-keyword\">if</span> <span class=\"hljs-keyword\">not</span> self.stack2: <br>            <span class=\"hljs-keyword\">return</span> -<span class=\"hljs-number\">1</span><br>        popitem = self.stack2.pop()<br>        <span class=\"hljs-comment\"># 将更新结果写回stack1中 保持一致</span><br>        <span class=\"hljs-keyword\">while</span> self.stack2:<br>            self.stack1.append(self.stack2.pop())<br>        <span class=\"hljs-keyword\">return</span> popitem<br><br><span class=\"hljs-comment\"># Your CQueue object will be instantiated and called as such:</span><br><span class=\"hljs-comment\"># obj = CQueue()</span><br><span class=\"hljs-comment\"># obj.appendTail(value)</span><br><span class=\"hljs-comment\"># param_2 = obj.deleteHead()</span><br></code></pre></td></tr></tbody></table></figure>\n\n","site":{"data":{"friends":[{"avatar":"http://image.luokangyuan.com/1_qq_27922023.jpg","name":"码酱","introduction":"我不是大佬，只是在追寻大佬的脚步","url":"http://luokangyuan.com/","title":"前去学习"},{"avatar":"http://image.luokangyuan.com/4027734.jpeg","name":"闪烁之狐","introduction":"编程界大佬，技术牛，人还特别好，不懂的都可以请教大佬","url":"https://blinkfox.github.io/","title":"前去学习"},{"avatar":"http://image.luokangyuan.com/avatar.jpg","name":"ja_rome","introduction":"平凡的脚步也可以走出伟大的行程","url":"https://me.csdn.net/jlh912008548","title":"前去学习"}]}},"excerpt":"","more":"<blockquote>\n<p>用两个栈实现队列</p>\n</blockquote>\n<h2 id=\"题目\"><a href=\"#题目\" class=\"headerlink\" title=\"题目\"></a>题目</h2><p>用两个栈实现一个队列。队列的声明如下，请实现它的两个函数 appendTail 和 deleteHead ，分别完成在队列尾部插入整数和在队列头部删除整数的功能。(若队列中没有元素，deleteHead 操作返回 -1 )</p>\n<h4 id=\"示例-1：\"><a href=\"#示例-1：\" class=\"headerlink\" title=\"示例 1：\"></a>示例 1：</h4><figure class=\"highlight prolog\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs prolog\">输入：<br>[<span class=\"hljs-string\">&quot;CQueue&quot;</span>,<span class=\"hljs-string\">&quot;appendTail&quot;</span>,<span class=\"hljs-string\">&quot;deleteHead&quot;</span>,<span class=\"hljs-string\">&quot;deleteHead&quot;</span>]<br>[[],[<span class=\"hljs-number\">3</span>],[],[]]<br>输出：[null,null,<span class=\"hljs-number\">3</span>,<span class=\"hljs-number\">-1</span>]<br></code></pre></td></tr></table></figure>\n\n<h4 id=\"示例-2：\"><a href=\"#示例-2：\" class=\"headerlink\" title=\"示例 2：\"></a>示例 2：</h4><figure class=\"highlight prolog\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs prolog\">输入：<br>[<span class=\"hljs-string\">&quot;CQueue&quot;</span>,<span class=\"hljs-string\">&quot;deleteHead&quot;</span>,<span class=\"hljs-string\">&quot;appendTail&quot;</span>,<span class=\"hljs-string\">&quot;appendTail&quot;</span>,<span class=\"hljs-string\">&quot;deleteHead&quot;</span>,<span class=\"hljs-string\">&quot;deleteHead&quot;</span>]<br>[[],[],[<span class=\"hljs-number\">5</span>],[<span class=\"hljs-number\">2</span>],[],[]]<br>输出：[null,<span class=\"hljs-number\">-1</span>,null,null,<span class=\"hljs-number\">5</span>,<span class=\"hljs-number\">2</span>]<br></code></pre></td></tr></table></figure>\n\n<h5 id=\"提示：\"><a href=\"#提示：\" class=\"headerlink\" title=\"提示：\"></a>提示：</h5><ul>\n<li>1 &lt;= values &lt;= 10000</li>\n<li>最多会对 appendTail、deleteHead 进行 10000 次调用</li>\n</ul>\n<h4 id=\"题解\"><a href=\"#题解\" class=\"headerlink\" title=\"题解\"></a>题解</h4><p>使用两个栈，<em>一个作为插入栈，一个作为删除栈</em>。<code>使用list进行相关操作（append，pop）</code>；在插入时直接对stack1进行append操作，删除时首先需要构建删除栈内容，再进行判断，最后同步到插入栈中（此时删除栈又为空）。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">CQueue</span>:</span><br><br>    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">__init__</span>(<span class=\"hljs-params\">self</span>):</span><br>        <span class=\"hljs-comment\"># stack1是insert栈 stack2是delete栈</span><br>        self.stack1 = [] <span class=\"hljs-comment\">#list作用和stack类似</span><br>        self.stack2 = []<br><br>    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">appendTail</span>(<span class=\"hljs-params\">self, value: <span class=\"hljs-built_in\">int</span></span>) -&gt; <span class=\"hljs-literal\">None</span>:</span><br>        self.stack1.append(value) <span class=\"hljs-comment\"># 直接插入栈顶</span><br><br>    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">deleteHead</span>(<span class=\"hljs-params\">self</span>) -&gt; <span class=\"hljs-built_in\">int</span>:</span><br>        <span class=\"hljs-keyword\">while</span> self.stack1: <span class=\"hljs-comment\">#首先更新delete栈</span><br>            self.stack2.append(self.stack1.pop())<br>        <span class=\"hljs-comment\">#进行deleteHead操作</span><br>        <span class=\"hljs-keyword\">if</span> <span class=\"hljs-keyword\">not</span> self.stack2: <br>            <span class=\"hljs-keyword\">return</span> -<span class=\"hljs-number\">1</span><br>        popitem = self.stack2.pop()<br>        <span class=\"hljs-comment\"># 将更新结果写回stack1中 保持一致</span><br>        <span class=\"hljs-keyword\">while</span> self.stack2:<br>            self.stack1.append(self.stack2.pop())<br>        <span class=\"hljs-keyword\">return</span> popitem<br><br><span class=\"hljs-comment\"># Your CQueue object will be instantiated and called as such:</span><br><span class=\"hljs-comment\"># obj = CQueue()</span><br><span class=\"hljs-comment\"># obj.appendTail(value)</span><br><span class=\"hljs-comment\"># param_2 = obj.deleteHead()</span><br></code></pre></td></tr></table></figure>\n\n"},{"title":"剑指offer10-1 斐波那契数列","date":"2021-08-10T03:55:26.000Z","math":true,"_content":"\n>斐波那契数列\n\n## 题目\n\n写一个函数，输入 n ，求斐波那契（Fibonacci）数列的第 n 项（即 F(N)）。斐波那契数列的定义如下：\n\n$$\nF(0) = 0,   F(1) = 1 \\\\\\\\\nF(N) = F(N - 1) + F(N - 2), 其中 N > 1.\n$$\n斐波那契数列由 0 和 1 开始，之后的斐波那契数就是由之前的两数相加而得出。\n\n答案需要取模 1e9+7（1000000007），如计算初始结果为：1000000008，请返回 1。\n\n#### 示例 1：\n\n```\n输入：n = 2\n输出：1\n```\n\n#### 示例 2：\n\n```\n输入：n = 5\n输出：5\n```\n\n##### 提示：\n\n- 0 <= n <= 100\n\n#### 题解\n\n有三种方向：\n\n- 使用递归\n\n  大量重复计算，时间超时。\n\n- 使用数组存储\n\n  新建长度为n的数组，在递归基础上，存储计算的结果，后直接取用。但是占用了额外的空间$O(n)$\n\n- 使用动态规划\n\n  `以其公式F(N) = F(N - 1) + F(N - 2)为转移方程。`\n\n```python\nclass Solution:\n    def fib(self, n: int) -> int:\n        a,b = 0,1\n        for _ in range(n):\n            a,b = b,a+b #sum = a+b a = b b = sum a相当于f(i) b相当于f(i+1)\n        return a%1000000007\n    # def fib(self, n: int) -> int:\n    #     if(n==0): return 0\n    #     if(n==1): return 1\n    #     return (self.fib(n-1)+self.fib(n-2))%1000000007 #超时 递归时间复杂度大\n```\n\n循环n次\n\n注意`a,b = b,a+b` 相当于sum = a+b ；a = b； b = sum ；\n\n第i轮中 a相当于f(i)，b相当于f(i+1) 。因此最后返回a\n\n","source":"_posts/leetcode/leetcode-offer10-1.md","raw":"---\ntitle: 剑指offer10-1 斐波那契数列\ntags: [剑指,斐波那契,动态规划]\ncategories: 剑指\ndate: 2021-08-10 11:55:26\nmath: true\n---\n\n>斐波那契数列\n\n## 题目\n\n写一个函数，输入 n ，求斐波那契（Fibonacci）数列的第 n 项（即 F(N)）。斐波那契数列的定义如下：\n\n$$\nF(0) = 0,   F(1) = 1 \\\\\\\\\nF(N) = F(N - 1) + F(N - 2), 其中 N > 1.\n$$\n斐波那契数列由 0 和 1 开始，之后的斐波那契数就是由之前的两数相加而得出。\n\n答案需要取模 1e9+7（1000000007），如计算初始结果为：1000000008，请返回 1。\n\n#### 示例 1：\n\n```\n输入：n = 2\n输出：1\n```\n\n#### 示例 2：\n\n```\n输入：n = 5\n输出：5\n```\n\n##### 提示：\n\n- 0 <= n <= 100\n\n#### 题解\n\n有三种方向：\n\n- 使用递归\n\n  大量重复计算，时间超时。\n\n- 使用数组存储\n\n  新建长度为n的数组，在递归基础上，存储计算的结果，后直接取用。但是占用了额外的空间$O(n)$\n\n- 使用动态规划\n\n  `以其公式F(N) = F(N - 1) + F(N - 2)为转移方程。`\n\n```python\nclass Solution:\n    def fib(self, n: int) -> int:\n        a,b = 0,1\n        for _ in range(n):\n            a,b = b,a+b #sum = a+b a = b b = sum a相当于f(i) b相当于f(i+1)\n        return a%1000000007\n    # def fib(self, n: int) -> int:\n    #     if(n==0): return 0\n    #     if(n==1): return 1\n    #     return (self.fib(n-1)+self.fib(n-2))%1000000007 #超时 递归时间复杂度大\n```\n\n循环n次\n\n注意`a,b = b,a+b` 相当于sum = a+b ；a = b； b = sum ；\n\n第i轮中 a相当于f(i)，b相当于f(i+1) 。因此最后返回a\n\n","slug":"leetcode/leetcode-offer10-1","published":1,"updated":"2021-08-10T06:35:19.739Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cksa5ksez000ya0x42lk4gie1","content":"<blockquote>\n<p>斐波那契数列</p>\n</blockquote>\n<h2 id=\"题目\"><a href=\"#题目\" class=\"headerlink\" title=\"题目\"></a>题目</h2><p>写一个函数，输入 n ，求斐波那契（Fibonacci）数列的第 n 项（即 F(N)）。斐波那契数列的定义如下：</p>\n<p>$$<br>F(0) = 0,   F(1) = 1 \\\\<br>F(N) = F(N - 1) + F(N - 2), 其中 N &gt; 1.<br>$$<br>斐波那契数列由 0 和 1 开始，之后的斐波那契数就是由之前的两数相加而得出。</p>\n<p>答案需要取模 1e9+7（1000000007），如计算初始结果为：1000000008，请返回 1。</p>\n<h4 id=\"示例-1：\"><a href=\"#示例-1：\" class=\"headerlink\" title=\"示例 1：\"></a>示例 1：</h4><figure class=\"highlight excel\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs excel\">输入：<span class=\"hljs-built_in\">n</span> = <span class=\"hljs-number\">2</span><br>输出：<span class=\"hljs-number\">1</span><br></code></pre></td></tr></tbody></table></figure>\n\n<h4 id=\"示例-2：\"><a href=\"#示例-2：\" class=\"headerlink\" title=\"示例 2：\"></a>示例 2：</h4><figure class=\"highlight excel\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs excel\">输入：<span class=\"hljs-built_in\">n</span> = <span class=\"hljs-number\">5</span><br>输出：<span class=\"hljs-number\">5</span><br></code></pre></td></tr></tbody></table></figure>\n\n<h5 id=\"提示：\"><a href=\"#提示：\" class=\"headerlink\" title=\"提示：\"></a>提示：</h5><ul>\n<li>0 &lt;= n &lt;= 100</li>\n</ul>\n<h4 id=\"题解\"><a href=\"#题解\" class=\"headerlink\" title=\"题解\"></a>题解</h4><p>有三种方向：</p>\n<ul>\n<li><p>使用递归</p>\n<p>大量重复计算，时间超时。</p>\n</li>\n<li><p>使用数组存储</p>\n<p>新建长度为n的数组，在递归基础上，存储计算的结果，后直接取用。但是占用了额外的空间$O(n)$</p>\n</li>\n<li><p>使用动态规划</p>\n<p><code>以其公式F(N) = F(N - 1) + F(N - 2)为转移方程。</code></p>\n</li>\n</ul>\n<figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">Solution</span>:</span><br>    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">fib</span>(<span class=\"hljs-params\">self, n: <span class=\"hljs-built_in\">int</span></span>) -&gt; <span class=\"hljs-built_in\">int</span>:</span><br>        a,b = <span class=\"hljs-number\">0</span>,<span class=\"hljs-number\">1</span><br>        <span class=\"hljs-keyword\">for</span> _ <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(n):<br>            a,b = b,a+b <span class=\"hljs-comment\">#sum = a+b a = b b = sum a相当于f(i) b相当于f(i+1)</span><br>        <span class=\"hljs-keyword\">return</span> a%<span class=\"hljs-number\">1000000007</span><br>    <span class=\"hljs-comment\"># def fib(self, n: int) -&gt; int:</span><br>    <span class=\"hljs-comment\">#     if(n==0): return 0</span><br>    <span class=\"hljs-comment\">#     if(n==1): return 1</span><br>    <span class=\"hljs-comment\">#     return (self.fib(n-1)+self.fib(n-2))%1000000007 #超时 递归时间复杂度大</span><br></code></pre></td></tr></tbody></table></figure>\n\n<p>循环n次</p>\n<p>注意<code>a,b = b,a+b</code> 相当于sum = a+b ；a = b； b = sum ；</p>\n<p>第i轮中 a相当于f(i)，b相当于f(i+1) 。因此最后返回a</p>\n","site":{"data":{"friends":[{"avatar":"http://image.luokangyuan.com/1_qq_27922023.jpg","name":"码酱","introduction":"我不是大佬，只是在追寻大佬的脚步","url":"http://luokangyuan.com/","title":"前去学习"},{"avatar":"http://image.luokangyuan.com/4027734.jpeg","name":"闪烁之狐","introduction":"编程界大佬，技术牛，人还特别好，不懂的都可以请教大佬","url":"https://blinkfox.github.io/","title":"前去学习"},{"avatar":"http://image.luokangyuan.com/avatar.jpg","name":"ja_rome","introduction":"平凡的脚步也可以走出伟大的行程","url":"https://me.csdn.net/jlh912008548","title":"前去学习"}]}},"excerpt":"","more":"<blockquote>\n<p>斐波那契数列</p>\n</blockquote>\n<h2 id=\"题目\"><a href=\"#题目\" class=\"headerlink\" title=\"题目\"></a>题目</h2><p>写一个函数，输入 n ，求斐波那契（Fibonacci）数列的第 n 项（即 F(N)）。斐波那契数列的定义如下：</p>\n<p>$$<br>F(0) = 0,   F(1) = 1 \\\\<br>F(N) = F(N - 1) + F(N - 2), 其中 N &gt; 1.<br>$$<br>斐波那契数列由 0 和 1 开始，之后的斐波那契数就是由之前的两数相加而得出。</p>\n<p>答案需要取模 1e9+7（1000000007），如计算初始结果为：1000000008，请返回 1。</p>\n<h4 id=\"示例-1：\"><a href=\"#示例-1：\" class=\"headerlink\" title=\"示例 1：\"></a>示例 1：</h4><figure class=\"highlight excel\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs excel\">输入：<span class=\"hljs-built_in\">n</span> = <span class=\"hljs-number\">2</span><br>输出：<span class=\"hljs-number\">1</span><br></code></pre></td></tr></table></figure>\n\n<h4 id=\"示例-2：\"><a href=\"#示例-2：\" class=\"headerlink\" title=\"示例 2：\"></a>示例 2：</h4><figure class=\"highlight excel\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs excel\">输入：<span class=\"hljs-built_in\">n</span> = <span class=\"hljs-number\">5</span><br>输出：<span class=\"hljs-number\">5</span><br></code></pre></td></tr></table></figure>\n\n<h5 id=\"提示：\"><a href=\"#提示：\" class=\"headerlink\" title=\"提示：\"></a>提示：</h5><ul>\n<li>0 &lt;= n &lt;= 100</li>\n</ul>\n<h4 id=\"题解\"><a href=\"#题解\" class=\"headerlink\" title=\"题解\"></a>题解</h4><p>有三种方向：</p>\n<ul>\n<li><p>使用递归</p>\n<p>大量重复计算，时间超时。</p>\n</li>\n<li><p>使用数组存储</p>\n<p>新建长度为n的数组，在递归基础上，存储计算的结果，后直接取用。但是占用了额外的空间$O(n)$</p>\n</li>\n<li><p>使用动态规划</p>\n<p><code>以其公式F(N) = F(N - 1) + F(N - 2)为转移方程。</code></p>\n</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">Solution</span>:</span><br>    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">fib</span>(<span class=\"hljs-params\">self, n: <span class=\"hljs-built_in\">int</span></span>) -&gt; <span class=\"hljs-built_in\">int</span>:</span><br>        a,b = <span class=\"hljs-number\">0</span>,<span class=\"hljs-number\">1</span><br>        <span class=\"hljs-keyword\">for</span> _ <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(n):<br>            a,b = b,a+b <span class=\"hljs-comment\">#sum = a+b a = b b = sum a相当于f(i) b相当于f(i+1)</span><br>        <span class=\"hljs-keyword\">return</span> a%<span class=\"hljs-number\">1000000007</span><br>    <span class=\"hljs-comment\"># def fib(self, n: int) -&gt; int:</span><br>    <span class=\"hljs-comment\">#     if(n==0): return 0</span><br>    <span class=\"hljs-comment\">#     if(n==1): return 1</span><br>    <span class=\"hljs-comment\">#     return (self.fib(n-1)+self.fib(n-2))%1000000007 #超时 递归时间复杂度大</span><br></code></pre></td></tr></table></figure>\n\n<p>循环n次</p>\n<p>注意<code>a,b = b,a+b</code> 相当于sum = a+b ；a = b； b = sum ；</p>\n<p>第i轮中 a相当于f(i)，b相当于f(i+1) 。因此最后返回a</p>\n"},{"title":"剑指offer10-2 青蛙跳台阶问题","date":"2021-08-10T06:22:55.000Z","math":true,"_content":"\n>青蛙跳台阶问题\n\n## 题目\n\n一只青蛙一次可以跳上1级台阶，也可以跳上2级台阶。求该青蛙跳上一个 n 级的台阶总共有多少种跳法。\n\n答案需要取模 1e9+7（1000000007），如计算初始结果为：1000000008，请返回 1。\n\n#### 示例 1：\n\n```\n输入：n = 2\n输出：2\n```\n\n#### 示例 2：\n\n```\n输入：n = 7\n输出：21\n```\n#### 示例3：\n```\n输入：n = 0\n输出：1\n```\n\n##### 提示：\n\n- 0 <= n <= 100\n\n#### 题解\n\n实际上是斐波那契数列的变种。跳上n级台阶的方法个数 可以分解为：*跳上此台阶前的一步是1步还是2步*。也就是 $f(n) = f(n-1) + f(n-2)$。\n\n不同之处在于此时的f(0) = 1\n\n```python\nclass Solution:\n    def numWays(self, n: int) -> int:\n        a,b = 1,1\n        for _ in range(n):\n            a,b = b,a+b\n        return a%1000000007\n```\n\n","source":"_posts/leetcode/leetcode-offer10-2.md","raw":"---\ntitle: 剑指offer10-2 青蛙跳台阶问题\ntags: [剑指,斐波那契,动态规划]\ncategories: 剑指\ndate: 2021-08-10 14:22:55\nmath: true\n---\n\n>青蛙跳台阶问题\n\n## 题目\n\n一只青蛙一次可以跳上1级台阶，也可以跳上2级台阶。求该青蛙跳上一个 n 级的台阶总共有多少种跳法。\n\n答案需要取模 1e9+7（1000000007），如计算初始结果为：1000000008，请返回 1。\n\n#### 示例 1：\n\n```\n输入：n = 2\n输出：2\n```\n\n#### 示例 2：\n\n```\n输入：n = 7\n输出：21\n```\n#### 示例3：\n```\n输入：n = 0\n输出：1\n```\n\n##### 提示：\n\n- 0 <= n <= 100\n\n#### 题解\n\n实际上是斐波那契数列的变种。跳上n级台阶的方法个数 可以分解为：*跳上此台阶前的一步是1步还是2步*。也就是 $f(n) = f(n-1) + f(n-2)$。\n\n不同之处在于此时的f(0) = 1\n\n```python\nclass Solution:\n    def numWays(self, n: int) -> int:\n        a,b = 1,1\n        for _ in range(n):\n            a,b = b,a+b\n        return a%1000000007\n```\n\n","slug":"leetcode/leetcode-offer10-2","published":1,"updated":"2021-08-10T06:55:37.399Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cksa5ksf00012a0x4hvx7c32h","content":"<blockquote>\n<p>青蛙跳台阶问题</p>\n</blockquote>\n<h2 id=\"题目\"><a href=\"#题目\" class=\"headerlink\" title=\"题目\"></a>题目</h2><p>一只青蛙一次可以跳上1级台阶，也可以跳上2级台阶。求该青蛙跳上一个 n 级的台阶总共有多少种跳法。</p>\n<p>答案需要取模 1e9+7（1000000007），如计算初始结果为：1000000008，请返回 1。</p>\n<h4 id=\"示例-1：\"><a href=\"#示例-1：\" class=\"headerlink\" title=\"示例 1：\"></a>示例 1：</h4><figure class=\"highlight excel\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs excel\">输入：<span class=\"hljs-built_in\">n</span> = <span class=\"hljs-number\">2</span><br>输出：<span class=\"hljs-number\">2</span><br></code></pre></td></tr></tbody></table></figure>\n\n<h4 id=\"示例-2：\"><a href=\"#示例-2：\" class=\"headerlink\" title=\"示例 2：\"></a>示例 2：</h4><figure class=\"highlight excel\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs excel\">输入：<span class=\"hljs-built_in\">n</span> = <span class=\"hljs-number\">7</span><br>输出：<span class=\"hljs-number\">21</span><br></code></pre></td></tr></tbody></table></figure>\n<h4 id=\"示例3：\"><a href=\"#示例3：\" class=\"headerlink\" title=\"示例3：\"></a>示例3：</h4><figure class=\"highlight excel\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs excel\">输入：<span class=\"hljs-built_in\">n</span> = <span class=\"hljs-number\">0</span><br>输出：<span class=\"hljs-number\">1</span><br></code></pre></td></tr></tbody></table></figure>\n\n<h5 id=\"提示：\"><a href=\"#提示：\" class=\"headerlink\" title=\"提示：\"></a>提示：</h5><ul>\n<li>0 &lt;= n &lt;= 100</li>\n</ul>\n<h4 id=\"题解\"><a href=\"#题解\" class=\"headerlink\" title=\"题解\"></a>题解</h4><p>实际上是斐波那契数列的变种。跳上n级台阶的方法个数 可以分解为：<em>跳上此台阶前的一步是1步还是2步</em>。也就是 $f(n) = f(n-1) + f(n-2)$。</p>\n<p>不同之处在于此时的f(0) = 1</p>\n<figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">Solution</span>:</span><br>    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">numWays</span>(<span class=\"hljs-params\">self, n: <span class=\"hljs-built_in\">int</span></span>) -&gt; <span class=\"hljs-built_in\">int</span>:</span><br>        a,b = <span class=\"hljs-number\">1</span>,<span class=\"hljs-number\">1</span><br>        <span class=\"hljs-keyword\">for</span> _ <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(n):<br>            a,b = b,a+b<br>        <span class=\"hljs-keyword\">return</span> a%<span class=\"hljs-number\">1000000007</span><br></code></pre></td></tr></tbody></table></figure>\n\n","site":{"data":{"friends":[{"avatar":"http://image.luokangyuan.com/1_qq_27922023.jpg","name":"码酱","introduction":"我不是大佬，只是在追寻大佬的脚步","url":"http://luokangyuan.com/","title":"前去学习"},{"avatar":"http://image.luokangyuan.com/4027734.jpeg","name":"闪烁之狐","introduction":"编程界大佬，技术牛，人还特别好，不懂的都可以请教大佬","url":"https://blinkfox.github.io/","title":"前去学习"},{"avatar":"http://image.luokangyuan.com/avatar.jpg","name":"ja_rome","introduction":"平凡的脚步也可以走出伟大的行程","url":"https://me.csdn.net/jlh912008548","title":"前去学习"}]}},"excerpt":"","more":"<blockquote>\n<p>青蛙跳台阶问题</p>\n</blockquote>\n<h2 id=\"题目\"><a href=\"#题目\" class=\"headerlink\" title=\"题目\"></a>题目</h2><p>一只青蛙一次可以跳上1级台阶，也可以跳上2级台阶。求该青蛙跳上一个 n 级的台阶总共有多少种跳法。</p>\n<p>答案需要取模 1e9+7（1000000007），如计算初始结果为：1000000008，请返回 1。</p>\n<h4 id=\"示例-1：\"><a href=\"#示例-1：\" class=\"headerlink\" title=\"示例 1：\"></a>示例 1：</h4><figure class=\"highlight excel\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs excel\">输入：<span class=\"hljs-built_in\">n</span> = <span class=\"hljs-number\">2</span><br>输出：<span class=\"hljs-number\">2</span><br></code></pre></td></tr></table></figure>\n\n<h4 id=\"示例-2：\"><a href=\"#示例-2：\" class=\"headerlink\" title=\"示例 2：\"></a>示例 2：</h4><figure class=\"highlight excel\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs excel\">输入：<span class=\"hljs-built_in\">n</span> = <span class=\"hljs-number\">7</span><br>输出：<span class=\"hljs-number\">21</span><br></code></pre></td></tr></table></figure>\n<h4 id=\"示例3：\"><a href=\"#示例3：\" class=\"headerlink\" title=\"示例3：\"></a>示例3：</h4><figure class=\"highlight excel\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs excel\">输入：<span class=\"hljs-built_in\">n</span> = <span class=\"hljs-number\">0</span><br>输出：<span class=\"hljs-number\">1</span><br></code></pre></td></tr></table></figure>\n\n<h5 id=\"提示：\"><a href=\"#提示：\" class=\"headerlink\" title=\"提示：\"></a>提示：</h5><ul>\n<li>0 &lt;= n &lt;= 100</li>\n</ul>\n<h4 id=\"题解\"><a href=\"#题解\" class=\"headerlink\" title=\"题解\"></a>题解</h4><p>实际上是斐波那契数列的变种。跳上n级台阶的方法个数 可以分解为：<em>跳上此台阶前的一步是1步还是2步</em>。也就是 $f(n) = f(n-1) + f(n-2)$。</p>\n<p>不同之处在于此时的f(0) = 1</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">Solution</span>:</span><br>    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">numWays</span>(<span class=\"hljs-params\">self, n: <span class=\"hljs-built_in\">int</span></span>) -&gt; <span class=\"hljs-built_in\">int</span>:</span><br>        a,b = <span class=\"hljs-number\">1</span>,<span class=\"hljs-number\">1</span><br>        <span class=\"hljs-keyword\">for</span> _ <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(n):<br>            a,b = b,a+b<br>        <span class=\"hljs-keyword\">return</span> a%<span class=\"hljs-number\">1000000007</span><br></code></pre></td></tr></table></figure>\n\n"},{"title":"Eckark_young定理","date":"2021-08-09T02:57:16.000Z","math":true,"_content":"\n最佳低秩逼近和奇异值的关系(*Eckart*-*Young定理*)\n### 定理\nSuppose a matrix $A\\in \\mathbb{R}^{m\\times n}$has an SVD-decomposition$A=U\\Sigma V^T$. Let $k < r= \\mathsf{rank}(A)$and truncated matrix\n$$\nA_k = \\sum_{i=1}^k \\sigma_i \\mathbf u_i \\mathbf v_i^T,\n$$\nthen, for any matrix B of rank k , the minimal error is achieved with $A_k$:\n\n{% raw %}\n$$\n\\min_{\\mathsf{rank}(B)=k}||A-B||_2 = || A - A_k||_2 = \\sigma_{k+1}.\n$$\n{% endraw %}\n\nThe same holds for Frobenius norm as well\n\n{% raw %}\n$$\n\\min_{\\mathsf{rank}(B)=k}||A-B||_F = || A - A_k||_F = \\sqrt{\\sigma_{k+1}^2 + \\cdots + \\sigma_p^2}.\n$$\n\n{% endraw %}\n\n### 证明 (2-norm case)\n\nSince $U^\\ A_k V = \\mathrm{diag}(\\sigma_1,\\ldots, \\sigma_k,0,\\ldots,0)$ it means that $A_k$ is rank K. Moreover, $U^T (A-A_k) V =  \\mathrm{diag}(0,\\ldots, 0,\\sigma_{k+1},\\ldots, \\sigma_p)$with the largest singular value is $\\sigma_{k+1}$ and thus {% raw %}$||A-A_k||_2 = \\sigma_{k+1}$.{% endraw %}\n\n### 证明 (Frobenius norm case)\n\n> Lemma: If $A,B \\in \\mathbb{R}^{m\\times n}$ , with B having rank K , then $\\sigma_{k+i}(A) \\le \\sigma_i(A-B) \\text{ for all }\\; i.$\n\nTo prove the lemma, first consider the case i=1, we have proved that $\\sigma_{k+1}(A) \\le \\sigma_1(A-B) = ||A-B||_2$in the 2-norm case. Then we do the general case:\n\n{% raw %}\n$$\n\\begin{aligned} \t\\sigma_i(A-B) = & \\sigma_i(A-B) + \\sigma_1(B-B_k)\\qquad\\text{since } B=B_k\\\\ \t=& \\sigma_1(A-B - (A-B)_{i-1}) + \\sigma_1(B-B_k)\\qquad\\\\ \t\\ge & \\sigma_1(A-B - (A-B)_{i-1}+B-B_k)   \\\\ \t=& \\sigma_1(A  - (A-B)_{i-1} -B_k)\\\\ \t\\ge & \\sigma_1(A - A_{k+i-1})\\\\ \t=& \\sigma_{k+i}(A)   \\end{aligned} \n$$\n{% endraw %}\n\n\n\n> https://zhuanlan.zhihu.com/p/361938622\n>\n> https://zhuanlan.zhihu.com/p/75283604\n","source":"_posts/math/Eckark-young.md","raw":"---\ntitle: Eckark_young定理\ndate: 2021-08-09 10:57:16\ntags: [math,线性代数]\ncategories: [math,线性代数]\nmath: true\n---\n\n最佳低秩逼近和奇异值的关系(*Eckart*-*Young定理*)\n### 定理\nSuppose a matrix $A\\in \\mathbb{R}^{m\\times n}$has an SVD-decomposition$A=U\\Sigma V^T$. Let $k < r= \\mathsf{rank}(A)$and truncated matrix\n$$\nA_k = \\sum_{i=1}^k \\sigma_i \\mathbf u_i \\mathbf v_i^T,\n$$\nthen, for any matrix B of rank k , the minimal error is achieved with $A_k$:\n\n{% raw %}\n$$\n\\min_{\\mathsf{rank}(B)=k}||A-B||_2 = || A - A_k||_2 = \\sigma_{k+1}.\n$$\n{% endraw %}\n\nThe same holds for Frobenius norm as well\n\n{% raw %}\n$$\n\\min_{\\mathsf{rank}(B)=k}||A-B||_F = || A - A_k||_F = \\sqrt{\\sigma_{k+1}^2 + \\cdots + \\sigma_p^2}.\n$$\n\n{% endraw %}\n\n### 证明 (2-norm case)\n\nSince $U^\\ A_k V = \\mathrm{diag}(\\sigma_1,\\ldots, \\sigma_k,0,\\ldots,0)$ it means that $A_k$ is rank K. Moreover, $U^T (A-A_k) V =  \\mathrm{diag}(0,\\ldots, 0,\\sigma_{k+1},\\ldots, \\sigma_p)$with the largest singular value is $\\sigma_{k+1}$ and thus {% raw %}$||A-A_k||_2 = \\sigma_{k+1}$.{% endraw %}\n\n### 证明 (Frobenius norm case)\n\n> Lemma: If $A,B \\in \\mathbb{R}^{m\\times n}$ , with B having rank K , then $\\sigma_{k+i}(A) \\le \\sigma_i(A-B) \\text{ for all }\\; i.$\n\nTo prove the lemma, first consider the case i=1, we have proved that $\\sigma_{k+1}(A) \\le \\sigma_1(A-B) = ||A-B||_2$in the 2-norm case. Then we do the general case:\n\n{% raw %}\n$$\n\\begin{aligned} \t\\sigma_i(A-B) = & \\sigma_i(A-B) + \\sigma_1(B-B_k)\\qquad\\text{since } B=B_k\\\\ \t=& \\sigma_1(A-B - (A-B)_{i-1}) + \\sigma_1(B-B_k)\\qquad\\\\ \t\\ge & \\sigma_1(A-B - (A-B)_{i-1}+B-B_k)   \\\\ \t=& \\sigma_1(A  - (A-B)_{i-1} -B_k)\\\\ \t\\ge & \\sigma_1(A - A_{k+i-1})\\\\ \t=& \\sigma_{k+i}(A)   \\end{aligned} \n$$\n{% endraw %}\n\n\n\n> https://zhuanlan.zhihu.com/p/361938622\n>\n> https://zhuanlan.zhihu.com/p/75283604\n","slug":"math/Eckark-young","published":1,"updated":"2021-08-09T07:33:43.757Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cksa5ksf10014a0x42wb874nd","content":"<p>最佳低秩逼近和奇异值的关系(<em>Eckart</em>-<em>Young定理</em>)</p>\n<h3 id=\"定理\"><a href=\"#定理\" class=\"headerlink\" title=\"定理\"></a>定理</h3><p>Suppose a matrix $A\\in \\mathbb{R}^{m\\times n}$has an SVD-decomposition$A=U\\Sigma V^T$. Let $k &lt; r= \\mathsf{rank}(A)$and truncated matrix<br>$$<br>A_k = \\sum_{i=1}^k \\sigma_i \\mathbf u_i \\mathbf v_i^T,<br>$$<br>then, for any matrix B of rank k , the minimal error is achieved with $A_k$:</p>\n\n$$\n\\min_{\\mathsf{rank}(B)=k}||A-B||_2 = || A - A_k||_2 = \\sigma_{k+1}.\n$$\n\n\n<p>The same holds for Frobenius norm as well</p>\n\n$$\n\\min_{\\mathsf{rank}(B)=k}||A-B||_F = || A - A_k||_F = \\sqrt{\\sigma_{k+1}^2 + \\cdots + \\sigma_p^2}.\n$$\n\n\n\n<h3 id=\"证明-2-norm-case\"><a href=\"#证明-2-norm-case\" class=\"headerlink\" title=\"证明 (2-norm case)\"></a>证明 (2-norm case)</h3><p>Since $U^\\ A_k V = \\mathrm{diag}(\\sigma_1,\\ldots, \\sigma_k,0,\\ldots,0)$ it means that $A_k$ is rank K. Moreover, $U^T (A-A_k) V =  \\mathrm{diag}(0,\\ldots, 0,\\sigma_{k+1},\\ldots, \\sigma_p)$with the largest singular value is $\\sigma_{k+1}$ and thus $||A-A_k||_2 = \\sigma_{k+1}$.</p>\n<h3 id=\"证明-Frobenius-norm-case\"><a href=\"#证明-Frobenius-norm-case\" class=\"headerlink\" title=\"证明 (Frobenius norm case)\"></a>证明 (Frobenius norm case)</h3><blockquote>\n<p>Lemma: If $A,B \\in \\mathbb{R}^{m\\times n}$ , with B having rank K , then $\\sigma_{k+i}(A) \\le \\sigma_i(A-B) \\text{ for all }; i.$</p>\n</blockquote>\n<p>To prove the lemma, first consider the case i=1, we have proved that $\\sigma_{k+1}(A) \\le \\sigma_1(A-B) = ||A-B||_2$in the 2-norm case. Then we do the general case:</p>\n\n$$\n\\begin{aligned} \t\\sigma_i(A-B) = &amp; \\sigma_i(A-B) + \\sigma_1(B-B_k)\\qquad\\text{since } B=B_k\\\\ \t=&amp; \\sigma_1(A-B - (A-B)_{i-1}) + \\sigma_1(B-B_k)\\qquad\\\\ \t\\ge &amp; \\sigma_1(A-B - (A-B)_{i-1}+B-B_k)   \\\\ \t=&amp; \\sigma_1(A  - (A-B)_{i-1} -B_k)\\\\ \t\\ge &amp; \\sigma_1(A - A_{k+i-1})\\\\ \t=&amp; \\sigma_{k+i}(A)   \\end{aligned} \n$$\n\n\n\n\n<blockquote>\n<p><a href=\"https://zhuanlan.zhihu.com/p/361938622\">https://zhuanlan.zhihu.com/p/361938622</a></p>\n<p><a href=\"https://zhuanlan.zhihu.com/p/75283604\">https://zhuanlan.zhihu.com/p/75283604</a></p>\n</blockquote>\n","site":{"data":{"friends":[{"avatar":"http://image.luokangyuan.com/1_qq_27922023.jpg","name":"码酱","introduction":"我不是大佬，只是在追寻大佬的脚步","url":"http://luokangyuan.com/","title":"前去学习"},{"avatar":"http://image.luokangyuan.com/4027734.jpeg","name":"闪烁之狐","introduction":"编程界大佬，技术牛，人还特别好，不懂的都可以请教大佬","url":"https://blinkfox.github.io/","title":"前去学习"},{"avatar":"http://image.luokangyuan.com/avatar.jpg","name":"ja_rome","introduction":"平凡的脚步也可以走出伟大的行程","url":"https://me.csdn.net/jlh912008548","title":"前去学习"}]}},"excerpt":"","more":"<p>最佳低秩逼近和奇异值的关系(<em>Eckart</em>-<em>Young定理</em>)</p>\n<h3 id=\"定理\"><a href=\"#定理\" class=\"headerlink\" title=\"定理\"></a>定理</h3><p>Suppose a matrix $A\\in \\mathbb{R}^{m\\times n}$has an SVD-decomposition$A=U\\Sigma V^T$. Let $k &lt; r= \\mathsf{rank}(A)$and truncated matrix<br>$$<br>A_k = \\sum_{i=1}^k \\sigma_i \\mathbf u_i \\mathbf v_i^T,<br>$$<br>then, for any matrix B of rank k , the minimal error is achieved with $A_k$:</p>\n\n$$\n\\min_{\\mathsf{rank}(B)=k}||A-B||_2 = || A - A_k||_2 = \\sigma_{k+1}.\n$$\n\n\n<p>The same holds for Frobenius norm as well</p>\n\n$$\n\\min_{\\mathsf{rank}(B)=k}||A-B||_F = || A - A_k||_F = \\sqrt{\\sigma_{k+1}^2 + \\cdots + \\sigma_p^2}.\n$$\n\n\n\n<h3 id=\"证明-2-norm-case\"><a href=\"#证明-2-norm-case\" class=\"headerlink\" title=\"证明 (2-norm case)\"></a>证明 (2-norm case)</h3><p>Since $U^\\ A_k V = \\mathrm{diag}(\\sigma_1,\\ldots, \\sigma_k,0,\\ldots,0)$ it means that $A_k$ is rank K. Moreover, $U^T (A-A_k) V =  \\mathrm{diag}(0,\\ldots, 0,\\sigma_{k+1},\\ldots, \\sigma_p)$with the largest singular value is $\\sigma_{k+1}$ and thus $||A-A_k||_2 = \\sigma_{k+1}$.</p>\n<h3 id=\"证明-Frobenius-norm-case\"><a href=\"#证明-Frobenius-norm-case\" class=\"headerlink\" title=\"证明 (Frobenius norm case)\"></a>证明 (Frobenius norm case)</h3><blockquote>\n<p>Lemma: If $A,B \\in \\mathbb{R}^{m\\times n}$ , with B having rank K , then $\\sigma_{k+i}(A) \\le \\sigma_i(A-B) \\text{ for all }; i.$</p>\n</blockquote>\n<p>To prove the lemma, first consider the case i=1, we have proved that $\\sigma_{k+1}(A) \\le \\sigma_1(A-B) = ||A-B||_2$in the 2-norm case. Then we do the general case:</p>\n\n$$\n\\begin{aligned} \t\\sigma_i(A-B) = & \\sigma_i(A-B) + \\sigma_1(B-B_k)\\qquad\\text{since } B=B_k\\\\ \t=& \\sigma_1(A-B - (A-B)_{i-1}) + \\sigma_1(B-B_k)\\qquad\\\\ \t\\ge & \\sigma_1(A-B - (A-B)_{i-1}+B-B_k)   \\\\ \t=& \\sigma_1(A  - (A-B)_{i-1} -B_k)\\\\ \t\\ge & \\sigma_1(A - A_{k+i-1})\\\\ \t=& \\sigma_{k+i}(A)   \\end{aligned} \n$$\n\n\n\n\n<blockquote>\n<p><a href=\"https://zhuanlan.zhihu.com/p/361938622\">https://zhuanlan.zhihu.com/p/361938622</a></p>\n<p><a href=\"https://zhuanlan.zhihu.com/p/75283604\">https://zhuanlan.zhihu.com/p/75283604</a></p>\n</blockquote>\n"},{"title":"Mahalanobis_distance","date":"2021-08-09T06:58:56.000Z","math":true,"_content":"\n> 马氏距离(Mahalanobis Distance)是度量学习中一种常用的距离指标，同欧氏距离、曼哈顿距离、汉明距离等一样被用作评定数据之间的相似度指标。但却可以应对高维线性分布的数据中各维度间非独立同分布的问题。\n\n*使用马氏距离，对高维非独立分布的数据进行距离度量。*\n\n**那我们为什么要用马氏距离呢？**\n马氏距离有很多**优点：** **马氏距离不受量纲的影响**，两点之间的马氏距离与原始数据的测量单位无关；由标准化数据和中心化数据(即原始数据与均值之差）计算出的二点之间的马氏距离相同。**马氏距离还可以排除变量之间的相关性的干扰**。\n\n## 什么是马氏距离\n\n马氏距离(Mahalanobis Distance)是一种距离的度量，可以看作是欧氏距离的一种修正，修正了欧式距离中各个维度尺度不一致且相关的问题。\n\n单个数据点的马氏距离\n\n![](https://pic4.zhimg.com/80/v2-d2987369d8167a362482d6cbecefb8bb_720w.jpg)\n\n\n\n数据点x, y之间的马氏距离\n\n\n\n![](https://pic3.zhimg.com/80/v2-d54956df14c05568f8c0c0548ac16416_720w.jpg)\n\n\n\n*其中Σ是多维随机变量的协方差矩阵，μ为样本均值，如果协方差矩阵是单位向量，也就是各维度独立同分布，马氏距离就变成了欧氏距离。*\n\n## 马氏距离实际意义\n\n那么马氏距离就能能干什么？它比欧氏距离好在哪里？举几个栗子\n\n**欧式距离近就一定相似？**\n\n先举个比较常用的例子，身高和体重，这两个变量拥有不同的单位标准，也就是有不同的scale。比如身高用毫米计算，而体重用千克计算，显然差10mm的身高与差10kg的体重是完全不同的。但在普通的欧氏距离中，这将会算作相同的差距。\n\n**归一化后欧氏距离近就一定相似？**\n\n当然我们可以先做归一化来消除这种维度间scale不同的问题，但是样本分布也会影响分类\n\n举个一维的栗子，现在有两个类别，统一单位，第一个类别均值为0，方差为0.1，第二个类别均值为5，方差为5。那么一个值为2的点属于第一类的概率大还是第二类的概率大？距离上说应该是第一类，但是直觉上显然是第二类，因为第一类不太可能到达2这个位置。\n\n所以，在一个方差较小的维度下很小的差别就有可能成为离群点。就像下图一样，A与B相对于原点的距离是相同的。但是由于样本总体沿着横轴分布，所以B点更有可能是这个样本中的点，而A则更有可能是离群点。\n\n![](https://pic4.zhimg.com/80/v2-6f5d1b59fd1687cfeecd0c6991c6db77_720w.jpg)\n\n\n\n**算上维度的方差就够了？**\n\n还有一个问题——如果维度间不独立同分布，样本点一定与欧氏距离近的样本点同类的概率更大吗？\n\n\n\n![](https://pic3.zhimg.com/80/v2-3cee35b79d272dda86e2604c160934ee_720w.jpg)\n\n\n\n可以看到样本基本服从f(x) = x的线性分布，A与B相对于原点的距离依旧相等，显然A更像是一个离群点\n\n即使数据已经经过了标准化，也不会改变AB与原点间距离大小的相互关系。所以要本质上解决这个问题，就要针对[主成分分析](https://link.zhihu.com/?target=https%3A//www.ph0en1x.space/2018/03/06/PCA/)中的`主成分`来进行标准化。\n\n## 马氏距离的几何意义\n\n上面搞懂了，马氏距离就好理解了，<u>只需要将变量`按照主成分进行旋转`，让维度间相互**独立**，然后进行`标准化`</u>，让维度**同分布**就可以了。\n\n由主成分分析可知，由于主成分就是特征向量方向，每个方向的方差就是对应的特征值，所以只需要按照特征向量的方向旋转，然后缩放特征值倍就可以了，可以得到以下的结果：\n\n\n\n![](https://pic3.zhimg.com/80/v2-068306ff7e62b7af24b126eafe0b8bc6_720w.jpg)\n\n\n\n离群点就被成功分离，这时候的欧式距离就是马氏距离。\n\n## 马氏距离的推导\n\n首先要对数据点进行*旋转*，旋转至主成分，维度间线性无关，假设新的坐标为\n\n![](https://pic2.zhimg.com/80/v2-e924839926a256cb277a8cfc850d5a89_720w.jpg)\n\n\n\n又变换后*维度间线性无关且每个维度自己的方差为特征值*，所以满足：\n\n\n\n![](https://pic1.zhimg.com/80/v2-24ace781a1f0b2cc64ea359b1bb78d74_720w.jpg)\n\n\n\n马氏距离是旋转变换缩放之后的欧式距离，所以马氏距离的计算公式为：\n\n![](https://pic3.zhimg.com/80/v2-4435a733478fafe47ee0198e315e67f6_720w.jpg)\n\n这就是之前提到的马氏距离的公式\n\n## 马氏距离的问题\n\n- 协方差矩阵必须满秩\n\n里面有求逆矩阵的过程，不满秩不行，要求数据要有原维度个特征值，如果没有可以考虑先进行PCA，这种情况下PCA不会损失信息\n\n- 不能处理非线性流形(manifold)上的问题\n\n只对线性空间有效，如果要处理流形，只能在局部定义，可以用来建立KNN图\n\n> 参考：\n>\n> https://zhuanlan.zhihu.com/p/46626607\n","source":"_posts/math/Mahalanobis-distance.md","raw":"---\ntitle: Mahalanobis_distance\ndate: 2021-08-09 14:58:56\ntags: 马氏距离\ncategories: [math,概率论]\nmath: true\n---\n\n> 马氏距离(Mahalanobis Distance)是度量学习中一种常用的距离指标，同欧氏距离、曼哈顿距离、汉明距离等一样被用作评定数据之间的相似度指标。但却可以应对高维线性分布的数据中各维度间非独立同分布的问题。\n\n*使用马氏距离，对高维非独立分布的数据进行距离度量。*\n\n**那我们为什么要用马氏距离呢？**\n马氏距离有很多**优点：** **马氏距离不受量纲的影响**，两点之间的马氏距离与原始数据的测量单位无关；由标准化数据和中心化数据(即原始数据与均值之差）计算出的二点之间的马氏距离相同。**马氏距离还可以排除变量之间的相关性的干扰**。\n\n## 什么是马氏距离\n\n马氏距离(Mahalanobis Distance)是一种距离的度量，可以看作是欧氏距离的一种修正，修正了欧式距离中各个维度尺度不一致且相关的问题。\n\n单个数据点的马氏距离\n\n![](https://pic4.zhimg.com/80/v2-d2987369d8167a362482d6cbecefb8bb_720w.jpg)\n\n\n\n数据点x, y之间的马氏距离\n\n\n\n![](https://pic3.zhimg.com/80/v2-d54956df14c05568f8c0c0548ac16416_720w.jpg)\n\n\n\n*其中Σ是多维随机变量的协方差矩阵，μ为样本均值，如果协方差矩阵是单位向量，也就是各维度独立同分布，马氏距离就变成了欧氏距离。*\n\n## 马氏距离实际意义\n\n那么马氏距离就能能干什么？它比欧氏距离好在哪里？举几个栗子\n\n**欧式距离近就一定相似？**\n\n先举个比较常用的例子，身高和体重，这两个变量拥有不同的单位标准，也就是有不同的scale。比如身高用毫米计算，而体重用千克计算，显然差10mm的身高与差10kg的体重是完全不同的。但在普通的欧氏距离中，这将会算作相同的差距。\n\n**归一化后欧氏距离近就一定相似？**\n\n当然我们可以先做归一化来消除这种维度间scale不同的问题，但是样本分布也会影响分类\n\n举个一维的栗子，现在有两个类别，统一单位，第一个类别均值为0，方差为0.1，第二个类别均值为5，方差为5。那么一个值为2的点属于第一类的概率大还是第二类的概率大？距离上说应该是第一类，但是直觉上显然是第二类，因为第一类不太可能到达2这个位置。\n\n所以，在一个方差较小的维度下很小的差别就有可能成为离群点。就像下图一样，A与B相对于原点的距离是相同的。但是由于样本总体沿着横轴分布，所以B点更有可能是这个样本中的点，而A则更有可能是离群点。\n\n![](https://pic4.zhimg.com/80/v2-6f5d1b59fd1687cfeecd0c6991c6db77_720w.jpg)\n\n\n\n**算上维度的方差就够了？**\n\n还有一个问题——如果维度间不独立同分布，样本点一定与欧氏距离近的样本点同类的概率更大吗？\n\n\n\n![](https://pic3.zhimg.com/80/v2-3cee35b79d272dda86e2604c160934ee_720w.jpg)\n\n\n\n可以看到样本基本服从f(x) = x的线性分布，A与B相对于原点的距离依旧相等，显然A更像是一个离群点\n\n即使数据已经经过了标准化，也不会改变AB与原点间距离大小的相互关系。所以要本质上解决这个问题，就要针对[主成分分析](https://link.zhihu.com/?target=https%3A//www.ph0en1x.space/2018/03/06/PCA/)中的`主成分`来进行标准化。\n\n## 马氏距离的几何意义\n\n上面搞懂了，马氏距离就好理解了，<u>只需要将变量`按照主成分进行旋转`，让维度间相互**独立**，然后进行`标准化`</u>，让维度**同分布**就可以了。\n\n由主成分分析可知，由于主成分就是特征向量方向，每个方向的方差就是对应的特征值，所以只需要按照特征向量的方向旋转，然后缩放特征值倍就可以了，可以得到以下的结果：\n\n\n\n![](https://pic3.zhimg.com/80/v2-068306ff7e62b7af24b126eafe0b8bc6_720w.jpg)\n\n\n\n离群点就被成功分离，这时候的欧式距离就是马氏距离。\n\n## 马氏距离的推导\n\n首先要对数据点进行*旋转*，旋转至主成分，维度间线性无关，假设新的坐标为\n\n![](https://pic2.zhimg.com/80/v2-e924839926a256cb277a8cfc850d5a89_720w.jpg)\n\n\n\n又变换后*维度间线性无关且每个维度自己的方差为特征值*，所以满足：\n\n\n\n![](https://pic1.zhimg.com/80/v2-24ace781a1f0b2cc64ea359b1bb78d74_720w.jpg)\n\n\n\n马氏距离是旋转变换缩放之后的欧式距离，所以马氏距离的计算公式为：\n\n![](https://pic3.zhimg.com/80/v2-4435a733478fafe47ee0198e315e67f6_720w.jpg)\n\n这就是之前提到的马氏距离的公式\n\n## 马氏距离的问题\n\n- 协方差矩阵必须满秩\n\n里面有求逆矩阵的过程，不满秩不行，要求数据要有原维度个特征值，如果没有可以考虑先进行PCA，这种情况下PCA不会损失信息\n\n- 不能处理非线性流形(manifold)上的问题\n\n只对线性空间有效，如果要处理流形，只能在局部定义，可以用来建立KNN图\n\n> 参考：\n>\n> https://zhuanlan.zhihu.com/p/46626607\n","slug":"math/Mahalanobis-distance","published":1,"updated":"2021-08-09T07:17:40.081Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cksa5ksf20017a0x43j87b86r","content":"<blockquote>\n<p>马氏距离(Mahalanobis Distance)是度量学习中一种常用的距离指标，同欧氏距离、曼哈顿距离、汉明距离等一样被用作评定数据之间的相似度指标。但却可以应对高维线性分布的数据中各维度间非独立同分布的问题。</p>\n</blockquote>\n<p><em>使用马氏距离，对高维非独立分布的数据进行距离度量。</em></p>\n<p><strong>那我们为什么要用马氏距离呢？</strong><br>马氏距离有很多<strong>优点：</strong> <strong>马氏距离不受量纲的影响</strong>，两点之间的马氏距离与原始数据的测量单位无关；由标准化数据和中心化数据(即原始数据与均值之差）计算出的二点之间的马氏距离相同。<strong>马氏距离还可以排除变量之间的相关性的干扰</strong>。</p>\n<h2 id=\"什么是马氏距离\"><a href=\"#什么是马氏距离\" class=\"headerlink\" title=\"什么是马氏距离\"></a>什么是马氏距离</h2><p>马氏距离(Mahalanobis Distance)是一种距离的度量，可以看作是欧氏距离的一种修正，修正了欧式距离中各个维度尺度不一致且相关的问题。</p>\n<p>单个数据点的马氏距离</p>\n<p><img src=\"https://pic4.zhimg.com/80/v2-d2987369d8167a362482d6cbecefb8bb_720w.jpg\"></p>\n<p>数据点x, y之间的马氏距离</p>\n<p><img src=\"https://pic3.zhimg.com/80/v2-d54956df14c05568f8c0c0548ac16416_720w.jpg\"></p>\n<p><em>其中Σ是多维随机变量的协方差矩阵，μ为样本均值，如果协方差矩阵是单位向量，也就是各维度独立同分布，马氏距离就变成了欧氏距离。</em></p>\n<h2 id=\"马氏距离实际意义\"><a href=\"#马氏距离实际意义\" class=\"headerlink\" title=\"马氏距离实际意义\"></a>马氏距离实际意义</h2><p>那么马氏距离就能能干什么？它比欧氏距离好在哪里？举几个栗子</p>\n<p><strong>欧式距离近就一定相似？</strong></p>\n<p>先举个比较常用的例子，身高和体重，这两个变量拥有不同的单位标准，也就是有不同的scale。比如身高用毫米计算，而体重用千克计算，显然差10mm的身高与差10kg的体重是完全不同的。但在普通的欧氏距离中，这将会算作相同的差距。</p>\n<p><strong>归一化后欧氏距离近就一定相似？</strong></p>\n<p>当然我们可以先做归一化来消除这种维度间scale不同的问题，但是样本分布也会影响分类</p>\n<p>举个一维的栗子，现在有两个类别，统一单位，第一个类别均值为0，方差为0.1，第二个类别均值为5，方差为5。那么一个值为2的点属于第一类的概率大还是第二类的概率大？距离上说应该是第一类，但是直觉上显然是第二类，因为第一类不太可能到达2这个位置。</p>\n<p>所以，在一个方差较小的维度下很小的差别就有可能成为离群点。就像下图一样，A与B相对于原点的距离是相同的。但是由于样本总体沿着横轴分布，所以B点更有可能是这个样本中的点，而A则更有可能是离群点。</p>\n<p><img src=\"https://pic4.zhimg.com/80/v2-6f5d1b59fd1687cfeecd0c6991c6db77_720w.jpg\"></p>\n<p><strong>算上维度的方差就够了？</strong></p>\n<p>还有一个问题——如果维度间不独立同分布，样本点一定与欧氏距离近的样本点同类的概率更大吗？</p>\n<p><img src=\"https://pic3.zhimg.com/80/v2-3cee35b79d272dda86e2604c160934ee_720w.jpg\"></p>\n<p>可以看到样本基本服从f(x) = x的线性分布，A与B相对于原点的距离依旧相等，显然A更像是一个离群点</p>\n<p>即使数据已经经过了标准化，也不会改变AB与原点间距离大小的相互关系。所以要本质上解决这个问题，就要针对<a href=\"https://link.zhihu.com/?target=https://www.ph0en1x.space/2018/03/06/PCA/\">主成分分析</a>中的<code>主成分</code>来进行标准化。</p>\n<h2 id=\"马氏距离的几何意义\"><a href=\"#马氏距离的几何意义\" class=\"headerlink\" title=\"马氏距离的几何意义\"></a>马氏距离的几何意义</h2><p>上面搞懂了，马氏距离就好理解了，<u>只需要将变量<code>按照主成分进行旋转</code>，让维度间相互<strong>独立</strong>，然后进行<code>标准化</code></u>，让维度<strong>同分布</strong>就可以了。</p>\n<p>由主成分分析可知，由于主成分就是特征向量方向，每个方向的方差就是对应的特征值，所以只需要按照特征向量的方向旋转，然后缩放特征值倍就可以了，可以得到以下的结果：</p>\n<p><img src=\"https://pic3.zhimg.com/80/v2-068306ff7e62b7af24b126eafe0b8bc6_720w.jpg\"></p>\n<p>离群点就被成功分离，这时候的欧式距离就是马氏距离。</p>\n<h2 id=\"马氏距离的推导\"><a href=\"#马氏距离的推导\" class=\"headerlink\" title=\"马氏距离的推导\"></a>马氏距离的推导</h2><p>首先要对数据点进行<em>旋转</em>，旋转至主成分，维度间线性无关，假设新的坐标为</p>\n<p><img src=\"https://pic2.zhimg.com/80/v2-e924839926a256cb277a8cfc850d5a89_720w.jpg\"></p>\n<p>又变换后<em>维度间线性无关且每个维度自己的方差为特征值</em>，所以满足：</p>\n<p><img src=\"https://pic1.zhimg.com/80/v2-24ace781a1f0b2cc64ea359b1bb78d74_720w.jpg\"></p>\n<p>马氏距离是旋转变换缩放之后的欧式距离，所以马氏距离的计算公式为：</p>\n<p><img src=\"https://pic3.zhimg.com/80/v2-4435a733478fafe47ee0198e315e67f6_720w.jpg\"></p>\n<p>这就是之前提到的马氏距离的公式</p>\n<h2 id=\"马氏距离的问题\"><a href=\"#马氏距离的问题\" class=\"headerlink\" title=\"马氏距离的问题\"></a>马氏距离的问题</h2><ul>\n<li>协方差矩阵必须满秩</li>\n</ul>\n<p>里面有求逆矩阵的过程，不满秩不行，要求数据要有原维度个特征值，如果没有可以考虑先进行PCA，这种情况下PCA不会损失信息</p>\n<ul>\n<li>不能处理非线性流形(manifold)上的问题</li>\n</ul>\n<p>只对线性空间有效，如果要处理流形，只能在局部定义，可以用来建立KNN图</p>\n<blockquote>\n<p>参考：</p>\n<p><a href=\"https://zhuanlan.zhihu.com/p/46626607\">https://zhuanlan.zhihu.com/p/46626607</a></p>\n</blockquote>\n","site":{"data":{"friends":[{"avatar":"http://image.luokangyuan.com/1_qq_27922023.jpg","name":"码酱","introduction":"我不是大佬，只是在追寻大佬的脚步","url":"http://luokangyuan.com/","title":"前去学习"},{"avatar":"http://image.luokangyuan.com/4027734.jpeg","name":"闪烁之狐","introduction":"编程界大佬，技术牛，人还特别好，不懂的都可以请教大佬","url":"https://blinkfox.github.io/","title":"前去学习"},{"avatar":"http://image.luokangyuan.com/avatar.jpg","name":"ja_rome","introduction":"平凡的脚步也可以走出伟大的行程","url":"https://me.csdn.net/jlh912008548","title":"前去学习"}]}},"excerpt":"","more":"<blockquote>\n<p>马氏距离(Mahalanobis Distance)是度量学习中一种常用的距离指标，同欧氏距离、曼哈顿距离、汉明距离等一样被用作评定数据之间的相似度指标。但却可以应对高维线性分布的数据中各维度间非独立同分布的问题。</p>\n</blockquote>\n<p><em>使用马氏距离，对高维非独立分布的数据进行距离度量。</em></p>\n<p><strong>那我们为什么要用马氏距离呢？</strong><br>马氏距离有很多<strong>优点：</strong> <strong>马氏距离不受量纲的影响</strong>，两点之间的马氏距离与原始数据的测量单位无关；由标准化数据和中心化数据(即原始数据与均值之差）计算出的二点之间的马氏距离相同。<strong>马氏距离还可以排除变量之间的相关性的干扰</strong>。</p>\n<h2 id=\"什么是马氏距离\"><a href=\"#什么是马氏距离\" class=\"headerlink\" title=\"什么是马氏距离\"></a>什么是马氏距离</h2><p>马氏距离(Mahalanobis Distance)是一种距离的度量，可以看作是欧氏距离的一种修正，修正了欧式距离中各个维度尺度不一致且相关的问题。</p>\n<p>单个数据点的马氏距离</p>\n<p><img src=\"https://pic4.zhimg.com/80/v2-d2987369d8167a362482d6cbecefb8bb_720w.jpg\"></p>\n<p>数据点x, y之间的马氏距离</p>\n<p><img src=\"https://pic3.zhimg.com/80/v2-d54956df14c05568f8c0c0548ac16416_720w.jpg\"></p>\n<p><em>其中Σ是多维随机变量的协方差矩阵，μ为样本均值，如果协方差矩阵是单位向量，也就是各维度独立同分布，马氏距离就变成了欧氏距离。</em></p>\n<h2 id=\"马氏距离实际意义\"><a href=\"#马氏距离实际意义\" class=\"headerlink\" title=\"马氏距离实际意义\"></a>马氏距离实际意义</h2><p>那么马氏距离就能能干什么？它比欧氏距离好在哪里？举几个栗子</p>\n<p><strong>欧式距离近就一定相似？</strong></p>\n<p>先举个比较常用的例子，身高和体重，这两个变量拥有不同的单位标准，也就是有不同的scale。比如身高用毫米计算，而体重用千克计算，显然差10mm的身高与差10kg的体重是完全不同的。但在普通的欧氏距离中，这将会算作相同的差距。</p>\n<p><strong>归一化后欧氏距离近就一定相似？</strong></p>\n<p>当然我们可以先做归一化来消除这种维度间scale不同的问题，但是样本分布也会影响分类</p>\n<p>举个一维的栗子，现在有两个类别，统一单位，第一个类别均值为0，方差为0.1，第二个类别均值为5，方差为5。那么一个值为2的点属于第一类的概率大还是第二类的概率大？距离上说应该是第一类，但是直觉上显然是第二类，因为第一类不太可能到达2这个位置。</p>\n<p>所以，在一个方差较小的维度下很小的差别就有可能成为离群点。就像下图一样，A与B相对于原点的距离是相同的。但是由于样本总体沿着横轴分布，所以B点更有可能是这个样本中的点，而A则更有可能是离群点。</p>\n<p><img src=\"https://pic4.zhimg.com/80/v2-6f5d1b59fd1687cfeecd0c6991c6db77_720w.jpg\"></p>\n<p><strong>算上维度的方差就够了？</strong></p>\n<p>还有一个问题——如果维度间不独立同分布，样本点一定与欧氏距离近的样本点同类的概率更大吗？</p>\n<p><img src=\"https://pic3.zhimg.com/80/v2-3cee35b79d272dda86e2604c160934ee_720w.jpg\"></p>\n<p>可以看到样本基本服从f(x) = x的线性分布，A与B相对于原点的距离依旧相等，显然A更像是一个离群点</p>\n<p>即使数据已经经过了标准化，也不会改变AB与原点间距离大小的相互关系。所以要本质上解决这个问题，就要针对<a href=\"https://link.zhihu.com/?target=https://www.ph0en1x.space/2018/03/06/PCA/\">主成分分析</a>中的<code>主成分</code>来进行标准化。</p>\n<h2 id=\"马氏距离的几何意义\"><a href=\"#马氏距离的几何意义\" class=\"headerlink\" title=\"马氏距离的几何意义\"></a>马氏距离的几何意义</h2><p>上面搞懂了，马氏距离就好理解了，<u>只需要将变量<code>按照主成分进行旋转</code>，让维度间相互<strong>独立</strong>，然后进行<code>标准化</code></u>，让维度<strong>同分布</strong>就可以了。</p>\n<p>由主成分分析可知，由于主成分就是特征向量方向，每个方向的方差就是对应的特征值，所以只需要按照特征向量的方向旋转，然后缩放特征值倍就可以了，可以得到以下的结果：</p>\n<p><img src=\"https://pic3.zhimg.com/80/v2-068306ff7e62b7af24b126eafe0b8bc6_720w.jpg\"></p>\n<p>离群点就被成功分离，这时候的欧式距离就是马氏距离。</p>\n<h2 id=\"马氏距离的推导\"><a href=\"#马氏距离的推导\" class=\"headerlink\" title=\"马氏距离的推导\"></a>马氏距离的推导</h2><p>首先要对数据点进行<em>旋转</em>，旋转至主成分，维度间线性无关，假设新的坐标为</p>\n<p><img src=\"https://pic2.zhimg.com/80/v2-e924839926a256cb277a8cfc850d5a89_720w.jpg\"></p>\n<p>又变换后<em>维度间线性无关且每个维度自己的方差为特征值</em>，所以满足：</p>\n<p><img src=\"https://pic1.zhimg.com/80/v2-24ace781a1f0b2cc64ea359b1bb78d74_720w.jpg\"></p>\n<p>马氏距离是旋转变换缩放之后的欧式距离，所以马氏距离的计算公式为：</p>\n<p><img src=\"https://pic3.zhimg.com/80/v2-4435a733478fafe47ee0198e315e67f6_720w.jpg\"></p>\n<p>这就是之前提到的马氏距离的公式</p>\n<h2 id=\"马氏距离的问题\"><a href=\"#马氏距离的问题\" class=\"headerlink\" title=\"马氏距离的问题\"></a>马氏距离的问题</h2><ul>\n<li>协方差矩阵必须满秩</li>\n</ul>\n<p>里面有求逆矩阵的过程，不满秩不行，要求数据要有原维度个特征值，如果没有可以考虑先进行PCA，这种情况下PCA不会损失信息</p>\n<ul>\n<li>不能处理非线性流形(manifold)上的问题</li>\n</ul>\n<p>只对线性空间有效，如果要处理流形，只能在局部定义，可以用来建立KNN图</p>\n<blockquote>\n<p>参考：</p>\n<p><a href=\"https://zhuanlan.zhihu.com/p/46626607\">https://zhuanlan.zhihu.com/p/46626607</a></p>\n</blockquote>\n"},{"title":"直观理解协方差矩阵","date":"2021-08-05T03:26:21.000Z","math":true,"_content":"\n> 原文出自 https://zhuanlan.zhihu.com/p/349802953\n\n## 1 概率论中的定义\n\n### 随机变量：\n\n随机变量(Random Variable) X 是一个映射，把随机试验的结果与实数建立起了一一对应的关系。而期望与方差是随机变量的两个重要的数字特征。\n\n### 数学期望：\n\n在概率论和统计学中，数学期望(mean)(或均值，亦简称期望(Expectation, or expected value))是试验中每次可能结果的概率乘以其结果的总和，是最基本的数学特征之一。它反映随机变量平均取值的大小。 期望值是该变量输出值的平均数。期望值并不一定包含于变量的输出值集合里。\n\n大数定律规定，随着重复次数接近无穷大，数值的算术平均值几乎肯定地收敛于期望值。\n\n### 方差：\n\n方差(Variance)是在概率论和统计方差衡量随机变量或一组数据时离散程度的度量。概率论中方差用来度量随机变量和其数学期望(即均值)之间的偏离程度。统计中的方差(样本方差)是每个样本值与全体样本值的平均数之差的平方值的平均数。\n\n设$X$为随机变量， 如果$\\mathrm{E}[X]$，则随机变量$X$的方差为：\n$$\n\\mu=\\mathrm{E}[X]\n$$\n\n方差也记为 $\\sigma_{X}^{2}$。\n\n样本方差计算公式：\n\n$$\nS^{2}=\\Sigma\\left(X-\\overline{X}\\right)^{2}/\\left(n-1\\right)\n$$\n\n其中，$S^{2}$为样本方差，$X$ 为变量，$\\overline{X}$为样本均值，$n$ 为样本例数。如果要了解为什么要除以$n-1$，请看[这篇文章](https://link.zhihu.com/?target=https%3A//www.visiondummy.com/2014/03/divide-variance-n-1/)。\n\n### 标准差：\n\n标准差(Standard Deviation)是离均差平方的算术平均数(即：方差)的算术平方根，用$\\sigma$表示。标准差也被称为标准偏差，或者实验标准差，在概率统计中最常使用作为统计分布程度上的测量依据。 见下图：\n\n![](https://pic1.zhimg.com/80/v2-37e04458baf17d09c914981b5dbae140_720w.jpg)\n\n标准差是方差的算术平方根。标准差能反映一个数据集的离散程度。平均数相同的两组数据，标准差未必相同。\n\n### 协方差：\n\n**协方差(Covariance)在概率论和统计学中用于衡量两个变量的总体误差。而方差是协方差的一种特殊情况，即当两个变量是相同的情况。**\n\n期望值分别为$ E[X]$与$[Y]$的两个实随机变量$X$与$Y$之间的协方差 $\\mathrm{Cov}(X,Y)$ 定义为：\n\n{% raw %}\n$$\n\\begin{aligned}\n\\mathrm{Cov}(X,Y)&=\\mathrm{E}\\left[\\left(X\\mathrm{E}\\left[X\\right]\\right)\\left(Y-\\mathrm{E}\\left[Y\\right]\\right)\\right]  \n\\\\&=\\mathrm{E}\\left[XY\\right]-2\\mathrm{E}\\left[Y\\right]\\mathrm{E}\\left[X\\right]+\\mathrm{E}\\left[X\\right]\\mathrm{E}\\left[Y\\right]\n\\\\&=\\mathrm{E}\\left[XY\\right]-\\mathrm{E}\\left[X\\right]\\mathrm{E}\\left[Y\\right] \n\\\\&=\\mathrm{E}\\left[XY\\right]-\\mathrm{E}\\left[X\\right]\\mathrm{E}\\left[Y\\right]\n\\end{aligned}\n$$\n{% endraw %}\n\n协方差表示的是两个变量总体误差的期望。 如果两个变量的变化趋势一致，也就是说如果其中一个大于自身的期望值，另外一个也大于自身的期望值，那么两个变量之间的协方差就是正值。 如果两个变量的变化趋势相反，即其中一个大于自身的期望值，另外一个却小于自身的期望值，那么两个变量之间的协方差就是负值。\n\n如果$X$与$Y$是统计独立的，那么二者之间的协方差就是0，因为两个独立的随机变量满足$\\mathrm{E}[XY]=\\mathrm{E}[X]\\mathrm{E}[Y]$。但是，反过来并不成立。即如果$X$与$Y$的协方差为0，二者并不一定是统计独立的。\n\n**协方差为0的两个随机变量称为是不相关的。**\n\n### 协方差矩阵：\n\n在统计学与概率论中，协方差矩阵(Covariance matrix)的每个元素是各个向量元素之间的协方差，是从标量随机变量到高维度随机向量的自然推广。\n\n设$X=\\left(X_{1},X_{2},\\ldots,X_{n}\\right)^{\\mathrm{T}}$为$n$ 维随机变量，称矩阵\n\n{% raw %}\n$$\nC=\\left(\\begin{array}{cccc} c_{11} & c_{12} & \\cdots & c_{1n}\\\\ c_{21} & c_{22} & \\cdots & c_{2n}\\\\ \\vdots & \\vdots & \\ddots & \\vdots\\\\ c_{n1} & c_{n2} & \\cdots & c_{nn} \\end{array}\\right)\n$$\n{% endraw %}\n\n为 n 维随机变量x的协方差矩阵，也记为 $D\\left(X\\right)$ ，其中\n$$\nc_{ij}=\\mathrm{Cov}(X_{i},X_{j}),\\quad i,j=1,2,\\ldots,n\n$$\n为X的分量$X_{i}$和$X_{j}$的协方差。*并且对角线上的元素为各个随机变量的方差：*\n\n$$\nc_{ii}=\\mathrm{Cov}(X_{i},X_{i}),\\quad i=1,2,\\ldots,n\n$$\n\n协方差矩阵是对称半正定矩阵。协方差矩阵的对称性，可从定义得知。对于半正定特性，证明如下：\n\n现给定任意一个非零向量$\\boldsymbol{x}$，则\n\n{% raw %}\n$$\n\\begin{aligned}\n\\boldsymbol{x}^{\\mathrm{T}}C\\boldsymbol{x}\t&=\\boldsymbol{x}^{\\mathrm{T}}\\mathrm{E}\\left[\\left(X-\\mu\\right)\\left(X-\\mu\\right)^{\\mathrm{T}}\\right]\\boldsymbol{x} \t\n\\\\&=\\mathrm{E}\\left[\\boldsymbol{x}^{\\mathrm{T}}\\left(X-\\mu\\right)\\left(X-\\mu\\right)^{\\mathrm{T}}\\boldsymbol{x}\\right] \t\\\\&=\\mathrm{E}\\left[\\left(\\left(X-\\mu\\right)^{\\mathrm{T}}\\boldsymbol{x}\\right)^{\\mathrm{T}}\\left(\\left(X-\\mu\\right)^{\\mathrm{T}}\\boldsymbol{x}\\right)\\right] \t\n\\\\&=\\mathrm{E}\\left(\\left\\Vert \\left(X-\\mu\\right)^{\\mathrm{T}}\\boldsymbol{x}\\right\\Vert ^{2}\\right) \t\n\\\\&=\\sigma_{X}^{2}\n\\end{aligned}\n$$\n{% endraw %}\n\n其中，\n$$\n\\sigma_{X}=\\left(X-\\mu \\right)^{\\mathrm{T}}\\boldsymbol{x}\n$$\n由于 $\\sigma_{X}^{2}\\geq0$，因此$\\boldsymbol{x}^{\\mathrm{T}}C\\boldsymbol{x}\\geq0$，因此协方差矩阵$C$ 是半正定矩阵。\n\n","source":"_posts/math/covariance-matrix.md","raw":"---\ntitle: 直观理解协方差矩阵\ndate: 2021-08-05 11:26:21\ntags: [math,概率论]\ncategories: [math,概率论]\nmath: true\n---\n\n> 原文出自 https://zhuanlan.zhihu.com/p/349802953\n\n## 1 概率论中的定义\n\n### 随机变量：\n\n随机变量(Random Variable) X 是一个映射，把随机试验的结果与实数建立起了一一对应的关系。而期望与方差是随机变量的两个重要的数字特征。\n\n### 数学期望：\n\n在概率论和统计学中，数学期望(mean)(或均值，亦简称期望(Expectation, or expected value))是试验中每次可能结果的概率乘以其结果的总和，是最基本的数学特征之一。它反映随机变量平均取值的大小。 期望值是该变量输出值的平均数。期望值并不一定包含于变量的输出值集合里。\n\n大数定律规定，随着重复次数接近无穷大，数值的算术平均值几乎肯定地收敛于期望值。\n\n### 方差：\n\n方差(Variance)是在概率论和统计方差衡量随机变量或一组数据时离散程度的度量。概率论中方差用来度量随机变量和其数学期望(即均值)之间的偏离程度。统计中的方差(样本方差)是每个样本值与全体样本值的平均数之差的平方值的平均数。\n\n设$X$为随机变量， 如果$\\mathrm{E}[X]$，则随机变量$X$的方差为：\n$$\n\\mu=\\mathrm{E}[X]\n$$\n\n方差也记为 $\\sigma_{X}^{2}$。\n\n样本方差计算公式：\n\n$$\nS^{2}=\\Sigma\\left(X-\\overline{X}\\right)^{2}/\\left(n-1\\right)\n$$\n\n其中，$S^{2}$为样本方差，$X$ 为变量，$\\overline{X}$为样本均值，$n$ 为样本例数。如果要了解为什么要除以$n-1$，请看[这篇文章](https://link.zhihu.com/?target=https%3A//www.visiondummy.com/2014/03/divide-variance-n-1/)。\n\n### 标准差：\n\n标准差(Standard Deviation)是离均差平方的算术平均数(即：方差)的算术平方根，用$\\sigma$表示。标准差也被称为标准偏差，或者实验标准差，在概率统计中最常使用作为统计分布程度上的测量依据。 见下图：\n\n![](https://pic1.zhimg.com/80/v2-37e04458baf17d09c914981b5dbae140_720w.jpg)\n\n标准差是方差的算术平方根。标准差能反映一个数据集的离散程度。平均数相同的两组数据，标准差未必相同。\n\n### 协方差：\n\n**协方差(Covariance)在概率论和统计学中用于衡量两个变量的总体误差。而方差是协方差的一种特殊情况，即当两个变量是相同的情况。**\n\n期望值分别为$ E[X]$与$[Y]$的两个实随机变量$X$与$Y$之间的协方差 $\\mathrm{Cov}(X,Y)$ 定义为：\n\n{% raw %}\n$$\n\\begin{aligned}\n\\mathrm{Cov}(X,Y)&=\\mathrm{E}\\left[\\left(X\\mathrm{E}\\left[X\\right]\\right)\\left(Y-\\mathrm{E}\\left[Y\\right]\\right)\\right]  \n\\\\&=\\mathrm{E}\\left[XY\\right]-2\\mathrm{E}\\left[Y\\right]\\mathrm{E}\\left[X\\right]+\\mathrm{E}\\left[X\\right]\\mathrm{E}\\left[Y\\right]\n\\\\&=\\mathrm{E}\\left[XY\\right]-\\mathrm{E}\\left[X\\right]\\mathrm{E}\\left[Y\\right] \n\\\\&=\\mathrm{E}\\left[XY\\right]-\\mathrm{E}\\left[X\\right]\\mathrm{E}\\left[Y\\right]\n\\end{aligned}\n$$\n{% endraw %}\n\n协方差表示的是两个变量总体误差的期望。 如果两个变量的变化趋势一致，也就是说如果其中一个大于自身的期望值，另外一个也大于自身的期望值，那么两个变量之间的协方差就是正值。 如果两个变量的变化趋势相反，即其中一个大于自身的期望值，另外一个却小于自身的期望值，那么两个变量之间的协方差就是负值。\n\n如果$X$与$Y$是统计独立的，那么二者之间的协方差就是0，因为两个独立的随机变量满足$\\mathrm{E}[XY]=\\mathrm{E}[X]\\mathrm{E}[Y]$。但是，反过来并不成立。即如果$X$与$Y$的协方差为0，二者并不一定是统计独立的。\n\n**协方差为0的两个随机变量称为是不相关的。**\n\n### 协方差矩阵：\n\n在统计学与概率论中，协方差矩阵(Covariance matrix)的每个元素是各个向量元素之间的协方差，是从标量随机变量到高维度随机向量的自然推广。\n\n设$X=\\left(X_{1},X_{2},\\ldots,X_{n}\\right)^{\\mathrm{T}}$为$n$ 维随机变量，称矩阵\n\n{% raw %}\n$$\nC=\\left(\\begin{array}{cccc} c_{11} & c_{12} & \\cdots & c_{1n}\\\\ c_{21} & c_{22} & \\cdots & c_{2n}\\\\ \\vdots & \\vdots & \\ddots & \\vdots\\\\ c_{n1} & c_{n2} & \\cdots & c_{nn} \\end{array}\\right)\n$$\n{% endraw %}\n\n为 n 维随机变量x的协方差矩阵，也记为 $D\\left(X\\right)$ ，其中\n$$\nc_{ij}=\\mathrm{Cov}(X_{i},X_{j}),\\quad i,j=1,2,\\ldots,n\n$$\n为X的分量$X_{i}$和$X_{j}$的协方差。*并且对角线上的元素为各个随机变量的方差：*\n\n$$\nc_{ii}=\\mathrm{Cov}(X_{i},X_{i}),\\quad i=1,2,\\ldots,n\n$$\n\n协方差矩阵是对称半正定矩阵。协方差矩阵的对称性，可从定义得知。对于半正定特性，证明如下：\n\n现给定任意一个非零向量$\\boldsymbol{x}$，则\n\n{% raw %}\n$$\n\\begin{aligned}\n\\boldsymbol{x}^{\\mathrm{T}}C\\boldsymbol{x}\t&=\\boldsymbol{x}^{\\mathrm{T}}\\mathrm{E}\\left[\\left(X-\\mu\\right)\\left(X-\\mu\\right)^{\\mathrm{T}}\\right]\\boldsymbol{x} \t\n\\\\&=\\mathrm{E}\\left[\\boldsymbol{x}^{\\mathrm{T}}\\left(X-\\mu\\right)\\left(X-\\mu\\right)^{\\mathrm{T}}\\boldsymbol{x}\\right] \t\\\\&=\\mathrm{E}\\left[\\left(\\left(X-\\mu\\right)^{\\mathrm{T}}\\boldsymbol{x}\\right)^{\\mathrm{T}}\\left(\\left(X-\\mu\\right)^{\\mathrm{T}}\\boldsymbol{x}\\right)\\right] \t\n\\\\&=\\mathrm{E}\\left(\\left\\Vert \\left(X-\\mu\\right)^{\\mathrm{T}}\\boldsymbol{x}\\right\\Vert ^{2}\\right) \t\n\\\\&=\\sigma_{X}^{2}\n\\end{aligned}\n$$\n{% endraw %}\n\n其中，\n$$\n\\sigma_{X}=\\left(X-\\mu \\right)^{\\mathrm{T}}\\boldsymbol{x}\n$$\n由于 $\\sigma_{X}^{2}\\geq0$，因此$\\boldsymbol{x}^{\\mathrm{T}}C\\boldsymbol{x}\\geq0$，因此协方差矩阵$C$ 是半正定矩阵。\n\n","slug":"math/covariance-matrix","published":1,"updated":"2021-08-05T13:14:23.401Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cksa5ksf30019a0x45nzfd6e9","content":"<blockquote>\n<p>原文出自 <a href=\"https://zhuanlan.zhihu.com/p/349802953\">https://zhuanlan.zhihu.com/p/349802953</a></p>\n</blockquote>\n<h2 id=\"1-概率论中的定义\"><a href=\"#1-概率论中的定义\" class=\"headerlink\" title=\"1 概率论中的定义\"></a>1 概率论中的定义</h2><h3 id=\"随机变量：\"><a href=\"#随机变量：\" class=\"headerlink\" title=\"随机变量：\"></a>随机变量：</h3><p>随机变量(Random Variable) X 是一个映射，把随机试验的结果与实数建立起了一一对应的关系。而期望与方差是随机变量的两个重要的数字特征。</p>\n<h3 id=\"数学期望：\"><a href=\"#数学期望：\" class=\"headerlink\" title=\"数学期望：\"></a>数学期望：</h3><p>在概率论和统计学中，数学期望(mean)(或均值，亦简称期望(Expectation, or expected value))是试验中每次可能结果的概率乘以其结果的总和，是最基本的数学特征之一。它反映随机变量平均取值的大小。 期望值是该变量输出值的平均数。期望值并不一定包含于变量的输出值集合里。</p>\n<p>大数定律规定，随着重复次数接近无穷大，数值的算术平均值几乎肯定地收敛于期望值。</p>\n<h3 id=\"方差：\"><a href=\"#方差：\" class=\"headerlink\" title=\"方差：\"></a>方差：</h3><p>方差(Variance)是在概率论和统计方差衡量随机变量或一组数据时离散程度的度量。概率论中方差用来度量随机变量和其数学期望(即均值)之间的偏离程度。统计中的方差(样本方差)是每个样本值与全体样本值的平均数之差的平方值的平均数。</p>\n<p>设$X$为随机变量， 如果$\\mathrm{E}[X]$，则随机变量$X$的方差为：<br>$$<br>\\mu=\\mathrm{E}[X]<br>$$</p>\n<p>方差也记为 $\\sigma_{X}^{2}$。</p>\n<p>样本方差计算公式：</p>\n<p>$$<br>S^{2}=\\Sigma\\left(X-\\overline{X}\\right)^{2}/\\left(n-1\\right)<br>$$</p>\n<p>其中，$S^{2}$为样本方差，$X$ 为变量，$\\overline{X}$为样本均值，$n$ 为样本例数。如果要了解为什么要除以$n-1$，请看<a href=\"https://link.zhihu.com/?target=https://www.visiondummy.com/2014/03/divide-variance-n-1/\">这篇文章</a>。</p>\n<h3 id=\"标准差：\"><a href=\"#标准差：\" class=\"headerlink\" title=\"标准差：\"></a>标准差：</h3><p>标准差(Standard Deviation)是离均差平方的算术平均数(即：方差)的算术平方根，用$\\sigma$表示。标准差也被称为标准偏差，或者实验标准差，在概率统计中最常使用作为统计分布程度上的测量依据。 见下图：</p>\n<p><img src=\"https://pic1.zhimg.com/80/v2-37e04458baf17d09c914981b5dbae140_720w.jpg\"></p>\n<p>标准差是方差的算术平方根。标准差能反映一个数据集的离散程度。平均数相同的两组数据，标准差未必相同。</p>\n<h3 id=\"协方差：\"><a href=\"#协方差：\" class=\"headerlink\" title=\"协方差：\"></a>协方差：</h3><p><strong>协方差(Covariance)在概率论和统计学中用于衡量两个变量的总体误差。而方差是协方差的一种特殊情况，即当两个变量是相同的情况。</strong></p>\n<p>期望值分别为$ E[X]$与$[Y]$的两个实随机变量$X$与$Y$之间的协方差 $\\mathrm{Cov}(X,Y)$ 定义为：</p>\n\n$$\n\\begin{aligned}\n\\mathrm{Cov}(X,Y)&amp;=\\mathrm{E}\\left[\\left(X\\mathrm{E}\\left[X\\right]\\right)\\left(Y-\\mathrm{E}\\left[Y\\right]\\right)\\right]  \n\\\\&amp;=\\mathrm{E}\\left[XY\\right]-2\\mathrm{E}\\left[Y\\right]\\mathrm{E}\\left[X\\right]+\\mathrm{E}\\left[X\\right]\\mathrm{E}\\left[Y\\right]\n\\\\&amp;=\\mathrm{E}\\left[XY\\right]-\\mathrm{E}\\left[X\\right]\\mathrm{E}\\left[Y\\right] \n\\\\&amp;=\\mathrm{E}\\left[XY\\right]-\\mathrm{E}\\left[X\\right]\\mathrm{E}\\left[Y\\right]\n\\end{aligned}\n$$\n\n\n<p>协方差表示的是两个变量总体误差的期望。 如果两个变量的变化趋势一致，也就是说如果其中一个大于自身的期望值，另外一个也大于自身的期望值，那么两个变量之间的协方差就是正值。 如果两个变量的变化趋势相反，即其中一个大于自身的期望值，另外一个却小于自身的期望值，那么两个变量之间的协方差就是负值。</p>\n<p>如果$X$与$Y$是统计独立的，那么二者之间的协方差就是0，因为两个独立的随机变量满足$\\mathrm{E}[XY]=\\mathrm{E}[X]\\mathrm{E}[Y]$。但是，反过来并不成立。即如果$X$与$Y$的协方差为0，二者并不一定是统计独立的。</p>\n<p><strong>协方差为0的两个随机变量称为是不相关的。</strong></p>\n<h3 id=\"协方差矩阵：\"><a href=\"#协方差矩阵：\" class=\"headerlink\" title=\"协方差矩阵：\"></a>协方差矩阵：</h3><p>在统计学与概率论中，协方差矩阵(Covariance matrix)的每个元素是各个向量元素之间的协方差，是从标量随机变量到高维度随机向量的自然推广。</p>\n<p>设$X=\\left(X_{1},X_{2},\\ldots,X_{n}\\right)^{\\mathrm{T}}$为$n$ 维随机变量，称矩阵</p>\n\n$$\nC=\\left(\\begin{array}{cccc} c_{11} &amp; c_{12} &amp; \\cdots &amp; c_{1n}\\\\ c_{21} &amp; c_{22} &amp; \\cdots &amp; c_{2n}\\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots\\\\ c_{n1} &amp; c_{n2} &amp; \\cdots &amp; c_{nn} \\end{array}\\right)\n$$\n\n\n<p>为 n 维随机变量x的协方差矩阵，也记为 $D\\left(X\\right)$ ，其中<br>$$<br>c_{ij}=\\mathrm{Cov}(X_{i},X_{j}),\\quad i,j=1,2,\\ldots,n<br>$$<br>为X的分量$X_{i}$和$X_{j}$的协方差。<em>并且对角线上的元素为各个随机变量的方差：</em></p>\n<p>$$<br>c_{ii}=\\mathrm{Cov}(X_{i},X_{i}),\\quad i=1,2,\\ldots,n<br>$$</p>\n<p>协方差矩阵是对称半正定矩阵。协方差矩阵的对称性，可从定义得知。对于半正定特性，证明如下：</p>\n<p>现给定任意一个非零向量$\\boldsymbol{x}$，则</p>\n\n$$\n\\begin{aligned}\n\\boldsymbol{x}^{\\mathrm{T}}C\\boldsymbol{x}\t&amp;=\\boldsymbol{x}^{\\mathrm{T}}\\mathrm{E}\\left[\\left(X-\\mu\\right)\\left(X-\\mu\\right)^{\\mathrm{T}}\\right]\\boldsymbol{x} \t\n\\\\&amp;=\\mathrm{E}\\left[\\boldsymbol{x}^{\\mathrm{T}}\\left(X-\\mu\\right)\\left(X-\\mu\\right)^{\\mathrm{T}}\\boldsymbol{x}\\right] \t\\\\&amp;=\\mathrm{E}\\left[\\left(\\left(X-\\mu\\right)^{\\mathrm{T}}\\boldsymbol{x}\\right)^{\\mathrm{T}}\\left(\\left(X-\\mu\\right)^{\\mathrm{T}}\\boldsymbol{x}\\right)\\right] \t\n\\\\&amp;=\\mathrm{E}\\left(\\left\\Vert \\left(X-\\mu\\right)^{\\mathrm{T}}\\boldsymbol{x}\\right\\Vert ^{2}\\right) \t\n\\\\&amp;=\\sigma_{X}^{2}\n\\end{aligned}\n$$\n\n\n<p>其中，<br>$$<br>\\sigma_{X}=\\left(X-\\mu \\right)^{\\mathrm{T}}\\boldsymbol{x}<br>$$<br>由于 $\\sigma_{X}^{2}\\geq0$，因此$\\boldsymbol{x}^{\\mathrm{T}}C\\boldsymbol{x}\\geq0$，因此协方差矩阵$C$ 是半正定矩阵。</p>\n","site":{"data":{"friends":[{"avatar":"http://image.luokangyuan.com/1_qq_27922023.jpg","name":"码酱","introduction":"我不是大佬，只是在追寻大佬的脚步","url":"http://luokangyuan.com/","title":"前去学习"},{"avatar":"http://image.luokangyuan.com/4027734.jpeg","name":"闪烁之狐","introduction":"编程界大佬，技术牛，人还特别好，不懂的都可以请教大佬","url":"https://blinkfox.github.io/","title":"前去学习"},{"avatar":"http://image.luokangyuan.com/avatar.jpg","name":"ja_rome","introduction":"平凡的脚步也可以走出伟大的行程","url":"https://me.csdn.net/jlh912008548","title":"前去学习"}]}},"excerpt":"","more":"<blockquote>\n<p>原文出自 <a href=\"https://zhuanlan.zhihu.com/p/349802953\">https://zhuanlan.zhihu.com/p/349802953</a></p>\n</blockquote>\n<h2 id=\"1-概率论中的定义\"><a href=\"#1-概率论中的定义\" class=\"headerlink\" title=\"1 概率论中的定义\"></a>1 概率论中的定义</h2><h3 id=\"随机变量：\"><a href=\"#随机变量：\" class=\"headerlink\" title=\"随机变量：\"></a>随机变量：</h3><p>随机变量(Random Variable) X 是一个映射，把随机试验的结果与实数建立起了一一对应的关系。而期望与方差是随机变量的两个重要的数字特征。</p>\n<h3 id=\"数学期望：\"><a href=\"#数学期望：\" class=\"headerlink\" title=\"数学期望：\"></a>数学期望：</h3><p>在概率论和统计学中，数学期望(mean)(或均值，亦简称期望(Expectation, or expected value))是试验中每次可能结果的概率乘以其结果的总和，是最基本的数学特征之一。它反映随机变量平均取值的大小。 期望值是该变量输出值的平均数。期望值并不一定包含于变量的输出值集合里。</p>\n<p>大数定律规定，随着重复次数接近无穷大，数值的算术平均值几乎肯定地收敛于期望值。</p>\n<h3 id=\"方差：\"><a href=\"#方差：\" class=\"headerlink\" title=\"方差：\"></a>方差：</h3><p>方差(Variance)是在概率论和统计方差衡量随机变量或一组数据时离散程度的度量。概率论中方差用来度量随机变量和其数学期望(即均值)之间的偏离程度。统计中的方差(样本方差)是每个样本值与全体样本值的平均数之差的平方值的平均数。</p>\n<p>设$X$为随机变量， 如果$\\mathrm{E}[X]$，则随机变量$X$的方差为：<br>$$<br>\\mu=\\mathrm{E}[X]<br>$$</p>\n<p>方差也记为 $\\sigma_{X}^{2}$。</p>\n<p>样本方差计算公式：</p>\n<p>$$<br>S^{2}=\\Sigma\\left(X-\\overline{X}\\right)^{2}/\\left(n-1\\right)<br>$$</p>\n<p>其中，$S^{2}$为样本方差，$X$ 为变量，$\\overline{X}$为样本均值，$n$ 为样本例数。如果要了解为什么要除以$n-1$，请看<a href=\"https://link.zhihu.com/?target=https://www.visiondummy.com/2014/03/divide-variance-n-1/\">这篇文章</a>。</p>\n<h3 id=\"标准差：\"><a href=\"#标准差：\" class=\"headerlink\" title=\"标准差：\"></a>标准差：</h3><p>标准差(Standard Deviation)是离均差平方的算术平均数(即：方差)的算术平方根，用$\\sigma$表示。标准差也被称为标准偏差，或者实验标准差，在概率统计中最常使用作为统计分布程度上的测量依据。 见下图：</p>\n<p><img src=\"https://pic1.zhimg.com/80/v2-37e04458baf17d09c914981b5dbae140_720w.jpg\"></p>\n<p>标准差是方差的算术平方根。标准差能反映一个数据集的离散程度。平均数相同的两组数据，标准差未必相同。</p>\n<h3 id=\"协方差：\"><a href=\"#协方差：\" class=\"headerlink\" title=\"协方差：\"></a>协方差：</h3><p><strong>协方差(Covariance)在概率论和统计学中用于衡量两个变量的总体误差。而方差是协方差的一种特殊情况，即当两个变量是相同的情况。</strong></p>\n<p>期望值分别为$ E[X]$与$[Y]$的两个实随机变量$X$与$Y$之间的协方差 $\\mathrm{Cov}(X,Y)$ 定义为：</p>\n\n$$\n\\begin{aligned}\n\\mathrm{Cov}(X,Y)&=\\mathrm{E}\\left[\\left(X\\mathrm{E}\\left[X\\right]\\right)\\left(Y-\\mathrm{E}\\left[Y\\right]\\right)\\right]  \n\\\\&=\\mathrm{E}\\left[XY\\right]-2\\mathrm{E}\\left[Y\\right]\\mathrm{E}\\left[X\\right]+\\mathrm{E}\\left[X\\right]\\mathrm{E}\\left[Y\\right]\n\\\\&=\\mathrm{E}\\left[XY\\right]-\\mathrm{E}\\left[X\\right]\\mathrm{E}\\left[Y\\right] \n\\\\&=\\mathrm{E}\\left[XY\\right]-\\mathrm{E}\\left[X\\right]\\mathrm{E}\\left[Y\\right]\n\\end{aligned}\n$$\n\n\n<p>协方差表示的是两个变量总体误差的期望。 如果两个变量的变化趋势一致，也就是说如果其中一个大于自身的期望值，另外一个也大于自身的期望值，那么两个变量之间的协方差就是正值。 如果两个变量的变化趋势相反，即其中一个大于自身的期望值，另外一个却小于自身的期望值，那么两个变量之间的协方差就是负值。</p>\n<p>如果$X$与$Y$是统计独立的，那么二者之间的协方差就是0，因为两个独立的随机变量满足$\\mathrm{E}[XY]=\\mathrm{E}[X]\\mathrm{E}[Y]$。但是，反过来并不成立。即如果$X$与$Y$的协方差为0，二者并不一定是统计独立的。</p>\n<p><strong>协方差为0的两个随机变量称为是不相关的。</strong></p>\n<h3 id=\"协方差矩阵：\"><a href=\"#协方差矩阵：\" class=\"headerlink\" title=\"协方差矩阵：\"></a>协方差矩阵：</h3><p>在统计学与概率论中，协方差矩阵(Covariance matrix)的每个元素是各个向量元素之间的协方差，是从标量随机变量到高维度随机向量的自然推广。</p>\n<p>设$X=\\left(X_{1},X_{2},\\ldots,X_{n}\\right)^{\\mathrm{T}}$为$n$ 维随机变量，称矩阵</p>\n\n$$\nC=\\left(\\begin{array}{cccc} c_{11} & c_{12} & \\cdots & c_{1n}\\\\ c_{21} & c_{22} & \\cdots & c_{2n}\\\\ \\vdots & \\vdots & \\ddots & \\vdots\\\\ c_{n1} & c_{n2} & \\cdots & c_{nn} \\end{array}\\right)\n$$\n\n\n<p>为 n 维随机变量x的协方差矩阵，也记为 $D\\left(X\\right)$ ，其中<br>$$<br>c_{ij}=\\mathrm{Cov}(X_{i},X_{j}),\\quad i,j=1,2,\\ldots,n<br>$$<br>为X的分量$X_{i}$和$X_{j}$的协方差。<em>并且对角线上的元素为各个随机变量的方差：</em></p>\n<p>$$<br>c_{ii}=\\mathrm{Cov}(X_{i},X_{i}),\\quad i=1,2,\\ldots,n<br>$$</p>\n<p>协方差矩阵是对称半正定矩阵。协方差矩阵的对称性，可从定义得知。对于半正定特性，证明如下：</p>\n<p>现给定任意一个非零向量$\\boldsymbol{x}$，则</p>\n\n$$\n\\begin{aligned}\n\\boldsymbol{x}^{\\mathrm{T}}C\\boldsymbol{x}\t&=\\boldsymbol{x}^{\\mathrm{T}}\\mathrm{E}\\left[\\left(X-\\mu\\right)\\left(X-\\mu\\right)^{\\mathrm{T}}\\right]\\boldsymbol{x} \t\n\\\\&=\\mathrm{E}\\left[\\boldsymbol{x}^{\\mathrm{T}}\\left(X-\\mu\\right)\\left(X-\\mu\\right)^{\\mathrm{T}}\\boldsymbol{x}\\right] \t\\\\&=\\mathrm{E}\\left[\\left(\\left(X-\\mu\\right)^{\\mathrm{T}}\\boldsymbol{x}\\right)^{\\mathrm{T}}\\left(\\left(X-\\mu\\right)^{\\mathrm{T}}\\boldsymbol{x}\\right)\\right] \t\n\\\\&=\\mathrm{E}\\left(\\left\\Vert \\left(X-\\mu\\right)^{\\mathrm{T}}\\boldsymbol{x}\\right\\Vert ^{2}\\right) \t\n\\\\&=\\sigma_{X}^{2}\n\\end{aligned}\n$$\n\n\n<p>其中，<br>$$<br>\\sigma_{X}=\\left(X-\\mu \\right)^{\\mathrm{T}}\\boldsymbol{x}<br>$$<br>由于 $\\sigma_{X}^{2}\\geq0$，因此$\\boldsymbol{x}^{\\mathrm{T}}C\\boldsymbol{x}\\geq0$，因此协方差矩阵$C$ 是半正定矩阵。</p>\n"},{"title":"低秩逼近的思考","date":"2021-08-06T08:38:25.000Z","math":true,"_content":"\n> 阅读文章**Semi-orthogonal Embedding for Effificient Unsupervised Anomaly Segmentation**时出现一个概念--**Low-rank approximation** ，就此进行相关讨论。\n\n### 低秩（Low-Rank）\n\n如果X是一个m行n列的数值矩阵，rank(X)是X的秩，假如rank (X)远小于m和n，则我们称X是低秩矩阵。低秩矩阵每行或每列都可以用其他的行或列线性表出，可见它包含大量的冗余信息。利用这种冗余信息，可以对缺失数据进行恢复，也可以对数据进行特征提取。\n\n图像处理中，*rank可以理解为图像所包含的信息的丰富程度*，在显示生活中，一张图片中大部分成分是相似的。比如给一张大草原的图片\n\n![](https://pic1.zhimg.com/50/ce29981e00f4d519ff547e986bf8a5d6_720w.jpg?source=1940ef5c)\n\n\n\n草原是由很多草组成的，而草是相似的，所以如果全是草，那么这张图所包含的信息量是很少的的，因为可以理解为草是草的复制品。而上图的蒙古包，人，马之类的则可以理解为图片所包含的信息，实际上，相对于只有草的草原图片和有草和蒙古包的草原图片，后者的秩是较高的。也就是说，图片中比较突兀的成分，比如蒙古包，比如人像照片中的红眼亮点，会增加图像矩阵的秩。而现实生活中一张不错的图片的秩其实是比较低的，如果图像的秩比较高，往往是因为图像中的噪声比较严重。比如拍照的时候ISO感光度设置过高造成噪点太过泛滥之类的。所以，*图像处理的低秩性其实可以拿来去除照片中的噪点*。\n\n### 低秩和稀疏\n\n我们认为图像有一些公共的模式，所有图像都由这些基本的模式组成。例如，如果图像是一个叉，可以看成是一个正斜线和反斜线的叠加。**只要我们找到了所有的基底（称作字典**，就是上面说的正斜线和反斜线之类的东西）**，就能通过基底的线性组合表示出所有的图像。**这就好像学画画，先学会基本的画正方体、球体、圆柱体等等，就可以组合出各种各样的复杂形状。\n\n**在很多情形下，基底的数量是很少的**，比如一张照片拍的是一面砖墙，那么它显然具有周期重复的特点，换句话说低秩。即使整个图不低秩，往往也能找出一些相似的块，这些块是低秩的。再退一步，就算这也做不到，往往也可以把已有的数据看成一组低维的结果加上噪声，也即原来的数据**可以被低秩矩阵很好的逼近**。**稀疏性**的意思是（以稀疏表示为例），任给一个图像，**字典可能是过完备的**，从而用字典里的基向量表出这幅图有很多种不同的方案。我们希望**选取使用基底数量最少的那种方案**，\n\n应用：\n\n***1）矩阵填充(Matrix Completion)***\n\n***2）鲁棒PCA***\n\n***3）背景建模***\n\n***4）变换不变低秩纹理（TILT）***\n\n> 在论文 **Semi-orthogonal Embedding for Effificient Unsupervised Anomaly Segmentation**中有一段可以参考。\n\n**Low-rank approximation of precision matrix**\n\nThe feature data **X** is subject to low-rank approximation due to the narrower target domain for anomaly-free images than the ImageNet dataset’s. The multi-scale features from different layers may also contribute to it due to the inter-dependency among the features from the layers. Inspired by the truncated SVD of a precision matrix, a low-rank embedding of input features with **W** *∈* $R^{F*k}$,where *F > k*, is considered as follows:\n$$\nd^2_{i,j} = X^TW(W^TC_{i,j}W)^{−1}W^TX\n$$\nwhere the below Theorem 1 shows the optimal **W*** is the eigenvectors related to the *k*-smallest eigenvalues of $C_{i,j}$ . Notice that 1) the computational complexity of the equation is cubically reduced to *O*($HWk^3$) set aside the cost of SVD, although which is the concern, 2) PCA embedding would fail to minimize approximation error since it uses the *k*-largest eigenvectors [14], and 3) near-zero eigenvalues may induce substantial anomaly scores.\n\n选取协方差矩阵的k个最小的特征值对应的特征向量，进行低秩逼近\n\n> 参考\n>\n>  https://www.zhihu.com/question/28630628\n>\n> https://blog.csdn.net/zouxy09/article/details/24972869\n","source":"_posts/math/low-rank-app.md","raw":"---\ntitle: 低秩逼近的思考\ndate: 2021-08-06 16:38:25\ntags: [math,线性代数]\ncategories: [math,线性代数]\nmath: true\n---\n\n> 阅读文章**Semi-orthogonal Embedding for Effificient Unsupervised Anomaly Segmentation**时出现一个概念--**Low-rank approximation** ，就此进行相关讨论。\n\n### 低秩（Low-Rank）\n\n如果X是一个m行n列的数值矩阵，rank(X)是X的秩，假如rank (X)远小于m和n，则我们称X是低秩矩阵。低秩矩阵每行或每列都可以用其他的行或列线性表出，可见它包含大量的冗余信息。利用这种冗余信息，可以对缺失数据进行恢复，也可以对数据进行特征提取。\n\n图像处理中，*rank可以理解为图像所包含的信息的丰富程度*，在显示生活中，一张图片中大部分成分是相似的。比如给一张大草原的图片\n\n![](https://pic1.zhimg.com/50/ce29981e00f4d519ff547e986bf8a5d6_720w.jpg?source=1940ef5c)\n\n\n\n草原是由很多草组成的，而草是相似的，所以如果全是草，那么这张图所包含的信息量是很少的的，因为可以理解为草是草的复制品。而上图的蒙古包，人，马之类的则可以理解为图片所包含的信息，实际上，相对于只有草的草原图片和有草和蒙古包的草原图片，后者的秩是较高的。也就是说，图片中比较突兀的成分，比如蒙古包，比如人像照片中的红眼亮点，会增加图像矩阵的秩。而现实生活中一张不错的图片的秩其实是比较低的，如果图像的秩比较高，往往是因为图像中的噪声比较严重。比如拍照的时候ISO感光度设置过高造成噪点太过泛滥之类的。所以，*图像处理的低秩性其实可以拿来去除照片中的噪点*。\n\n### 低秩和稀疏\n\n我们认为图像有一些公共的模式，所有图像都由这些基本的模式组成。例如，如果图像是一个叉，可以看成是一个正斜线和反斜线的叠加。**只要我们找到了所有的基底（称作字典**，就是上面说的正斜线和反斜线之类的东西）**，就能通过基底的线性组合表示出所有的图像。**这就好像学画画，先学会基本的画正方体、球体、圆柱体等等，就可以组合出各种各样的复杂形状。\n\n**在很多情形下，基底的数量是很少的**，比如一张照片拍的是一面砖墙，那么它显然具有周期重复的特点，换句话说低秩。即使整个图不低秩，往往也能找出一些相似的块，这些块是低秩的。再退一步，就算这也做不到，往往也可以把已有的数据看成一组低维的结果加上噪声，也即原来的数据**可以被低秩矩阵很好的逼近**。**稀疏性**的意思是（以稀疏表示为例），任给一个图像，**字典可能是过完备的**，从而用字典里的基向量表出这幅图有很多种不同的方案。我们希望**选取使用基底数量最少的那种方案**，\n\n应用：\n\n***1）矩阵填充(Matrix Completion)***\n\n***2）鲁棒PCA***\n\n***3）背景建模***\n\n***4）变换不变低秩纹理（TILT）***\n\n> 在论文 **Semi-orthogonal Embedding for Effificient Unsupervised Anomaly Segmentation**中有一段可以参考。\n\n**Low-rank approximation of precision matrix**\n\nThe feature data **X** is subject to low-rank approximation due to the narrower target domain for anomaly-free images than the ImageNet dataset’s. The multi-scale features from different layers may also contribute to it due to the inter-dependency among the features from the layers. Inspired by the truncated SVD of a precision matrix, a low-rank embedding of input features with **W** *∈* $R^{F*k}$,where *F > k*, is considered as follows:\n$$\nd^2_{i,j} = X^TW(W^TC_{i,j}W)^{−1}W^TX\n$$\nwhere the below Theorem 1 shows the optimal **W*** is the eigenvectors related to the *k*-smallest eigenvalues of $C_{i,j}$ . Notice that 1) the computational complexity of the equation is cubically reduced to *O*($HWk^3$) set aside the cost of SVD, although which is the concern, 2) PCA embedding would fail to minimize approximation error since it uses the *k*-largest eigenvectors [14], and 3) near-zero eigenvalues may induce substantial anomaly scores.\n\n选取协方差矩阵的k个最小的特征值对应的特征向量，进行低秩逼近\n\n> 参考\n>\n>  https://www.zhihu.com/question/28630628\n>\n> https://blog.csdn.net/zouxy09/article/details/24972869\n","slug":"math/low-rank-app","published":1,"updated":"2021-08-09T10:08:30.748Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cksa5ksfs003na0x49p905ia7","content":"<blockquote>\n<p>阅读文章<strong>Semi-orthogonal Embedding for Effificient Unsupervised Anomaly Segmentation</strong>时出现一个概念–<strong>Low-rank approximation</strong> ，就此进行相关讨论。</p>\n</blockquote>\n<h3 id=\"低秩（Low-Rank）\"><a href=\"#低秩（Low-Rank）\" class=\"headerlink\" title=\"低秩（Low-Rank）\"></a>低秩（Low-Rank）</h3><p>如果X是一个m行n列的数值矩阵，rank(X)是X的秩，假如rank (X)远小于m和n，则我们称X是低秩矩阵。低秩矩阵每行或每列都可以用其他的行或列线性表出，可见它包含大量的冗余信息。利用这种冗余信息，可以对缺失数据进行恢复，也可以对数据进行特征提取。</p>\n<p>图像处理中，<em>rank可以理解为图像所包含的信息的丰富程度</em>，在显示生活中，一张图片中大部分成分是相似的。比如给一张大草原的图片</p>\n<p><img src=\"https://pic1.zhimg.com/50/ce29981e00f4d519ff547e986bf8a5d6_720w.jpg?source=1940ef5c\"></p>\n<p>草原是由很多草组成的，而草是相似的，所以如果全是草，那么这张图所包含的信息量是很少的的，因为可以理解为草是草的复制品。而上图的蒙古包，人，马之类的则可以理解为图片所包含的信息，实际上，相对于只有草的草原图片和有草和蒙古包的草原图片，后者的秩是较高的。也就是说，图片中比较突兀的成分，比如蒙古包，比如人像照片中的红眼亮点，会增加图像矩阵的秩。而现实生活中一张不错的图片的秩其实是比较低的，如果图像的秩比较高，往往是因为图像中的噪声比较严重。比如拍照的时候ISO感光度设置过高造成噪点太过泛滥之类的。所以，<em>图像处理的低秩性其实可以拿来去除照片中的噪点</em>。</p>\n<h3 id=\"低秩和稀疏\"><a href=\"#低秩和稀疏\" class=\"headerlink\" title=\"低秩和稀疏\"></a>低秩和稀疏</h3><p>我们认为图像有一些公共的模式，所有图像都由这些基本的模式组成。例如，如果图像是一个叉，可以看成是一个正斜线和反斜线的叠加。<strong>只要我们找到了所有的基底（称作字典</strong>，就是上面说的正斜线和反斜线之类的东西）<strong>，就能通过基底的线性组合表示出所有的图像。</strong>这就好像学画画，先学会基本的画正方体、球体、圆柱体等等，就可以组合出各种各样的复杂形状。</p>\n<p><strong>在很多情形下，基底的数量是很少的</strong>，比如一张照片拍的是一面砖墙，那么它显然具有周期重复的特点，换句话说低秩。即使整个图不低秩，往往也能找出一些相似的块，这些块是低秩的。再退一步，就算这也做不到，往往也可以把已有的数据看成一组低维的结果加上噪声，也即原来的数据<strong>可以被低秩矩阵很好的逼近</strong>。<strong>稀疏性</strong>的意思是（以稀疏表示为例），任给一个图像，<strong>字典可能是过完备的</strong>，从而用字典里的基向量表出这幅图有很多种不同的方案。我们希望<strong>选取使用基底数量最少的那种方案</strong>，</p>\n<p>应用：</p>\n<p><em><strong>1）矩阵填充(Matrix Completion)</strong></em></p>\n<p><em><strong>2）鲁棒PCA</strong></em></p>\n<p><em><strong>3）背景建模</strong></em></p>\n<p><em><strong>4）变换不变低秩纹理（TILT）</strong></em></p>\n<blockquote>\n<p>在论文 <strong>Semi-orthogonal Embedding for Effificient Unsupervised Anomaly Segmentation</strong>中有一段可以参考。</p>\n</blockquote>\n<p><strong>Low-rank approximation of precision matrix</strong></p>\n<p>The feature data <strong>X</strong> is subject to low-rank approximation due to the narrower target domain for anomaly-free images than the ImageNet dataset’s. The multi-scale features from different layers may also contribute to it due to the inter-dependency among the features from the layers. Inspired by the truncated SVD of a precision matrix, a low-rank embedding of input features with <strong>W</strong> <em>∈</em> $R^{F<em>k}$,where <em>F &gt; k</em>, is considered as follows:<br>$$<br>d^2_{i,j} = X^TW(W^TC_{i,j}W)^{−1}W^TX<br>$$<br>where the below Theorem 1 shows the optimal <strong>W</strong></em> is the eigenvectors related to the <em>k</em>-smallest eigenvalues of $C_{i,j}$ . Notice that 1) the computational complexity of the equation is cubically reduced to <em>O</em>($HWk^3$) set aside the cost of SVD, although which is the concern, 2) PCA embedding would fail to minimize approximation error since it uses the <em>k</em>-largest eigenvectors [14], and 3) near-zero eigenvalues may induce substantial anomaly scores.</p>\n<p>选取协方差矩阵的k个最小的特征值对应的特征向量，进行低秩逼近</p>\n<blockquote>\n<p>参考</p>\n<p> <a href=\"https://www.zhihu.com/question/28630628\">https://www.zhihu.com/question/28630628</a></p>\n<p><a href=\"https://blog.csdn.net/zouxy09/article/details/24972869\">https://blog.csdn.net/zouxy09/article/details/24972869</a></p>\n</blockquote>\n","site":{"data":{"friends":[{"avatar":"http://image.luokangyuan.com/1_qq_27922023.jpg","name":"码酱","introduction":"我不是大佬，只是在追寻大佬的脚步","url":"http://luokangyuan.com/","title":"前去学习"},{"avatar":"http://image.luokangyuan.com/4027734.jpeg","name":"闪烁之狐","introduction":"编程界大佬，技术牛，人还特别好，不懂的都可以请教大佬","url":"https://blinkfox.github.io/","title":"前去学习"},{"avatar":"http://image.luokangyuan.com/avatar.jpg","name":"ja_rome","introduction":"平凡的脚步也可以走出伟大的行程","url":"https://me.csdn.net/jlh912008548","title":"前去学习"}]}},"excerpt":"","more":"<blockquote>\n<p>阅读文章<strong>Semi-orthogonal Embedding for Effificient Unsupervised Anomaly Segmentation</strong>时出现一个概念–<strong>Low-rank approximation</strong> ，就此进行相关讨论。</p>\n</blockquote>\n<h3 id=\"低秩（Low-Rank）\"><a href=\"#低秩（Low-Rank）\" class=\"headerlink\" title=\"低秩（Low-Rank）\"></a>低秩（Low-Rank）</h3><p>如果X是一个m行n列的数值矩阵，rank(X)是X的秩，假如rank (X)远小于m和n，则我们称X是低秩矩阵。低秩矩阵每行或每列都可以用其他的行或列线性表出，可见它包含大量的冗余信息。利用这种冗余信息，可以对缺失数据进行恢复，也可以对数据进行特征提取。</p>\n<p>图像处理中，<em>rank可以理解为图像所包含的信息的丰富程度</em>，在显示生活中，一张图片中大部分成分是相似的。比如给一张大草原的图片</p>\n<p><img src=\"https://pic1.zhimg.com/50/ce29981e00f4d519ff547e986bf8a5d6_720w.jpg?source=1940ef5c\"></p>\n<p>草原是由很多草组成的，而草是相似的，所以如果全是草，那么这张图所包含的信息量是很少的的，因为可以理解为草是草的复制品。而上图的蒙古包，人，马之类的则可以理解为图片所包含的信息，实际上，相对于只有草的草原图片和有草和蒙古包的草原图片，后者的秩是较高的。也就是说，图片中比较突兀的成分，比如蒙古包，比如人像照片中的红眼亮点，会增加图像矩阵的秩。而现实生活中一张不错的图片的秩其实是比较低的，如果图像的秩比较高，往往是因为图像中的噪声比较严重。比如拍照的时候ISO感光度设置过高造成噪点太过泛滥之类的。所以，<em>图像处理的低秩性其实可以拿来去除照片中的噪点</em>。</p>\n<h3 id=\"低秩和稀疏\"><a href=\"#低秩和稀疏\" class=\"headerlink\" title=\"低秩和稀疏\"></a>低秩和稀疏</h3><p>我们认为图像有一些公共的模式，所有图像都由这些基本的模式组成。例如，如果图像是一个叉，可以看成是一个正斜线和反斜线的叠加。<strong>只要我们找到了所有的基底（称作字典</strong>，就是上面说的正斜线和反斜线之类的东西）<strong>，就能通过基底的线性组合表示出所有的图像。</strong>这就好像学画画，先学会基本的画正方体、球体、圆柱体等等，就可以组合出各种各样的复杂形状。</p>\n<p><strong>在很多情形下，基底的数量是很少的</strong>，比如一张照片拍的是一面砖墙，那么它显然具有周期重复的特点，换句话说低秩。即使整个图不低秩，往往也能找出一些相似的块，这些块是低秩的。再退一步，就算这也做不到，往往也可以把已有的数据看成一组低维的结果加上噪声，也即原来的数据<strong>可以被低秩矩阵很好的逼近</strong>。<strong>稀疏性</strong>的意思是（以稀疏表示为例），任给一个图像，<strong>字典可能是过完备的</strong>，从而用字典里的基向量表出这幅图有很多种不同的方案。我们希望<strong>选取使用基底数量最少的那种方案</strong>，</p>\n<p>应用：</p>\n<p><em><strong>1）矩阵填充(Matrix Completion)</strong></em></p>\n<p><em><strong>2）鲁棒PCA</strong></em></p>\n<p><em><strong>3）背景建模</strong></em></p>\n<p><em><strong>4）变换不变低秩纹理（TILT）</strong></em></p>\n<blockquote>\n<p>在论文 <strong>Semi-orthogonal Embedding for Effificient Unsupervised Anomaly Segmentation</strong>中有一段可以参考。</p>\n</blockquote>\n<p><strong>Low-rank approximation of precision matrix</strong></p>\n<p>The feature data <strong>X</strong> is subject to low-rank approximation due to the narrower target domain for anomaly-free images than the ImageNet dataset’s. The multi-scale features from different layers may also contribute to it due to the inter-dependency among the features from the layers. Inspired by the truncated SVD of a precision matrix, a low-rank embedding of input features with <strong>W</strong> <em>∈</em> $R^{F<em>k}$,where <em>F &gt; k</em>, is considered as follows:<br>$$<br>d^2_{i,j} = X^TW(W^TC_{i,j}W)^{−1}W^TX<br>$$<br>where the below Theorem 1 shows the optimal <strong>W</strong></em> is the eigenvectors related to the <em>k</em>-smallest eigenvalues of $C_{i,j}$ . Notice that 1) the computational complexity of the equation is cubically reduced to <em>O</em>($HWk^3$) set aside the cost of SVD, although which is the concern, 2) PCA embedding would fail to minimize approximation error since it uses the <em>k</em>-largest eigenvectors [14], and 3) near-zero eigenvalues may induce substantial anomaly scores.</p>\n<p>选取协方差矩阵的k个最小的特征值对应的特征向量，进行低秩逼近</p>\n<blockquote>\n<p>参考</p>\n<p> <a href=\"https://www.zhihu.com/question/28630628\">https://www.zhihu.com/question/28630628</a></p>\n<p><a href=\"https://blog.csdn.net/zouxy09/article/details/24972869\">https://blog.csdn.net/zouxy09/article/details/24972869</a></p>\n</blockquote>\n"}],"PostAsset":[],"PostCategory":[{"post_id":"cksa5kseg0001a0x4ea7vc6s3","category_id":"cksa5ksek0004a0x44uoe7ta5","_id":"cksa5kses000ia0x4bmjs7i37"},{"post_id":"cksa5ksej0003a0x42r6jb0qq","category_id":"cksa5ksep000ca0x47so09han","_id":"cksa5ksex000pa0x46tipd2hi"},{"post_id":"cksa5ksem0007a0x4aa4ighm6","category_id":"cksa5ksep000ca0x47so09han","_id":"cksa5ksey000ta0x40vmb6grb"},{"post_id":"cksa5ksen0009a0x4gq7n8cx7","category_id":"cksa5ksev000oa0x42pw950jz","_id":"cksa5ksf00010a0x4dllb8lhd"},{"post_id":"cksa5kseo000ba0x4ffzx0scr","category_id":"cksa5ksev000oa0x42pw950jz","_id":"cksa5ksf20015a0x4hohvdrdz"},{"post_id":"cksa5kseq000ga0x43jjy6zi6","category_id":"cksa5ksf0000za0x43yw86jlg","_id":"cksa5ksf4001ba0x4embifiv5"},{"post_id":"cksa5kset000la0x48z6n6nu5","category_id":"cksa5ksf4001ca0x48qe954qh","_id":"cksa5ksf5001ha0x4f555bf1b"},{"post_id":"cksa5kseu000na0x4edtzed9i","category_id":"cksa5ksf5001fa0x41irvcs3k","_id":"cksa5ksf6001na0x4cbzm0ndv"},{"post_id":"cksa5ksex000ra0x46zonflea","category_id":"cksa5ksf5001fa0x41irvcs3k","_id":"cksa5ksf7001sa0x476x7bfa4"},{"post_id":"cksa5ksey000sa0x40r216wc0","category_id":"cksa5ksf5001fa0x41irvcs3k","_id":"cksa5ksf7001va0x471uqc6i1"},{"post_id":"cksa5ksez000wa0x428so4bu3","category_id":"cksa5ksf5001fa0x41irvcs3k","_id":"cksa5ksf8001ya0x4g7lo47a1"},{"post_id":"cksa5ksez000ya0x42lk4gie1","category_id":"cksa5ksf5001fa0x41irvcs3k","_id":"cksa5ksf90022a0x49njl5nw9"},{"post_id":"cksa5ksf00012a0x4hvx7c32h","category_id":"cksa5ksf5001fa0x41irvcs3k","_id":"cksa5ksf90026a0x49bh517zn"},{"post_id":"cksa5kser000ha0x42o9ncw4n","category_id":"cksa5ksf20016a0x41tixf2m8","_id":"cksa5ksfc002ia0x4b2re0ubl"},{"post_id":"cksa5kser000ha0x42o9ncw4n","category_id":"cksa5ksfb002ca0x44dmw7jsa","_id":"cksa5ksfc002la0x469ngdvzt"},{"post_id":"cksa5ksf10014a0x42wb874nd","category_id":"cksa5ksf90021a0x41n4i8jki","_id":"cksa5ksfd002oa0x4etno2vs4"},{"post_id":"cksa5ksf10014a0x42wb874nd","category_id":"cksa5ksfb002ga0x49jeo7noc","_id":"cksa5ksfd002qa0x4e9z225xz"},{"post_id":"cksa5ksf20017a0x43j87b86r","category_id":"cksa5ksf90021a0x41n4i8jki","_id":"cksa5ksfd002sa0x4fjlncbun"},{"post_id":"cksa5ksf20017a0x43j87b86r","category_id":"cksa5ksfc002ja0x46nxg0ux6","_id":"cksa5ksfe002ua0x463ipepbb"},{"post_id":"cksa5ksf30019a0x45nzfd6e9","category_id":"cksa5ksf90021a0x41n4i8jki","_id":"cksa5ksfe002xa0x4bium0ky5"},{"post_id":"cksa5ksf30019a0x45nzfd6e9","category_id":"cksa5ksfc002ja0x46nxg0ux6","_id":"cksa5ksfe002ya0x4g0eefd5f"},{"post_id":"cksa5ksfs003na0x49p905ia7","category_id":"cksa5ksf90021a0x41n4i8jki","_id":"cksa5ksft003qa0x489ed6r6l"},{"post_id":"cksa5ksfs003na0x49p905ia7","category_id":"cksa5ksfb002ga0x49jeo7noc","_id":"cksa5ksft003ra0x4gs4kehi7"}],"PostTag":[{"post_id":"cksa5kseg0001a0x4ea7vc6s3","tag_id":"cksa5ksel0005a0x42azs6crv","_id":"cksa5ksep000ea0x4dt2u2140"},{"post_id":"cksa5ksej0003a0x42r6jb0qq","tag_id":"cksa5ksep000da0x4027h1fwh","_id":"cksa5kseu000ma0x456dr1058"},{"post_id":"cksa5ksem0007a0x4aa4ighm6","tag_id":"cksa5kses000ka0x4gd4u07d3","_id":"cksa5ksez000xa0x4fe0jaroe"},{"post_id":"cksa5ksem0007a0x4aa4ighm6","tag_id":"cksa5ksex000qa0x4d7snel6i","_id":"cksa5ksf00011a0x4h19x6dt7"},{"post_id":"cksa5ksen0009a0x4gq7n8cx7","tag_id":"cksa5ksey000va0x4f5cq26mp","_id":"cksa5ksf3001aa0x4c3mdhpyx"},{"post_id":"cksa5ksen0009a0x4gq7n8cx7","tag_id":"cksa5ksf10013a0x47hov65i1","_id":"cksa5ksf4001da0x431o03092"},{"post_id":"cksa5kseo000ba0x4ffzx0scr","tag_id":"cksa5ksey000va0x4f5cq26mp","_id":"cksa5ksf6001ka0x4149xciry"},{"post_id":"cksa5kseo000ba0x4ffzx0scr","tag_id":"cksa5ksf10013a0x47hov65i1","_id":"cksa5ksf6001la0x46n3q1tvf"},{"post_id":"cksa5kseo000ba0x4ffzx0scr","tag_id":"cksa5ksf5001ga0x41jhkfd7y","_id":"cksa5ksf7001pa0x498kag8wp"},{"post_id":"cksa5kseq000ga0x43jjy6zi6","tag_id":"cksa5ksf5001ja0x4bxeadjie","_id":"cksa5ksf7001qa0x49nxih3iv"},{"post_id":"cksa5kser000ha0x42o9ncw4n","tag_id":"cksa5ksf6001oa0x4cfjmdgjc","_id":"cksa5ksf90020a0x4elszbqju"},{"post_id":"cksa5kser000ha0x42o9ncw4n","tag_id":"cksa5ksf7001ta0x4a07i3md1","_id":"cksa5ksf90023a0x4830n2afs"},{"post_id":"cksa5kser000ha0x42o9ncw4n","tag_id":"cksa5ksf8001wa0x4fhfag831","_id":"cksa5ksf90025a0x4adk65rfu"},{"post_id":"cksa5kset000la0x48z6n6nu5","tag_id":"cksa5ksf8001za0x4h5m24p9t","_id":"cksa5ksfa0028a0x4db2mhk6j"},{"post_id":"cksa5kseu000na0x4edtzed9i","tag_id":"cksa5ksf90024a0x47hs5g345","_id":"cksa5ksfb002da0x4dkctber5"},{"post_id":"cksa5kseu000na0x4edtzed9i","tag_id":"cksa5ksfa0029a0x47ls708yp","_id":"cksa5ksfb002ea0x483yfa5kv"},{"post_id":"cksa5ksex000ra0x46zonflea","tag_id":"cksa5ksf90024a0x47hs5g345","_id":"cksa5ksfc002ka0x45ahda8cv"},{"post_id":"cksa5ksex000ra0x46zonflea","tag_id":"cksa5ksfb002fa0x4a9xx38g8","_id":"cksa5ksfc002ma0x42bbw6ezp"},{"post_id":"cksa5ksey000sa0x40r216wc0","tag_id":"cksa5ksf90024a0x47hs5g345","_id":"cksa5ksfd002ta0x4cuc7bpyf"},{"post_id":"cksa5ksey000sa0x40r216wc0","tag_id":"cksa5ksfc002na0x48dlrhkvw","_id":"cksa5ksfe002va0x4cxo94pui"},{"post_id":"cksa5ksez000wa0x428so4bu3","tag_id":"cksa5ksf90024a0x47hs5g345","_id":"cksa5ksfe0030a0x4cw5tg4bq"},{"post_id":"cksa5ksez000wa0x428so4bu3","tag_id":"cksa5ksfe002wa0x437785ac4","_id":"cksa5ksfe0031a0x43oqm6wk1"},{"post_id":"cksa5ksez000ya0x42lk4gie1","tag_id":"cksa5ksf90024a0x47hs5g345","_id":"cksa5ksfg0035a0x4bs1fft17"},{"post_id":"cksa5ksez000ya0x42lk4gie1","tag_id":"cksa5ksff0032a0x489j25p1p","_id":"cksa5ksfg0036a0x49wej0hmu"},{"post_id":"cksa5ksez000ya0x42lk4gie1","tag_id":"cksa5ksff0033a0x46jk0aoqo","_id":"cksa5ksfh0038a0x4b05dexsw"},{"post_id":"cksa5ksf00012a0x4hvx7c32h","tag_id":"cksa5ksf90024a0x47hs5g345","_id":"cksa5ksfh003ba0x41hozensj"},{"post_id":"cksa5ksf00012a0x4hvx7c32h","tag_id":"cksa5ksff0032a0x489j25p1p","_id":"cksa5ksfh003ca0x4a2ux2mpi"},{"post_id":"cksa5ksf00012a0x4hvx7c32h","tag_id":"cksa5ksff0033a0x46jk0aoqo","_id":"cksa5ksfi003ea0x47wlpd4pz"},{"post_id":"cksa5ksf10014a0x42wb874nd","tag_id":"cksa5ksfh003aa0x4773vcxqh","_id":"cksa5ksfi003ga0x4cnweggh2"},{"post_id":"cksa5ksf10014a0x42wb874nd","tag_id":"cksa5ksfh003da0x4d7aebfp1","_id":"cksa5ksfi003ha0x4fpdseomh"},{"post_id":"cksa5ksf20017a0x43j87b86r","tag_id":"cksa5ksfi003fa0x4cykyaclr","_id":"cksa5ksfi003ja0x4a4a78hm0"},{"post_id":"cksa5ksf30019a0x45nzfd6e9","tag_id":"cksa5ksfh003aa0x4773vcxqh","_id":"cksa5ksfj003la0x42abraza8"},{"post_id":"cksa5ksf30019a0x45nzfd6e9","tag_id":"cksa5ksfj003ka0x46306chx2","_id":"cksa5ksfj003ma0x4d37h01nb"},{"post_id":"cksa5ksfs003na0x49p905ia7","tag_id":"cksa5ksfh003aa0x4773vcxqh","_id":"cksa5ksft003oa0x4a3fhdbei"},{"post_id":"cksa5ksfs003na0x49p905ia7","tag_id":"cksa5ksfh003da0x4d7aebfp1","_id":"cksa5ksft003pa0x4bwwh6dh5"}],"Tag":[{"name":"文献","_id":"cksa5ksel0005a0x42azs6crv"},{"name":"深度学习，梯度","_id":"cksa5ksep000da0x4027h1fwh"},{"name":"深度学习","_id":"cksa5kses000ka0x4gd4u07d3"},{"name":"微调","_id":"cksa5ksex000qa0x4d7snel6i"},{"name":"docker","_id":"cksa5ksey000va0x4f5cq26mp"},{"name":"远程配置","_id":"cksa5ksf10013a0x47hov65i1"},{"name":"ssh","_id":"cksa5ksf5001ga0x41jhkfd7y"},{"name":"dvc","_id":"cksa5ksf5001ja0x4bxeadjie"},{"name":"hexo","_id":"cksa5ksf6001oa0x4cfjmdgjc"},{"name":"fluid","_id":"cksa5ksf7001ta0x4a07i3md1"},{"name":"配置","_id":"cksa5ksf8001wa0x4fhfag831"},{"name":"git","_id":"cksa5ksf8001za0x4h5m24p9t"},{"name":"剑指","_id":"cksa5ksf90024a0x47hs5g345"},{"name":"数组","_id":"cksa5ksfa0029a0x47ls708yp"},{"name":"字符串","_id":"cksa5ksfb002fa0x4a9xx38g8"},{"name":"数组查找","_id":"cksa5ksfc002na0x48dlrhkvw"},{"name":"栈","_id":"cksa5ksfe002wa0x437785ac4"},{"name":"斐波那契","_id":"cksa5ksff0032a0x489j25p1p"},{"name":"动态规划","_id":"cksa5ksff0033a0x46jk0aoqo"},{"name":"math","_id":"cksa5ksfh003aa0x4773vcxqh"},{"name":"线性代数","_id":"cksa5ksfh003da0x4d7aebfp1"},{"name":"马氏距离","_id":"cksa5ksfi003fa0x4cykyaclr"},{"name":"概率论","_id":"cksa5ksfj003ka0x46306chx2"}]}}