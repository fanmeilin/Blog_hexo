{"meta":{"version":1,"warehouse":"4.0.0"},"models":{"Asset":[{"_id":"source/CNAME","path":"CNAME","modified":1,"renderable":0},{"_id":"themes/fluid/source/css/gitalk.css","path":"css/gitalk.css","modified":1,"renderable":1},{"_id":"themes/fluid/source/css/main.styl","path":"css/main.styl","modified":1,"renderable":1},{"_id":"themes/fluid/source/img/avatar.png","path":"img/avatar.png","modified":1,"renderable":1},{"_id":"themes/fluid/source/img/default.png","path":"img/default.png","modified":1,"renderable":1},{"_id":"themes/fluid/source/img/favicon.png","path":"img/favicon.png","modified":1,"renderable":1},{"_id":"themes/fluid/source/img/favicon1.png","path":"img/favicon1.png","modified":1,"renderable":1},{"_id":"themes/fluid/source/img/loading.gif","path":"img/loading.gif","modified":1,"renderable":1},{"_id":"themes/fluid/source/img/meicon.png","path":"img/meicon.png","modified":1,"renderable":1},{"_id":"themes/fluid/source/img/meiconbali.jpg","path":"img/meiconbali.jpg","modified":1,"renderable":1},{"_id":"themes/fluid/source/img/police_beian.png","path":"img/police_beian.png","modified":1,"renderable":1},{"_id":"themes/fluid/source/js/boot.js","path":"js/boot.js","modified":1,"renderable":1},{"_id":"themes/fluid/source/js/color-schema.js","path":"js/color-schema.js","modified":1,"renderable":1},{"_id":"themes/fluid/source/js/events.js","path":"js/events.js","modified":1,"renderable":1},{"_id":"themes/fluid/source/js/img-lazyload.js","path":"js/img-lazyload.js","modified":1,"renderable":1},{"_id":"themes/fluid/source/js/leancloud.js","path":"js/leancloud.js","modified":1,"renderable":1},{"_id":"themes/fluid/source/js/local-search.js","path":"js/local-search.js","modified":1,"renderable":1},{"_id":"themes/fluid/source/js/plugins.js","path":"js/plugins.js","modified":1,"renderable":1},{"_id":"themes/fluid/source/js/utils.js","path":"js/utils.js","modified":1,"renderable":1},{"_id":"themes/fluid/source/xml/local-search.xml","path":"xml/local-search.xml","modified":1,"renderable":1},{"_id":"themes/fluid/source/lib/hint/hint.min.css","path":"lib/hint/hint.min.css","modified":1,"renderable":1}],"Cache":[{"_id":"source/CNAME","hash":"2e5dd8c5b74841b2b49fab68b7628476b78e9078","modified":1628237208563},{"_id":"source/404/index.md","hash":"62e7b5d955e560619709cb232c84770eea4f89d0","modified":1628063828058},{"_id":"source/_data/friends.json","hash":"519916312399331fdcee1d72ee4cef6b284908fb","modified":1628064027776},{"_id":"source/_posts/Eckark-young.md","hash":"a56c5b1e2478729c654164dc9c520a21b83021a1","modified":1628494423757},{"_id":"source/_posts/Mahalanobis-distance.md","hash":"cbe7670e05c1a03043d911210950eb77349a08dc","modified":1628493460081},{"_id":"source/_posts/covariance-matrix.md","hash":"99d0795f864890030574066c0382faca492ba08c","modified":1628169263401},{"_id":"source/_posts/git-submodule.md","hash":"38d0d71772a92aae5f71af6840e2f0140a317cca","modified":1628237208563},{"_id":"source/_posts/hexo-math-config.md","hash":"9385cc40c0183e448647f8d1e1cf2e090f29aabe","modified":1628237208572},{"_id":"source/_posts/low-rank-app.md","hash":"8a7957ff3376dcad56224741e56423867527d4a7","modified":1628489471759},{"_id":"source/about/index.md","hash":"6ad944506a4423dc14c4b873517c88264eb53496","modified":1628063494459},{"_id":"source/categories/index.md","hash":"4d36849168b56d025907ee89d14018aa6a97588d","modified":1628063466721},{"_id":"source/contact/index.md","hash":"f094ba3c8a8c85f46715cb0503c66610d03a2cd1","modified":1628063592028},{"_id":"source/friends/index.md","hash":"514e5b3fb524e240a6dca39bef60c784a95e2b67","modified":1628063987355},{"_id":"source/tags/index.md","hash":"feaf990ce7dc3299d419fc52c092dd9c99f56150","modified":1627994916046},{"_id":"themes/fluid/source/css/_pages/_category/category.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1628164697300},{"_id":"themes/fluid/source/css/_pages/_tag/tag.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1628164697301},{"_id":"themes/fluid/.editorconfig","hash":"b595159772f3ee1ef5e6780ce307270e741cb309","modified":1628164697275},{"_id":"themes/fluid/.gitattributes","hash":"3e00e1fb043438cd820d94ee3dc9ffb6718996f3","modified":1628164697276},{"_id":"themes/fluid/.eslintrc","hash":"3df89453e1f63051fafc90f16a8d83951050e316","modified":1628164697276},{"_id":"themes/fluid/.gitignore","hash":"5d7e78749ba0a1efcf61253d4a9e50fc6ce0b4bc","modified":1628164697277},{"_id":"themes/fluid/LICENSE","hash":"694fb3659a4331dd752bd92e4248623bff8617cd","modified":1628164697278},{"_id":"themes/fluid/README.md","hash":"9adb524ba5a0821c8c612fe5619f64f242d5ad6b","modified":1628164697278},{"_id":"themes/fluid/README_en.md","hash":"2b47ed68ec888dcc34fa6aad9ce95aeba6744fec","modified":1628164697278},{"_id":"themes/fluid/_config.yml","hash":"f4611dbb514fabf6aa7edb31cdf90cbf7182a243","modified":1628164697278},{"_id":"themes/fluid/gulpfile.js","hash":"93e2bd4a4f1902e7a4c99ae3ebfa6420fd906c1b","modified":1628164697279},{"_id":"themes/fluid/package.json","hash":"8b6640fe2d7e71900bf708b977074f621b2e7a8a","modified":1628164697289},{"_id":"themes/fluid/languages/de.yml","hash":"288f649c2c2314eb610693b18853ee74f0541e87","modified":1628164697279},{"_id":"themes/fluid/languages/en.yml","hash":"31f2867619a768606166778d4ee51f3d00ac33a0","modified":1628164697279},{"_id":"themes/fluid/languages/eo.yml","hash":"2c1c481d9af116e79fe55a0aa0bdbb143a97f559","modified":1628164697279},{"_id":"themes/fluid/languages/ja.yml","hash":"dc43be11a300893ebef47283c22f2f946ca21260","modified":1628164697279},{"_id":"themes/fluid/languages/zh-CN.yml","hash":"3b92f4428d66c31610f6cde13b82ee723aff00d2","modified":1628164697280},{"_id":"themes/fluid/languages/zh-TW.yml","hash":"de9b7e729d72eee9327671c3d5df0a607c4c3257","modified":1628164697280},{"_id":"themes/fluid/layout/404.ejs","hash":"79a598e43c40d48b23076361720f1e77df466e41","modified":1628164697280},{"_id":"themes/fluid/layout/about.ejs","hash":"5b6de01c82b14834ab1e67f0a803612f5855f064","modified":1628164697287},{"_id":"themes/fluid/layout/archive.ejs","hash":"7a1e19dec37804927f0d331d7e6c80ed03becd61","modified":1628164697287},{"_id":"themes/fluid/layout/categories.ejs","hash":"4255c27c8f31fbcc12ec3a973fe73b7a3a35782f","modified":1628164697287},{"_id":"themes/fluid/layout/category.ejs","hash":"dd2bd15cbd811d6ea973b6e6a17d99e36151e274","modified":1628164697288},{"_id":"themes/fluid/layout/index.ejs","hash":"32a6c84b4690ecf8505ca786bc80aa90530b1534","modified":1628164697288},{"_id":"themes/fluid/layout/layout.ejs","hash":"a8342733553ce3368a8520e6f430666070f7d8dc","modified":1628164697288},{"_id":"themes/fluid/layout/links.ejs","hash":"b282e8888cd844bb24b31677a32feb444ecc4144","modified":1628164697288},{"_id":"themes/fluid/layout/page.ejs","hash":"f867e69e563b8ad83054714f73d9173ea050d93b","modified":1628164697288},{"_id":"themes/fluid/layout/post.ejs","hash":"edfeb655895027d15334d009324d27a29926cc94","modified":1628164697288},{"_id":"themes/fluid/layout/tag.ejs","hash":"3a9296eb7181e8b3fb0cdc60cbafc815b98d6f51","modified":1628164697289},{"_id":"themes/fluid/layout/tags.ejs","hash":"b7c1a6d8fc1097fc16d2300260297013cb692153","modified":1628164697289},{"_id":"themes/fluid/.github/ISSUE_TEMPLATE/bug_report.md","hash":"beb3474d6f65c1e56700ba872c6a0d0836d4168e","modified":1628164697276},{"_id":"themes/fluid/.github/ISSUE_TEMPLATE/bug_report_zh.md","hash":"78ce211415d502c5a4398d786d5c697d34d868b9","modified":1628164697276},{"_id":"themes/fluid/.github/ISSUE_TEMPLATE/feature_request.md","hash":"5cc30e7b6e7b77c8b40b182ba02a5d93d37d2fc2","modified":1628164697277},{"_id":"themes/fluid/.github/ISSUE_TEMPLATE/feature_request_zh.md","hash":"7db378613df2b7d13e8c428c006399a879a4a852","modified":1628164697277},{"_id":"themes/fluid/.github/ISSUE_TEMPLATE/question.md","hash":"102213e5d6790d060c0e26b4a3a7ec744d753c52","modified":1628164697277},{"_id":"themes/fluid/.github/ISSUE_TEMPLATE/question_zh.md","hash":"18381d03518526d7cefd024a0bdd8d9e7c6440f5","modified":1628164697277},{"_id":"themes/fluid/.github/workflows/limit.yaml","hash":"bdbdb66da69ab7353b546f02150a6792f4787975","modified":1628164697277},{"_id":"themes/fluid/.github/workflows/lint.yaml","hash":"4c04caa5ca20bbcbf0934bb7adba4d2cd8a26da2","modified":1628164697277},{"_id":"themes/fluid/layout/_partial/archive-list.ejs","hash":"7d780309e12c437c2f8a246dd2fd0c272b8636ce","modified":1628164697280},{"_id":"themes/fluid/layout/_partial/css.ejs","hash":"04957fcd5c9025da54d593652b51939e54056827","modified":1628164697283},{"_id":"themes/fluid/layout/_partial/beian.ejs","hash":"53d9f79b4a3b71d2e89872fa138bc09611862ee4","modified":1628164697281},{"_id":"themes/fluid/layout/_partial/footer.ejs","hash":"585bb98a23ced3cfbbff6d73d48fdbcd4a87577a","modified":1628164697283},{"_id":"themes/fluid/layout/_partial/head.ejs","hash":"8e29e7ddbda1555c0f9d0d4b5d4550975fec7537","modified":1628164697284},{"_id":"themes/fluid/layout/_partial/nav.ejs","hash":"48944e12d95dc46137f9f270629296cfd2a8dd22","modified":1628164697285},{"_id":"themes/fluid/layout/_partial/paginator.ejs","hash":"0d443f23c459787338917900f50fec1c8b3b3bdd","modified":1628164697285},{"_id":"themes/fluid/layout/_partial/post-meta.ejs","hash":"3f16de8c40d87c7d23eba121dd8061757c3f9a58","modified":1628164697286},{"_id":"themes/fluid/layout/_partial/scripts.ejs","hash":"1d8349b7d26271e08cee592aa66f9c79ec41c3c0","modified":1628164697286},{"_id":"themes/fluid/layout/_partial/search.ejs","hash":"bea21f1b5de61badd6c068080315c201fc80bc36","modified":1628164697286},{"_id":"themes/fluid/layout/_partial/statistics.ejs","hash":"a70c26e415a27f07f38b9384e7eb48d1f2b30328","modified":1628164697287},{"_id":"themes/fluid/layout/_partial/toc.ejs","hash":"76e6bc368cf46d4103ea9514699e10ec0b9a4b56","modified":1628164697287},{"_id":"themes/fluid/scripts/events/index.js","hash":"91defe82d50a317903411f0b260da0f140f43dc4","modified":1628164697289},{"_id":"themes/fluid/scripts/generators/local-search.js","hash":"bda7fbe58082a2a02c0db066794b791b14462271","modified":1628164697292},{"_id":"themes/fluid/scripts/generators/pages.js","hash":"a2a15ea722863aba09dcad578558432682a3b6b3","modified":1628164697292},{"_id":"themes/fluid/scripts/filters/locals.js","hash":"2340a576635b16fd2456b3494f5afe89cd7764db","modified":1628164697291},{"_id":"themes/fluid/scripts/filters/post-filter.js","hash":"cb72e5acfba882a6eacd6cae8db3238bb078737a","modified":1628164697291},{"_id":"themes/fluid/scripts/tags/button.js","hash":"e1d0caed12e7cd9a35cf64272c41854b2901a58f","modified":1628164697293},{"_id":"themes/fluid/scripts/tags/checkbox.js","hash":"dac0e08eaa3614a6fd9ddbdfb4584094b1bdb30a","modified":1628164697293},{"_id":"themes/fluid/scripts/tags/group-image.js","hash":"cc176cc1d7e7cc28cedf8397ae748c691d140be2","modified":1628164697293},{"_id":"themes/fluid/scripts/tags/label.js","hash":"6c5916d86c63795c7e910bf614b0e7ece5073702","modified":1628164697294},{"_id":"themes/fluid/scripts/tags/mermaid.js","hash":"dbfe59fde77d87b1d7d0c46480a2a729010988eb","modified":1628164697294},{"_id":"themes/fluid/scripts/tags/note.js","hash":"8020acc2c4bb3a2054e3cb349fac7cd10b79a0be","modified":1628164697294},{"_id":"themes/fluid/scripts/helpers/export-config.js","hash":"c72a7373c19b730e926b476eb528f651617ac4f2","modified":1628164697292},{"_id":"themes/fluid/scripts/helpers/page.js","hash":"49b2c6449d7be35739c6cfea3cab4e790580983a","modified":1628164697292},{"_id":"themes/fluid/scripts/helpers/url.js","hash":"1664f8faa028898bd6f91d6db61c7dbf7463ee01","modified":1628164697292},{"_id":"themes/fluid/scripts/helpers/utils.js","hash":"4acb213f90f1e7ba3696ef08d894a2a84807b669","modified":1628164697293},{"_id":"themes/fluid/scripts/helpers/wordcount.js","hash":"da6144ee040fed0a9b9f45da3478bc33087b5ac9","modified":1628164697293},{"_id":"themes/fluid/scripts/utils/join-path.js","hash":"ec068c699155565aea4aa4ab55d8a10b2947a114","modified":1628164697294},{"_id":"themes/fluid/scripts/utils/object.js","hash":"d798779ec79a53ce04b8ac79efd5d064981d95bd","modified":1628164697294},{"_id":"themes/fluid/source/css/gitalk.css","hash":"1fe60b2ab1d704f5a4f55e700dca5b8785fb390e","modified":1628164697303},{"_id":"themes/fluid/source/css/main.styl","hash":"bf536db598434c36cc0c752196bfde46e584a92e","modified":1628164697303},{"_id":"themes/fluid/source/img/avatar.png","hash":"fe739a158cc128f70f780eb5fa96f388b81d478f","modified":1628164697304},{"_id":"themes/fluid/source/img/default.png","hash":"7bb2b8ee07db305bcadee2985b81b942027ae940","modified":1628164697304},{"_id":"themes/fluid/source/img/favicon.png","hash":"fe739a158cc128f70f780eb5fa96f388b81d478f","modified":1628164697304},{"_id":"themes/fluid/source/img/favicon1.png","hash":"64b215db2cb3af98fe639e94537cb5209f959c78","modified":1628164697304},{"_id":"themes/fluid/source/img/loading.gif","hash":"2d2fc0f947940f98c21afafef39ecf226a2e8d55","modified":1628164697304},{"_id":"themes/fluid/source/img/police_beian.png","hash":"90efded6baa2dde599a9d6b1387973e8e64923ea","modified":1628164697305},{"_id":"themes/fluid/source/js/boot.js","hash":"5264c0d2eb73b4948ee6bcb1bd847a924d906088","modified":1628164697305},{"_id":"themes/fluid/source/js/color-schema.js","hash":"2840108a36b1e9a02cd2ed25adcffde08c42e1cc","modified":1628164697305},{"_id":"themes/fluid/source/js/events.js","hash":"2c40be98f3471427626b9130fd231bc7e9a66d03","modified":1628164697305},{"_id":"themes/fluid/source/js/img-lazyload.js","hash":"67f6250f98b36a6599ea982d11cbb060c5ffb92a","modified":1628164697306},{"_id":"themes/fluid/source/js/leancloud.js","hash":"ca82e71e31d3d5ef7fe9487756af06d4e27d9b53","modified":1628164697306},{"_id":"themes/fluid/source/js/local-search.js","hash":"3b9322b6b669c870360db468446b00f53bd1b44c","modified":1628164697306},{"_id":"themes/fluid/source/js/plugins.js","hash":"1afcd1ca415edc994ae813d6f5d54dd3d1888bc4","modified":1628164697307},{"_id":"themes/fluid/source/js/utils.js","hash":"f20aa828122fce9a76c03b07c7da142704edc8c0","modified":1628164697307},{"_id":"themes/fluid/source/xml/local-search.xml","hash":"85fcc23b4db654a7f91fc55b6fb0442bb3ed3a9a","modified":1628164697308},{"_id":"themes/fluid/layout/_partial/comments/changyan.ejs","hash":"b13e69e555ddec2a71710e07178793e7e13319e7","modified":1628164697281},{"_id":"themes/fluid/layout/_partial/comments/cusdis.ejs","hash":"1e93ca89777e4beb0f0e5cb70e03aab48e958542","modified":1628164697281},{"_id":"themes/fluid/layout/_partial/comments/gitalk.ejs","hash":"7f04e5c22821bb94da791973d9c6692b03bac81d","modified":1628164697282},{"_id":"themes/fluid/layout/_partial/comments/disqus.ejs","hash":"7a35381478328b65c9d81827504c4e031bc76a86","modified":1628164697281},{"_id":"themes/fluid/layout/_partial/comments/livere.ejs","hash":"bcceafab01fe695c59951d939f7cef502f3d7b48","modified":1628164697282},{"_id":"themes/fluid/layout/_partial/comments/remark42.ejs","hash":"45c879768b40ba56af62e18ad54bffbf73a6f3a1","modified":1628164697282},{"_id":"themes/fluid/layout/_partial/comments/twikoo.ejs","hash":"c3297931cf5d3d1bc53d988b74cbc54dd06ebbd7","modified":1628164697282},{"_id":"themes/fluid/layout/_partial/comments/utterances.ejs","hash":"d1e86754c9560f7346200b2aa9a7f715a3fac82b","modified":1628164697282},{"_id":"themes/fluid/layout/_partial/comments/valine.ejs","hash":"caae3f692523275b8ca1c56c009a6aeb9c7fdc03","modified":1628164697283},{"_id":"themes/fluid/layout/_partial/comments/waline.ejs","hash":"d6f6620fbc6cf3df5a52322378c0d703b7e1fcf9","modified":1628164697283},{"_id":"themes/fluid/layout/_partial/plugins/analytics.ejs","hash":"d20f54bf2fd5cd274b4b9c5542eafbfec5120838","modified":1628164697285},{"_id":"themes/fluid/layout/_partial/plugins/math.ejs","hash":"a49a0064b55cf6d8f2a61abfecd41f0083757e04","modified":1628164697285},{"_id":"themes/fluid/layout/_partial/plugins/mermaid.ejs","hash":"fd1f78287c868ccab78b6244b66e3f9b0968c4a8","modified":1628164697285},{"_id":"themes/fluid/layout/_partial/plugins/nprogress.ejs","hash":"47c1df255aa552ad71ef3e57deca46530a8f2802","modified":1628164697286},{"_id":"themes/fluid/layout/_partial/plugins/typed.ejs","hash":"c57817ceaee868d416558e56d2a8d0d418c64a2d","modified":1628164697286},{"_id":"themes/fluid/scripts/events/lib/compatible-configs.js","hash":"c0da20f9adca2761d370cc6dda013ec1ecbb7710","modified":1628164697290},{"_id":"themes/fluid/scripts/events/lib/footnote.js","hash":"13d8466cd4c98367131b5f3d6a30b3d4ce8de26f","modified":1628164697290},{"_id":"themes/fluid/scripts/events/lib/hello.js","hash":"1a262c15896663dba773a1796f637f6484f3e524","modified":1628164697290},{"_id":"themes/fluid/scripts/events/lib/highlight.js","hash":"5eec946182fd537a4d75f15bdf7a09453cc00d83","modified":1628164697290},{"_id":"themes/fluid/scripts/events/lib/lazyload.js","hash":"00a4876e9c37b77fed619138b8bd9ad88ea1e9f3","modified":1628164697291},{"_id":"themes/fluid/scripts/events/lib/merge-configs.js","hash":"3f2dba4959b27466521de97eff692815650c02b7","modified":1628164697291},{"_id":"themes/fluid/source/css/_functions/base.styl","hash":"171697018fd384fce0834875ca94b91f16564cac","modified":1628164697295},{"_id":"themes/fluid/source/css/_mixins/base.styl","hash":"046979dbd8cdabd21d89f9c1d8f1bb3f2fd06d6f","modified":1628164697295},{"_id":"themes/fluid/source/css/_pages/pages.styl","hash":"92c062cf55457b6549497244d09ec34e9c0c95c2","modified":1628164697302},{"_id":"themes/fluid/source/css/_variables/base.styl","hash":"d555a4c9df7b49250c1747c2fbd8353f2d822775","modified":1628164697303},{"_id":"themes/fluid/source/lib/hint/hint.min.css","hash":"64fa8c328dc93432ec822de2818aef21a4f63b29","modified":1628164697307},{"_id":"themes/fluid/source/css/_pages/_about/about.styl","hash":"47235d222812e2f829e9bde039fa719bbced9325","modified":1628164697296},{"_id":"themes/fluid/source/css/_pages/_archive/archive.styl","hash":"86926a80bf6f39a7f47789b1a8f44b5984b4683f","modified":1628164697296},{"_id":"themes/fluid/source/css/_pages/_base/base.styl","hash":"33d237014f22324a034ae463857ce2af72a0d65e","modified":1628164697298},{"_id":"themes/fluid/source/css/_pages/_base/color-schema.styl","hash":"2dd6f1a8470f5bd10ed53cfcba6811197c79d487","modified":1628164697298},{"_id":"themes/fluid/source/css/_pages/_base/inline.styl","hash":"6f2a3b8af2793dd831f661c6db0ccbe0a62ccc48","modified":1628164697299},{"_id":"themes/fluid/source/css/_pages/_base/keyframes.styl","hash":"58a7f8f2baea2d58cf5f7edfc91314ee5d7156ca","modified":1628164697299},{"_id":"themes/fluid/source/css/_pages/_base/rewrite.styl","hash":"c628894ec5afab5b3e6f4633390f2b403bf6678f","modified":1628164697299},{"_id":"themes/fluid/source/css/_pages/_category/categories.styl","hash":"0924e35eff2ec84e2d9e4772abccda452d9463ef","modified":1628164697299},{"_id":"themes/fluid/source/css/_pages/_index/index.styl","hash":"5775fd234c62a2f3520b34b2a66fe181cc2d4ea3","modified":1628164697300},{"_id":"themes/fluid/source/css/_pages/_links/links.styl","hash":"83694b28209c548ef38bee78e473b02e90cbcf9f","modified":1628164697300},{"_id":"themes/fluid/source/css/_pages/_post/post.styl","hash":"c189a52dbc6eb554d1da3f2636920813b3b7e4fb","modified":1628164697301},{"_id":"themes/fluid/source/css/_pages/_post/tag_plugin.styl","hash":"88939a09d1ab73a2b96a6b8b08c96ad03d402728","modified":1628164697301},{"_id":"themes/fluid/source/css/_pages/_tag/tags.styl","hash":"29e9b72cfda2f2baf9cf2597fcd7f9e66303a9bd","modified":1628164697301},{"_id":"themes/fluid/source/css/_pages/_base/_widget/banner.styl","hash":"da823846f0896f16b21c7430f047f7222a89cd10","modified":1628164697296},{"_id":"themes/fluid/source/css/_pages/_base/_widget/board.styl","hash":"bb9cdde191b9b1287ba19414bab862f30be6a8a0","modified":1628164697297},{"_id":"themes/fluid/source/css/_pages/_base/_widget/copy-btn.styl","hash":"c398892fba1494dd6fd417415076458ed321d34d","modified":1628164697297},{"_id":"themes/fluid/source/css/_pages/_base/_widget/footer.styl","hash":"dbd0a3518e5bfca92851490b34654f46bb5cfc76","modified":1628164697297},{"_id":"themes/fluid/source/css/_pages/_base/_widget/footnote.styl","hash":"41935973a66c14ab2bea0539d4b1f15c62534fa4","modified":1628164697297},{"_id":"themes/fluid/source/css/_pages/_base/_widget/header.styl","hash":"f770c5c3ee89421e9e3f1313ca5bd07a2448f400","modified":1628164697297},{"_id":"themes/fluid/source/css/_pages/_base/_widget/qrcode.styl","hash":"d29064ed8bdf62d5cf4eac32ebdb5d0c7075ebbd","modified":1628164697298},{"_id":"themes/fluid/source/css/_pages/_base/_widget/search.styl","hash":"1f4e678d7219815ab62de1b92ec75e021247f90b","modified":1628164697298},{"_id":"themes/fluid/source/css/_pages/_base/_widget/scroll-btn.styl","hash":"e568f308df26465e0432197e8b57384707470f54","modified":1628164697298},{"_id":"themes/fluid/source/img/meicon.png","hash":"9232364c346db7d635804d69e1e2d5ecda6007f3","modified":1628215074715},{"_id":"themes/fluid/source/img/meiconbali.jpg","hash":"251240f4833515e6df48cdec4b17f4c0313c0784","modified":1628232992878},{"_id":"public/search.xml","hash":"f3ecdf00a544aa2db2719eeb5ef471d6e41bd97e","modified":1628500068991},{"_id":"public/local-search.xml","hash":"66d06c03d24f72ac57dbfee60254327ad8d7fa64","modified":1628500068991},{"_id":"public/404/index.html","hash":"88a01be0af7d8982f668143ea03f7e41d11b273d","modified":1628500068991},{"_id":"public/about/index.html","hash":"7e75ad660ee90bead83f137e2c71ed51d2935510","modified":1628500068991},{"_id":"public/categories/index.html","hash":"6875c1d69abf699c1153c2de4723f2eb0ddfa392","modified":1628500068991},{"_id":"public/contact/index.html","hash":"f63326fa253e07ad144357743d37566a7b15f92f","modified":1628500068991},{"_id":"public/friends/index.html","hash":"94e0cde45454b742e63f813b8cab8d39b3ec6899","modified":1628500068991},{"_id":"public/tags/index.html","hash":"6b23b2021d192e40d7815e7417e5873bbc04e32b","modified":1628500068991},{"_id":"public/archives/index.html","hash":"b5c0b618e3a014d6fed8e6689c2d74654a3dd4f6","modified":1628500068991},{"_id":"public/archives/2021/index.html","hash":"b5c0b618e3a014d6fed8e6689c2d74654a3dd4f6","modified":1628500068991},{"_id":"public/archives/2021/08/index.html","hash":"b5c0b618e3a014d6fed8e6689c2d74654a3dd4f6","modified":1628500068991},{"_id":"public/categories/math/index.html","hash":"39b72ec078486c929904000a3b054e44243c46af","modified":1628500068991},{"_id":"public/categories/git/index.html","hash":"1ffd842bec396191990e852fe6c382cb2d84cfc9","modified":1628500068991},{"_id":"public/categories/math/线性代数/index.html","hash":"3c54afcd8dad3c4332f9d10814a70a30df885fdf","modified":1628500068991},{"_id":"public/categories/配置/index.html","hash":"65bf6eeba04af7f05bc4047447e77ba634e8207e","modified":1628500068991},{"_id":"public/categories/math/概率论/index.html","hash":"718d67f89cb9bb030e08b0ae32a3daa6fdac4b21","modified":1628500068991},{"_id":"public/categories/配置/hexo/index.html","hash":"a02b68c122d9fb58671526dd43562f6a4055e786","modified":1628500068991},{"_id":"public/tags/math/index.html","hash":"6ff6244d43f234ccd7156c52d867fcbfbffe8811","modified":1628500068991},{"_id":"public/tags/线性代数/index.html","hash":"98758ca44a8f3f2d7aae4b0682b2903439a9b726","modified":1628500068991},{"_id":"public/tags/马氏距离/index.html","hash":"3eddf984e2d4b88729dddcd3c5227eae9acb9a84","modified":1628500068991},{"_id":"public/tags/概率论/index.html","hash":"5fd67864734c0bdf21e8920ff90e30adec46b9c2","modified":1628500068991},{"_id":"public/tags/git/index.html","hash":"22b5ce22f83bfc01060ae18630739147fd97208e","modified":1628500068991},{"_id":"public/tags/hexo/index.html","hash":"c2fe3f991d6954f1de950e620925c5aa58757272","modified":1628500068991},{"_id":"public/404.html","hash":"a07264e818b65c0e757b3f8d9afac6528c3d3602","modified":1628500068991},{"_id":"public/tags/fluid/index.html","hash":"42d275cba2c8742d655c6f674a620341df65d855","modified":1628500068991},{"_id":"public/tags/配置/index.html","hash":"12ebf36ea727fbf9189a6cc5babb02b3cf1ef5af","modified":1628500068991},{"_id":"public/links/index.html","hash":"5e8ea5e3c8b0ce55c8e37d5e6d81db62fbb56c83","modified":1628500068991},{"_id":"public/2021/08/09/Mahalanobis-distance/index.html","hash":"9a76b993dd08dfae5fd91fe898482cb32f7db6b7","modified":1628500068991},{"_id":"public/2021/08/06/low-rank-app/index.html","hash":"ce63dde0741db4db3975bc52d14b5d723e0b3e25","modified":1628500068991},{"_id":"public/2021/08/09/Eckark-young/index.html","hash":"bcf27962a3559a9b0ec9597b31c591b39c520255","modified":1628500068991},{"_id":"public/2021/08/06/git-submodule/index.html","hash":"3359ee0262423fb3efde29665c6b1256f7efce77","modified":1628500068991},{"_id":"public/2021/08/05/hexo-math-config/index.html","hash":"9d1d646185b9ca4792ab29d720010d30a9b7ec36","modified":1628500068991},{"_id":"public/2021/08/05/covariance-matrix/index.html","hash":"d2d5b15ad21a5b9990c036c246ae5c7db86d093d","modified":1628500068991},{"_id":"public/index.html","hash":"e0d4ca70765fd74fe7b2e3296358f2626fcf5678","modified":1628500068991},{"_id":"public/CNAME","hash":"2e5dd8c5b74841b2b49fab68b7628476b78e9078","modified":1628500068991},{"_id":"public/img/avatar.png","hash":"fe739a158cc128f70f780eb5fa96f388b81d478f","modified":1628500068991},{"_id":"public/img/favicon.png","hash":"fe739a158cc128f70f780eb5fa96f388b81d478f","modified":1628500068991},{"_id":"public/img/default.png","hash":"7bb2b8ee07db305bcadee2985b81b942027ae940","modified":1628500068991},{"_id":"public/img/favicon1.png","hash":"64b215db2cb3af98fe639e94537cb5209f959c78","modified":1628500068991},{"_id":"public/img/loading.gif","hash":"2d2fc0f947940f98c21afafef39ecf226a2e8d55","modified":1628500068991},{"_id":"public/img/police_beian.png","hash":"90efded6baa2dde599a9d6b1387973e8e64923ea","modified":1628500068991},{"_id":"public/xml/local-search.xml","hash":"85fcc23b4db654a7f91fc55b6fb0442bb3ed3a9a","modified":1628500068991},{"_id":"public/live2dw/assets/mtn/00_idle.mtn","hash":"b224c60e463b9f71ddbfc0c720e430496c175f4f","modified":1628500068991},{"_id":"public/live2dw/assets/mtn/01.mtn","hash":"fb550833ae22c9954c3e01df37ed29b2d61700f2","modified":1628500068991},{"_id":"public/live2dw/assets/mtn/02.mtn","hash":"7eafc52edc73b7cb80ae70d34b43c6ac778fa47b","modified":1628500068991},{"_id":"public/live2dw/assets/mtn/03.mtn","hash":"f900737c7a98441cbb2e05255427e6260e19ae68","modified":1628500068991},{"_id":"public/live2dw/assets/mtn/04.mtn","hash":"c7a25d3c5d783639bae18db2f3cd284b819c3c85","modified":1628500068991},{"_id":"public/live2dw/assets/mtn/05.mtn","hash":"dd20ad24b5d1830a5d44b9bccb28f922eea5e0e5","modified":1628500068991},{"_id":"public/live2dw/assets/mtn/06.mtn","hash":"ad404bd852d276cdd3d054c953e23f90e4e45ae1","modified":1628500068991},{"_id":"public/live2dw/assets/mtn/07.mtn","hash":"b7f2e3a9fa4f3ffbb6e64a08f8d9f45ca1868ffb","modified":1628500068991},{"_id":"public/live2dw/assets/mtn/08.mtn","hash":"4411c7651ff65195b113d95e7d5ebef8a59a37d9","modified":1628500068991},{"_id":"public/live2dw/assets/tororo.model.json","hash":"3b96ea33460642d288c98327444966d93a0c11ba","modified":1628500068991},{"_id":"public/live2dw/assets/tororo.pose.json","hash":"81438bf69b32c7c11e311b4fe043730cdc7b7ec2","modified":1628500068991},{"_id":"public/live2dw/lib/L2Dwidget.min.js","hash":"5f1a807437cc723bcadc3791d37add5ceed566a2","modified":1628500068991},{"_id":"public/img/meicon.png","hash":"9232364c346db7d635804d69e1e2d5ecda6007f3","modified":1628500068991},{"_id":"public/live2dw/lib/L2Dwidget.min.js.map","hash":"3290fe2df45f065b51a1cd7b24ec325cbf9bb5ce","modified":1628500068991},{"_id":"public/live2dw/lib/L2Dwidget.0.min.js","hash":"35bb5b588b6de25c9be2dd51d3fd331feafac02d","modified":1628500068991},{"_id":"public/css/gitalk.css","hash":"a57b3cc8e04a0a4a27aefa07facf5b5e7bca0e76","modified":1628500068991},{"_id":"public/js/boot.js","hash":"3de344ee619da989f6dccf7c2ae459fe91075983","modified":1628500068991},{"_id":"public/js/color-schema.js","hash":"cc712fc71bf33d561e1ba74fe1d52d2353092171","modified":1628500068991},{"_id":"public/js/img-lazyload.js","hash":"cbdeca434ec4da51f488c821d51b4d23c73294af","modified":1628500068991},{"_id":"public/js/events.js","hash":"4b9d2676c9544db9cc40a8c7d18456792299ba86","modified":1628500068991},{"_id":"public/js/leancloud.js","hash":"b7985ac3cff9ee2722db43ee6b32b5484c43f5f2","modified":1628500068991},{"_id":"public/js/local-search.js","hash":"bf00f5786bb8de7241f635455b67243d26656222","modified":1628500068991},{"_id":"public/js/plugins.js","hash":"342b1fbc30d1465687ce389a4e07f967266d5d86","modified":1628500068991},{"_id":"public/js/utils.js","hash":"9d492fab9c26311ad0ab553c890e09b9575a76f2","modified":1628500068991},{"_id":"public/lib/hint/hint.min.css","hash":"b38df228460ebfb4c0b6085336ee2878fe85aafe","modified":1628500068991},{"_id":"public/css/main.css","hash":"bf7b61acb0f60f43cf343fed01575b3ce40b2138","modified":1628500068991},{"_id":"public/img/meiconbali.jpg","hash":"251240f4833515e6df48cdec4b17f4c0313c0784","modified":1628500068991},{"_id":"public/live2dw/assets/moc/tororo.moc","hash":"44289e62545a7046e0f5231103a851750b78524e","modified":1628500068991},{"_id":"public/live2dw/assets/moc/tororo.2048/texture_00.png","hash":"98af764b541083e87fc2f8e85f02d2db38c898cc","modified":1628500068991},{"_id":"public/live2dw/lib/L2Dwidget.0.min.js.map","hash":"35e71cc2a130199efb167b9a06939576602f0d75","modified":1628500068991}],"Category":[{"name":"math","_id":"cks4ew7uf0004xox4dgovc1z3"},{"name":"git","_id":"cks4ew7uo000kxox4012704po"},{"name":"线性代数","parent":"cks4ew7uf0004xox4dgovc1z3","_id":"cks4ew7up000oxox4ghlk9hnu"},{"name":"配置","_id":"cks4ew7up000sxox48nrv081m"},{"name":"概率论","parent":"cks4ew7uf0004xox4dgovc1z3","_id":"cks4ew7ut0011xox4dcuq36sd"},{"name":"hexo","parent":"cks4ew7up000sxox48nrv081m","_id":"cks4ew7uu0017xox48ujy06zd"}],"Data":[{"_id":"friends","data":[{"avatar":"http://image.luokangyuan.com/1_qq_27922023.jpg","name":"码酱","introduction":"我不是大佬，只是在追寻大佬的脚步","url":"http://luokangyuan.com/","title":"前去学习"},{"avatar":"http://image.luokangyuan.com/4027734.jpeg","name":"闪烁之狐","introduction":"编程界大佬，技术牛，人还特别好，不懂的都可以请教大佬","url":"https://blinkfox.github.io/","title":"前去学习"},{"avatar":"http://image.luokangyuan.com/avatar.jpg","name":"ja_rome","introduction":"平凡的脚步也可以走出伟大的行程","url":"https://me.csdn.net/jlh912008548","title":"前去学习"}]}],"Page":[{"title":"404","date":"2021-08-04T07:56:32.000Z","type":"404","layout":"404","description":"Oops～，我崩溃了！找不到你想要的页面 :(","_content":"","source":"404/index.md","raw":"---\ntitle: 404\ndate: 2021-08-04 15:56:32\ntype: \"404\"\nlayout: \"404\"\ndescription: \"Oops～，我崩溃了！找不到你想要的页面 :(\"\n---\n","updated":"2021-08-04T07:57:08.058Z","path":"404/index.html","comments":1,"_id":"cks4ew7ua0000xox4eymqftos","content":"","site":{"data":{"friends":[{"avatar":"http://image.luokangyuan.com/1_qq_27922023.jpg","name":"码酱","introduction":"我不是大佬，只是在追寻大佬的脚步","url":"http://luokangyuan.com/","title":"前去学习"},{"avatar":"http://image.luokangyuan.com/4027734.jpeg","name":"闪烁之狐","introduction":"编程界大佬，技术牛，人还特别好，不懂的都可以请教大佬","url":"https://blinkfox.github.io/","title":"前去学习"},{"avatar":"http://image.luokangyuan.com/avatar.jpg","name":"ja_rome","introduction":"平凡的脚步也可以走出伟大的行程","url":"https://me.csdn.net/jlh912008548","title":"前去学习"}]}},"excerpt":"","more":""},{"title":"小站自述","date":"2021-08-03T11:39:55.000Z","type":"about","layout":"about","_content":"","source":"about/index.md","raw":"---\ntitle: 小站自述\ndate: 2021-08-03 19:39:55\ntype: \"about\"\nlayout: \"about\"\n---\n","updated":"2021-08-04T07:51:34.459Z","path":"about/index.html","comments":1,"_id":"cks4ew7ue0002xox4ceg68s3e","content":"","site":{"data":{"friends":[{"avatar":"http://image.luokangyuan.com/1_qq_27922023.jpg","name":"码酱","introduction":"我不是大佬，只是在追寻大佬的脚步","url":"http://luokangyuan.com/","title":"前去学习"},{"avatar":"http://image.luokangyuan.com/4027734.jpeg","name":"闪烁之狐","introduction":"编程界大佬，技术牛，人还特别好，不懂的都可以请教大佬","url":"https://blinkfox.github.io/","title":"前去学习"},{"avatar":"http://image.luokangyuan.com/avatar.jpg","name":"ja_rome","introduction":"平凡的脚步也可以走出伟大的行程","url":"https://me.csdn.net/jlh912008548","title":"前去学习"}]}},"excerpt":"","more":""},{"title":"文章类别","date":"2021-08-03T11:38:47.000Z","type":"categories","layout":"categories","_content":"","source":"categories/index.md","raw":"---\ntitle: 文章类别\ndate: 2021-08-03 19:38:47\ntype: \"categories\"\nlayout: \"categories\"\n---\n","updated":"2021-08-04T07:51:06.721Z","path":"categories/index.html","comments":1,"_id":"cks4ew7uh0006xox477og65va","content":"","site":{"data":{"friends":[{"avatar":"http://image.luokangyuan.com/1_qq_27922023.jpg","name":"码酱","introduction":"我不是大佬，只是在追寻大佬的脚步","url":"http://luokangyuan.com/","title":"前去学习"},{"avatar":"http://image.luokangyuan.com/4027734.jpeg","name":"闪烁之狐","introduction":"编程界大佬，技术牛，人还特别好，不懂的都可以请教大佬","url":"https://blinkfox.github.io/","title":"前去学习"},{"avatar":"http://image.luokangyuan.com/avatar.jpg","name":"ja_rome","introduction":"平凡的脚步也可以走出伟大的行程","url":"https://me.csdn.net/jlh912008548","title":"前去学习"}]}},"excerpt":"","more":""},{"title":"contact","date":"2021-08-04T07:52:31.000Z","type":"contact","layout":"contact","_content":"","source":"contact/index.md","raw":"---\ntitle: contact\ndate: 2021-08-04 15:52:31\ntype: \"contact\"\nlayout: \"contact\"\n---\n","updated":"2021-08-04T07:53:12.028Z","path":"contact/index.html","comments":1,"_id":"cks4ew7ui0008xox4gfl53rxj","content":"","site":{"data":{"friends":[{"avatar":"http://image.luokangyuan.com/1_qq_27922023.jpg","name":"码酱","introduction":"我不是大佬，只是在追寻大佬的脚步","url":"http://luokangyuan.com/","title":"前去学习"},{"avatar":"http://image.luokangyuan.com/4027734.jpeg","name":"闪烁之狐","introduction":"编程界大佬，技术牛，人还特别好，不懂的都可以请教大佬","url":"https://blinkfox.github.io/","title":"前去学习"},{"avatar":"http://image.luokangyuan.com/avatar.jpg","name":"ja_rome","introduction":"平凡的脚步也可以走出伟大的行程","url":"https://me.csdn.net/jlh912008548","title":"前去学习"}]}},"excerpt":"","more":""},{"title":"friends","date":"2021-08-04T07:59:30.000Z","type":"friends","layout":"friends","_content":"\n","source":"friends/index.md","raw":"---\ntitle: friends\ndate: 2021-08-04 15:59:30\ntype: \"friends\"\nlayout: \"friends\"\n---\n\n","updated":"2021-08-04T07:59:47.355Z","path":"friends/index.html","comments":1,"_id":"cks4ew7uj000axox4ecwtgv94","content":"","site":{"data":{"friends":[{"avatar":"http://image.luokangyuan.com/1_qq_27922023.jpg","name":"码酱","introduction":"我不是大佬，只是在追寻大佬的脚步","url":"http://luokangyuan.com/","title":"前去学习"},{"avatar":"http://image.luokangyuan.com/4027734.jpeg","name":"闪烁之狐","introduction":"编程界大佬，技术牛，人还特别好，不懂的都可以请教大佬","url":"https://blinkfox.github.io/","title":"前去学习"},{"avatar":"http://image.luokangyuan.com/avatar.jpg","name":"ja_rome","introduction":"平凡的脚步也可以走出伟大的行程","url":"https://me.csdn.net/jlh912008548","title":"前去学习"}]}},"excerpt":"","more":""},{"title":"article","date":"2021-08-03T11:33:47.000Z","type":"tags","layout":"tags","_content":"\n","source":"tags/index.md","raw":"---\ntitle: article\ndate: 2021-08-03 19:33:47\ntype: \"tags\"\nlayout: \"tags\"\n---\n\n","updated":"2021-08-03T12:48:36.046Z","path":"tags/index.html","comments":1,"_id":"cks4ew7ul000exox4cddsfcdp","content":"","site":{"data":{"friends":[{"avatar":"http://image.luokangyuan.com/1_qq_27922023.jpg","name":"码酱","introduction":"我不是大佬，只是在追寻大佬的脚步","url":"http://luokangyuan.com/","title":"前去学习"},{"avatar":"http://image.luokangyuan.com/4027734.jpeg","name":"闪烁之狐","introduction":"编程界大佬，技术牛，人还特别好，不懂的都可以请教大佬","url":"https://blinkfox.github.io/","title":"前去学习"},{"avatar":"http://image.luokangyuan.com/avatar.jpg","name":"ja_rome","introduction":"平凡的脚步也可以走出伟大的行程","url":"https://me.csdn.net/jlh912008548","title":"前去学习"}]}},"excerpt":"","more":""}],"Post":[{"title":"Eckark_young定理","date":"2021-08-09T02:57:16.000Z","math":true,"_content":"\n最佳低秩逼近和奇异值的关系(*Eckart*-*Young定理*)\n### 定理\nSuppose a matrix $A\\in \\mathbb{R}^{m\\times n}$has an SVD-decomposition$A=U\\Sigma V^T$. Let $k < r= \\mathsf{rank}(A)$and truncated matrix\n$$\nA_k = \\sum_{i=1}^k \\sigma_i \\mathbf u_i \\mathbf v_i^T,\n$$\nthen, for any matrix B of rank k , the minimal error is achieved with $A_k$:\n\n{% raw %}\n$$\n\\min_{\\mathsf{rank}(B)=k}||A-B||_2 = || A - A_k||_2 = \\sigma_{k+1}.\n$$\n{% endraw %}\n\nThe same holds for Frobenius norm as well\n\n{% raw %}\n$$\n\\min_{\\mathsf{rank}(B)=k}||A-B||_F = || A - A_k||_F = \\sqrt{\\sigma_{k+1}^2 + \\cdots + \\sigma_p^2}.\n$$\n\n{% endraw %}\n\n### 证明 (2-norm case)\n\nSince $U^\\ A_k V = \\mathrm{diag}(\\sigma_1,\\ldots, \\sigma_k,0,\\ldots,0)$ it means that $A_k$ is rank K. Moreover, $U^T (A-A_k) V =  \\mathrm{diag}(0,\\ldots, 0,\\sigma_{k+1},\\ldots, \\sigma_p)$with the largest singular value is $\\sigma_{k+1}$ and thus {% raw %}$||A-A_k||_2 = \\sigma_{k+1}$.{% endraw %}\n\n### 证明 (Frobenius norm case)\n\n> Lemma: If $A,B \\in \\mathbb{R}^{m\\times n}$ , with B having rank K , then $\\sigma_{k+i}(A) \\le \\sigma_i(A-B) \\text{ for all }\\; i.$\n\nTo prove the lemma, first consider the case i=1, we have proved that $\\sigma_{k+1}(A) \\le \\sigma_1(A-B) = ||A-B||_2$in the 2-norm case. Then we do the general case:\n\n{% raw %}\n$$\n\\begin{aligned} \t\\sigma_i(A-B) = & \\sigma_i(A-B) + \\sigma_1(B-B_k)\\qquad\\text{since } B=B_k\\\\ \t=& \\sigma_1(A-B - (A-B)_{i-1}) + \\sigma_1(B-B_k)\\qquad\\\\ \t\\ge & \\sigma_1(A-B - (A-B)_{i-1}+B-B_k)   \\\\ \t=& \\sigma_1(A  - (A-B)_{i-1} -B_k)\\\\ \t\\ge & \\sigma_1(A - A_{k+i-1})\\\\ \t=& \\sigma_{k+i}(A)   \\end{aligned} \n$$\n{% endraw %}\n\n\n\n> https://zhuanlan.zhihu.com/p/361938622\n>\n> https://zhuanlan.zhihu.com/p/75283604\n","source":"_posts/Eckark-young.md","raw":"---\ntitle: Eckark_young定理\ndate: 2021-08-09 10:57:16\ntags: [math,线性代数]\ncategories: [math,线性代数]\nmath: true\n---\n\n最佳低秩逼近和奇异值的关系(*Eckart*-*Young定理*)\n### 定理\nSuppose a matrix $A\\in \\mathbb{R}^{m\\times n}$has an SVD-decomposition$A=U\\Sigma V^T$. Let $k < r= \\mathsf{rank}(A)$and truncated matrix\n$$\nA_k = \\sum_{i=1}^k \\sigma_i \\mathbf u_i \\mathbf v_i^T,\n$$\nthen, for any matrix B of rank k , the minimal error is achieved with $A_k$:\n\n{% raw %}\n$$\n\\min_{\\mathsf{rank}(B)=k}||A-B||_2 = || A - A_k||_2 = \\sigma_{k+1}.\n$$\n{% endraw %}\n\nThe same holds for Frobenius norm as well\n\n{% raw %}\n$$\n\\min_{\\mathsf{rank}(B)=k}||A-B||_F = || A - A_k||_F = \\sqrt{\\sigma_{k+1}^2 + \\cdots + \\sigma_p^2}.\n$$\n\n{% endraw %}\n\n### 证明 (2-norm case)\n\nSince $U^\\ A_k V = \\mathrm{diag}(\\sigma_1,\\ldots, \\sigma_k,0,\\ldots,0)$ it means that $A_k$ is rank K. Moreover, $U^T (A-A_k) V =  \\mathrm{diag}(0,\\ldots, 0,\\sigma_{k+1},\\ldots, \\sigma_p)$with the largest singular value is $\\sigma_{k+1}$ and thus {% raw %}$||A-A_k||_2 = \\sigma_{k+1}$.{% endraw %}\n\n### 证明 (Frobenius norm case)\n\n> Lemma: If $A,B \\in \\mathbb{R}^{m\\times n}$ , with B having rank K , then $\\sigma_{k+i}(A) \\le \\sigma_i(A-B) \\text{ for all }\\; i.$\n\nTo prove the lemma, first consider the case i=1, we have proved that $\\sigma_{k+1}(A) \\le \\sigma_1(A-B) = ||A-B||_2$in the 2-norm case. Then we do the general case:\n\n{% raw %}\n$$\n\\begin{aligned} \t\\sigma_i(A-B) = & \\sigma_i(A-B) + \\sigma_1(B-B_k)\\qquad\\text{since } B=B_k\\\\ \t=& \\sigma_1(A-B - (A-B)_{i-1}) + \\sigma_1(B-B_k)\\qquad\\\\ \t\\ge & \\sigma_1(A-B - (A-B)_{i-1}+B-B_k)   \\\\ \t=& \\sigma_1(A  - (A-B)_{i-1} -B_k)\\\\ \t\\ge & \\sigma_1(A - A_{k+i-1})\\\\ \t=& \\sigma_{k+i}(A)   \\end{aligned} \n$$\n{% endraw %}\n\n\n\n> https://zhuanlan.zhihu.com/p/361938622\n>\n> https://zhuanlan.zhihu.com/p/75283604\n","slug":"Eckark-young","published":1,"updated":"2021-08-09T07:33:43.757Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cks4ew7uc0001xox471tr05m8","content":"<p>最佳低秩逼近和奇异值的关系(<em>Eckart</em>-<em>Young定理</em>)</p>\n<h3 id=\"定理\"><a href=\"#定理\" class=\"headerlink\" title=\"定理\"></a>定理</h3><p>Suppose a matrix $A\\in \\mathbb{R}^{m\\times n}$has an SVD-decomposition$A=U\\Sigma V^T$. Let $k &lt; r= \\mathsf{rank}(A)$and truncated matrix<br>$$<br>A_k = \\sum_{i=1}^k \\sigma_i \\mathbf u_i \\mathbf v_i^T,<br>$$<br>then, for any matrix B of rank k , the minimal error is achieved with $A_k$:</p>\n\n$$\n\\min_{\\mathsf{rank}(B)=k}||A-B||_2 = || A - A_k||_2 = \\sigma_{k+1}.\n$$\n\n\n<p>The same holds for Frobenius norm as well</p>\n\n$$\n\\min_{\\mathsf{rank}(B)=k}||A-B||_F = || A - A_k||_F = \\sqrt{\\sigma_{k+1}^2 + \\cdots + \\sigma_p^2}.\n$$\n\n\n\n<h3 id=\"证明-2-norm-case\"><a href=\"#证明-2-norm-case\" class=\"headerlink\" title=\"证明 (2-norm case)\"></a>证明 (2-norm case)</h3><p>Since $U^\\ A_k V = \\mathrm{diag}(\\sigma_1,\\ldots, \\sigma_k,0,\\ldots,0)$ it means that $A_k$ is rank K. Moreover, $U^T (A-A_k) V =  \\mathrm{diag}(0,\\ldots, 0,\\sigma_{k+1},\\ldots, \\sigma_p)$with the largest singular value is $\\sigma_{k+1}$ and thus $||A-A_k||_2 = \\sigma_{k+1}$.</p>\n<h3 id=\"证明-Frobenius-norm-case\"><a href=\"#证明-Frobenius-norm-case\" class=\"headerlink\" title=\"证明 (Frobenius norm case)\"></a>证明 (Frobenius norm case)</h3><blockquote>\n<p>Lemma: If $A,B \\in \\mathbb{R}^{m\\times n}$ , with B having rank K , then $\\sigma_{k+i}(A) \\le \\sigma_i(A-B) \\text{ for all }; i.$</p>\n</blockquote>\n<p>To prove the lemma, first consider the case i=1, we have proved that $\\sigma_{k+1}(A) \\le \\sigma_1(A-B) = ||A-B||_2$in the 2-norm case. Then we do the general case:</p>\n\n$$\n\\begin{aligned} \t\\sigma_i(A-B) = &amp; \\sigma_i(A-B) + \\sigma_1(B-B_k)\\qquad\\text{since } B=B_k\\\\ \t=&amp; \\sigma_1(A-B - (A-B)_{i-1}) + \\sigma_1(B-B_k)\\qquad\\\\ \t\\ge &amp; \\sigma_1(A-B - (A-B)_{i-1}+B-B_k)   \\\\ \t=&amp; \\sigma_1(A  - (A-B)_{i-1} -B_k)\\\\ \t\\ge &amp; \\sigma_1(A - A_{k+i-1})\\\\ \t=&amp; \\sigma_{k+i}(A)   \\end{aligned} \n$$\n\n\n\n\n<blockquote>\n<p><a href=\"https://zhuanlan.zhihu.com/p/361938622\">https://zhuanlan.zhihu.com/p/361938622</a></p>\n<p><a href=\"https://zhuanlan.zhihu.com/p/75283604\">https://zhuanlan.zhihu.com/p/75283604</a></p>\n</blockquote>\n","site":{"data":{"friends":[{"avatar":"http://image.luokangyuan.com/1_qq_27922023.jpg","name":"码酱","introduction":"我不是大佬，只是在追寻大佬的脚步","url":"http://luokangyuan.com/","title":"前去学习"},{"avatar":"http://image.luokangyuan.com/4027734.jpeg","name":"闪烁之狐","introduction":"编程界大佬，技术牛，人还特别好，不懂的都可以请教大佬","url":"https://blinkfox.github.io/","title":"前去学习"},{"avatar":"http://image.luokangyuan.com/avatar.jpg","name":"ja_rome","introduction":"平凡的脚步也可以走出伟大的行程","url":"https://me.csdn.net/jlh912008548","title":"前去学习"}]}},"excerpt":"","more":"<p>最佳低秩逼近和奇异值的关系(<em>Eckart</em>-<em>Young定理</em>)</p>\n<h3 id=\"定理\"><a href=\"#定理\" class=\"headerlink\" title=\"定理\"></a>定理</h3><p>Suppose a matrix $A\\in \\mathbb{R}^{m\\times n}$has an SVD-decomposition$A=U\\Sigma V^T$. Let $k &lt; r= \\mathsf{rank}(A)$and truncated matrix<br>$$<br>A_k = \\sum_{i=1}^k \\sigma_i \\mathbf u_i \\mathbf v_i^T,<br>$$<br>then, for any matrix B of rank k , the minimal error is achieved with $A_k$:</p>\n\n$$\n\\min_{\\mathsf{rank}(B)=k}||A-B||_2 = || A - A_k||_2 = \\sigma_{k+1}.\n$$\n\n\n<p>The same holds for Frobenius norm as well</p>\n\n$$\n\\min_{\\mathsf{rank}(B)=k}||A-B||_F = || A - A_k||_F = \\sqrt{\\sigma_{k+1}^2 + \\cdots + \\sigma_p^2}.\n$$\n\n\n\n<h3 id=\"证明-2-norm-case\"><a href=\"#证明-2-norm-case\" class=\"headerlink\" title=\"证明 (2-norm case)\"></a>证明 (2-norm case)</h3><p>Since $U^\\ A_k V = \\mathrm{diag}(\\sigma_1,\\ldots, \\sigma_k,0,\\ldots,0)$ it means that $A_k$ is rank K. Moreover, $U^T (A-A_k) V =  \\mathrm{diag}(0,\\ldots, 0,\\sigma_{k+1},\\ldots, \\sigma_p)$with the largest singular value is $\\sigma_{k+1}$ and thus $||A-A_k||_2 = \\sigma_{k+1}$.</p>\n<h3 id=\"证明-Frobenius-norm-case\"><a href=\"#证明-Frobenius-norm-case\" class=\"headerlink\" title=\"证明 (Frobenius norm case)\"></a>证明 (Frobenius norm case)</h3><blockquote>\n<p>Lemma: If $A,B \\in \\mathbb{R}^{m\\times n}$ , with B having rank K , then $\\sigma_{k+i}(A) \\le \\sigma_i(A-B) \\text{ for all }; i.$</p>\n</blockquote>\n<p>To prove the lemma, first consider the case i=1, we have proved that $\\sigma_{k+1}(A) \\le \\sigma_1(A-B) = ||A-B||_2$in the 2-norm case. Then we do the general case:</p>\n\n$$\n\\begin{aligned} \t\\sigma_i(A-B) = & \\sigma_i(A-B) + \\sigma_1(B-B_k)\\qquad\\text{since } B=B_k\\\\ \t=& \\sigma_1(A-B - (A-B)_{i-1}) + \\sigma_1(B-B_k)\\qquad\\\\ \t\\ge & \\sigma_1(A-B - (A-B)_{i-1}+B-B_k)   \\\\ \t=& \\sigma_1(A  - (A-B)_{i-1} -B_k)\\\\ \t\\ge & \\sigma_1(A - A_{k+i-1})\\\\ \t=& \\sigma_{k+i}(A)   \\end{aligned} \n$$\n\n\n\n\n<blockquote>\n<p><a href=\"https://zhuanlan.zhihu.com/p/361938622\">https://zhuanlan.zhihu.com/p/361938622</a></p>\n<p><a href=\"https://zhuanlan.zhihu.com/p/75283604\">https://zhuanlan.zhihu.com/p/75283604</a></p>\n</blockquote>\n"},{"title":"Mahalanobis_distance","date":"2021-08-09T06:58:56.000Z","math":true,"_content":"\n> 马氏距离(Mahalanobis Distance)是度量学习中一种常用的距离指标，同欧氏距离、曼哈顿距离、汉明距离等一样被用作评定数据之间的相似度指标。但却可以应对高维线性分布的数据中各维度间非独立同分布的问题。\n\n*使用马氏距离，对高维非独立分布的数据进行距离度量。*\n\n**那我们为什么要用马氏距离呢？**\n马氏距离有很多**优点：** **马氏距离不受量纲的影响**，两点之间的马氏距离与原始数据的测量单位无关；由标准化数据和中心化数据(即原始数据与均值之差）计算出的二点之间的马氏距离相同。**马氏距离还可以排除变量之间的相关性的干扰**。\n\n## 什么是马氏距离\n\n马氏距离(Mahalanobis Distance)是一种距离的度量，可以看作是欧氏距离的一种修正，修正了欧式距离中各个维度尺度不一致且相关的问题。\n\n单个数据点的马氏距离\n\n![](https://pic4.zhimg.com/80/v2-d2987369d8167a362482d6cbecefb8bb_720w.jpg)\n\n\n\n数据点x, y之间的马氏距离\n\n\n\n![](https://pic3.zhimg.com/80/v2-d54956df14c05568f8c0c0548ac16416_720w.jpg)\n\n\n\n*其中Σ是多维随机变量的协方差矩阵，μ为样本均值，如果协方差矩阵是单位向量，也就是各维度独立同分布，马氏距离就变成了欧氏距离。*\n\n## 马氏距离实际意义\n\n那么马氏距离就能能干什么？它比欧氏距离好在哪里？举几个栗子\n\n**欧式距离近就一定相似？**\n\n先举个比较常用的例子，身高和体重，这两个变量拥有不同的单位标准，也就是有不同的scale。比如身高用毫米计算，而体重用千克计算，显然差10mm的身高与差10kg的体重是完全不同的。但在普通的欧氏距离中，这将会算作相同的差距。\n\n**归一化后欧氏距离近就一定相似？**\n\n当然我们可以先做归一化来消除这种维度间scale不同的问题，但是样本分布也会影响分类\n\n举个一维的栗子，现在有两个类别，统一单位，第一个类别均值为0，方差为0.1，第二个类别均值为5，方差为5。那么一个值为2的点属于第一类的概率大还是第二类的概率大？距离上说应该是第一类，但是直觉上显然是第二类，因为第一类不太可能到达2这个位置。\n\n所以，在一个方差较小的维度下很小的差别就有可能成为离群点。就像下图一样，A与B相对于原点的距离是相同的。但是由于样本总体沿着横轴分布，所以B点更有可能是这个样本中的点，而A则更有可能是离群点。\n\n![](https://pic4.zhimg.com/80/v2-6f5d1b59fd1687cfeecd0c6991c6db77_720w.jpg)\n\n\n\n**算上维度的方差就够了？**\n\n还有一个问题——如果维度间不独立同分布，样本点一定与欧氏距离近的样本点同类的概率更大吗？\n\n\n\n![](https://pic3.zhimg.com/80/v2-3cee35b79d272dda86e2604c160934ee_720w.jpg)\n\n\n\n可以看到样本基本服从f(x) = x的线性分布，A与B相对于原点的距离依旧相等，显然A更像是一个离群点\n\n即使数据已经经过了标准化，也不会改变AB与原点间距离大小的相互关系。所以要本质上解决这个问题，就要针对[主成分分析](https://link.zhihu.com/?target=https%3A//www.ph0en1x.space/2018/03/06/PCA/)中的`主成分`来进行标准化。\n\n## 马氏距离的几何意义\n\n上面搞懂了，马氏距离就好理解了，<u>只需要将变量`按照主成分进行旋转`，让维度间相互**独立**，然后进行`标准化`</u>，让维度**同分布**就可以了。\n\n由主成分分析可知，由于主成分就是特征向量方向，每个方向的方差就是对应的特征值，所以只需要按照特征向量的方向旋转，然后缩放特征值倍就可以了，可以得到以下的结果：\n\n\n\n![](https://pic3.zhimg.com/80/v2-068306ff7e62b7af24b126eafe0b8bc6_720w.jpg)\n\n\n\n离群点就被成功分离，这时候的欧式距离就是马氏距离。\n\n## 马氏距离的推导\n\n首先要对数据点进行*旋转*，旋转至主成分，维度间线性无关，假设新的坐标为\n\n![](https://pic2.zhimg.com/80/v2-e924839926a256cb277a8cfc850d5a89_720w.jpg)\n\n\n\n又变换后*维度间线性无关且每个维度自己的方差为特征值*，所以满足：\n\n\n\n![](https://pic1.zhimg.com/80/v2-24ace781a1f0b2cc64ea359b1bb78d74_720w.jpg)\n\n\n\n马氏距离是旋转变换缩放之后的欧式距离，所以马氏距离的计算公式为：\n\n![](https://pic3.zhimg.com/80/v2-4435a733478fafe47ee0198e315e67f6_720w.jpg)\n\n这就是之前提到的马氏距离的公式\n\n## 马氏距离的问题\n\n- 协方差矩阵必须满秩\n\n里面有求逆矩阵的过程，不满秩不行，要求数据要有原维度个特征值，如果没有可以考虑先进行PCA，这种情况下PCA不会损失信息\n\n- 不能处理非线性流形(manifold)上的问题\n\n只对线性空间有效，如果要处理流形，只能在局部定义，可以用来建立KNN图\n\n> 参考：\n>\n> https://zhuanlan.zhihu.com/p/46626607\n","source":"_posts/Mahalanobis-distance.md","raw":"---\ntitle: Mahalanobis_distance\ndate: 2021-08-09 14:58:56\ntags: 马氏距离\ncategories: [math,概率论]\nmath: true\n---\n\n> 马氏距离(Mahalanobis Distance)是度量学习中一种常用的距离指标，同欧氏距离、曼哈顿距离、汉明距离等一样被用作评定数据之间的相似度指标。但却可以应对高维线性分布的数据中各维度间非独立同分布的问题。\n\n*使用马氏距离，对高维非独立分布的数据进行距离度量。*\n\n**那我们为什么要用马氏距离呢？**\n马氏距离有很多**优点：** **马氏距离不受量纲的影响**，两点之间的马氏距离与原始数据的测量单位无关；由标准化数据和中心化数据(即原始数据与均值之差）计算出的二点之间的马氏距离相同。**马氏距离还可以排除变量之间的相关性的干扰**。\n\n## 什么是马氏距离\n\n马氏距离(Mahalanobis Distance)是一种距离的度量，可以看作是欧氏距离的一种修正，修正了欧式距离中各个维度尺度不一致且相关的问题。\n\n单个数据点的马氏距离\n\n![](https://pic4.zhimg.com/80/v2-d2987369d8167a362482d6cbecefb8bb_720w.jpg)\n\n\n\n数据点x, y之间的马氏距离\n\n\n\n![](https://pic3.zhimg.com/80/v2-d54956df14c05568f8c0c0548ac16416_720w.jpg)\n\n\n\n*其中Σ是多维随机变量的协方差矩阵，μ为样本均值，如果协方差矩阵是单位向量，也就是各维度独立同分布，马氏距离就变成了欧氏距离。*\n\n## 马氏距离实际意义\n\n那么马氏距离就能能干什么？它比欧氏距离好在哪里？举几个栗子\n\n**欧式距离近就一定相似？**\n\n先举个比较常用的例子，身高和体重，这两个变量拥有不同的单位标准，也就是有不同的scale。比如身高用毫米计算，而体重用千克计算，显然差10mm的身高与差10kg的体重是完全不同的。但在普通的欧氏距离中，这将会算作相同的差距。\n\n**归一化后欧氏距离近就一定相似？**\n\n当然我们可以先做归一化来消除这种维度间scale不同的问题，但是样本分布也会影响分类\n\n举个一维的栗子，现在有两个类别，统一单位，第一个类别均值为0，方差为0.1，第二个类别均值为5，方差为5。那么一个值为2的点属于第一类的概率大还是第二类的概率大？距离上说应该是第一类，但是直觉上显然是第二类，因为第一类不太可能到达2这个位置。\n\n所以，在一个方差较小的维度下很小的差别就有可能成为离群点。就像下图一样，A与B相对于原点的距离是相同的。但是由于样本总体沿着横轴分布，所以B点更有可能是这个样本中的点，而A则更有可能是离群点。\n\n![](https://pic4.zhimg.com/80/v2-6f5d1b59fd1687cfeecd0c6991c6db77_720w.jpg)\n\n\n\n**算上维度的方差就够了？**\n\n还有一个问题——如果维度间不独立同分布，样本点一定与欧氏距离近的样本点同类的概率更大吗？\n\n\n\n![](https://pic3.zhimg.com/80/v2-3cee35b79d272dda86e2604c160934ee_720w.jpg)\n\n\n\n可以看到样本基本服从f(x) = x的线性分布，A与B相对于原点的距离依旧相等，显然A更像是一个离群点\n\n即使数据已经经过了标准化，也不会改变AB与原点间距离大小的相互关系。所以要本质上解决这个问题，就要针对[主成分分析](https://link.zhihu.com/?target=https%3A//www.ph0en1x.space/2018/03/06/PCA/)中的`主成分`来进行标准化。\n\n## 马氏距离的几何意义\n\n上面搞懂了，马氏距离就好理解了，<u>只需要将变量`按照主成分进行旋转`，让维度间相互**独立**，然后进行`标准化`</u>，让维度**同分布**就可以了。\n\n由主成分分析可知，由于主成分就是特征向量方向，每个方向的方差就是对应的特征值，所以只需要按照特征向量的方向旋转，然后缩放特征值倍就可以了，可以得到以下的结果：\n\n\n\n![](https://pic3.zhimg.com/80/v2-068306ff7e62b7af24b126eafe0b8bc6_720w.jpg)\n\n\n\n离群点就被成功分离，这时候的欧式距离就是马氏距离。\n\n## 马氏距离的推导\n\n首先要对数据点进行*旋转*，旋转至主成分，维度间线性无关，假设新的坐标为\n\n![](https://pic2.zhimg.com/80/v2-e924839926a256cb277a8cfc850d5a89_720w.jpg)\n\n\n\n又变换后*维度间线性无关且每个维度自己的方差为特征值*，所以满足：\n\n\n\n![](https://pic1.zhimg.com/80/v2-24ace781a1f0b2cc64ea359b1bb78d74_720w.jpg)\n\n\n\n马氏距离是旋转变换缩放之后的欧式距离，所以马氏距离的计算公式为：\n\n![](https://pic3.zhimg.com/80/v2-4435a733478fafe47ee0198e315e67f6_720w.jpg)\n\n这就是之前提到的马氏距离的公式\n\n## 马氏距离的问题\n\n- 协方差矩阵必须满秩\n\n里面有求逆矩阵的过程，不满秩不行，要求数据要有原维度个特征值，如果没有可以考虑先进行PCA，这种情况下PCA不会损失信息\n\n- 不能处理非线性流形(manifold)上的问题\n\n只对线性空间有效，如果要处理流形，只能在局部定义，可以用来建立KNN图\n\n> 参考：\n>\n> https://zhuanlan.zhihu.com/p/46626607\n","slug":"Mahalanobis-distance","published":1,"updated":"2021-08-09T07:17:40.081Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cks4ew7ue0003xox4hhai8gxn","content":"<blockquote>\n<p>马氏距离(Mahalanobis Distance)是度量学习中一种常用的距离指标，同欧氏距离、曼哈顿距离、汉明距离等一样被用作评定数据之间的相似度指标。但却可以应对高维线性分布的数据中各维度间非独立同分布的问题。</p>\n</blockquote>\n<p><em>使用马氏距离，对高维非独立分布的数据进行距离度量。</em></p>\n<p><strong>那我们为什么要用马氏距离呢？</strong><br>马氏距离有很多<strong>优点：</strong> <strong>马氏距离不受量纲的影响</strong>，两点之间的马氏距离与原始数据的测量单位无关；由标准化数据和中心化数据(即原始数据与均值之差）计算出的二点之间的马氏距离相同。<strong>马氏距离还可以排除变量之间的相关性的干扰</strong>。</p>\n<h2 id=\"什么是马氏距离\"><a href=\"#什么是马氏距离\" class=\"headerlink\" title=\"什么是马氏距离\"></a>什么是马氏距离</h2><p>马氏距离(Mahalanobis Distance)是一种距离的度量，可以看作是欧氏距离的一种修正，修正了欧式距离中各个维度尺度不一致且相关的问题。</p>\n<p>单个数据点的马氏距离</p>\n<p><img src=\"https://pic4.zhimg.com/80/v2-d2987369d8167a362482d6cbecefb8bb_720w.jpg\"></p>\n<p>数据点x, y之间的马氏距离</p>\n<p><img src=\"https://pic3.zhimg.com/80/v2-d54956df14c05568f8c0c0548ac16416_720w.jpg\"></p>\n<p><em>其中Σ是多维随机变量的协方差矩阵，μ为样本均值，如果协方差矩阵是单位向量，也就是各维度独立同分布，马氏距离就变成了欧氏距离。</em></p>\n<h2 id=\"马氏距离实际意义\"><a href=\"#马氏距离实际意义\" class=\"headerlink\" title=\"马氏距离实际意义\"></a>马氏距离实际意义</h2><p>那么马氏距离就能能干什么？它比欧氏距离好在哪里？举几个栗子</p>\n<p><strong>欧式距离近就一定相似？</strong></p>\n<p>先举个比较常用的例子，身高和体重，这两个变量拥有不同的单位标准，也就是有不同的scale。比如身高用毫米计算，而体重用千克计算，显然差10mm的身高与差10kg的体重是完全不同的。但在普通的欧氏距离中，这将会算作相同的差距。</p>\n<p><strong>归一化后欧氏距离近就一定相似？</strong></p>\n<p>当然我们可以先做归一化来消除这种维度间scale不同的问题，但是样本分布也会影响分类</p>\n<p>举个一维的栗子，现在有两个类别，统一单位，第一个类别均值为0，方差为0.1，第二个类别均值为5，方差为5。那么一个值为2的点属于第一类的概率大还是第二类的概率大？距离上说应该是第一类，但是直觉上显然是第二类，因为第一类不太可能到达2这个位置。</p>\n<p>所以，在一个方差较小的维度下很小的差别就有可能成为离群点。就像下图一样，A与B相对于原点的距离是相同的。但是由于样本总体沿着横轴分布，所以B点更有可能是这个样本中的点，而A则更有可能是离群点。</p>\n<p><img src=\"https://pic4.zhimg.com/80/v2-6f5d1b59fd1687cfeecd0c6991c6db77_720w.jpg\"></p>\n<p><strong>算上维度的方差就够了？</strong></p>\n<p>还有一个问题——如果维度间不独立同分布，样本点一定与欧氏距离近的样本点同类的概率更大吗？</p>\n<p><img src=\"https://pic3.zhimg.com/80/v2-3cee35b79d272dda86e2604c160934ee_720w.jpg\"></p>\n<p>可以看到样本基本服从f(x) = x的线性分布，A与B相对于原点的距离依旧相等，显然A更像是一个离群点</p>\n<p>即使数据已经经过了标准化，也不会改变AB与原点间距离大小的相互关系。所以要本质上解决这个问题，就要针对<a href=\"https://link.zhihu.com/?target=https://www.ph0en1x.space/2018/03/06/PCA/\">主成分分析</a>中的<code>主成分</code>来进行标准化。</p>\n<h2 id=\"马氏距离的几何意义\"><a href=\"#马氏距离的几何意义\" class=\"headerlink\" title=\"马氏距离的几何意义\"></a>马氏距离的几何意义</h2><p>上面搞懂了，马氏距离就好理解了，<u>只需要将变量<code>按照主成分进行旋转</code>，让维度间相互<strong>独立</strong>，然后进行<code>标准化</code></u>，让维度<strong>同分布</strong>就可以了。</p>\n<p>由主成分分析可知，由于主成分就是特征向量方向，每个方向的方差就是对应的特征值，所以只需要按照特征向量的方向旋转，然后缩放特征值倍就可以了，可以得到以下的结果：</p>\n<p><img src=\"https://pic3.zhimg.com/80/v2-068306ff7e62b7af24b126eafe0b8bc6_720w.jpg\"></p>\n<p>离群点就被成功分离，这时候的欧式距离就是马氏距离。</p>\n<h2 id=\"马氏距离的推导\"><a href=\"#马氏距离的推导\" class=\"headerlink\" title=\"马氏距离的推导\"></a>马氏距离的推导</h2><p>首先要对数据点进行<em>旋转</em>，旋转至主成分，维度间线性无关，假设新的坐标为</p>\n<p><img src=\"https://pic2.zhimg.com/80/v2-e924839926a256cb277a8cfc850d5a89_720w.jpg\"></p>\n<p>又变换后<em>维度间线性无关且每个维度自己的方差为特征值</em>，所以满足：</p>\n<p><img src=\"https://pic1.zhimg.com/80/v2-24ace781a1f0b2cc64ea359b1bb78d74_720w.jpg\"></p>\n<p>马氏距离是旋转变换缩放之后的欧式距离，所以马氏距离的计算公式为：</p>\n<p><img src=\"https://pic3.zhimg.com/80/v2-4435a733478fafe47ee0198e315e67f6_720w.jpg\"></p>\n<p>这就是之前提到的马氏距离的公式</p>\n<h2 id=\"马氏距离的问题\"><a href=\"#马氏距离的问题\" class=\"headerlink\" title=\"马氏距离的问题\"></a>马氏距离的问题</h2><ul>\n<li>协方差矩阵必须满秩</li>\n</ul>\n<p>里面有求逆矩阵的过程，不满秩不行，要求数据要有原维度个特征值，如果没有可以考虑先进行PCA，这种情况下PCA不会损失信息</p>\n<ul>\n<li>不能处理非线性流形(manifold)上的问题</li>\n</ul>\n<p>只对线性空间有效，如果要处理流形，只能在局部定义，可以用来建立KNN图</p>\n<blockquote>\n<p>参考：</p>\n<p><a href=\"https://zhuanlan.zhihu.com/p/46626607\">https://zhuanlan.zhihu.com/p/46626607</a></p>\n</blockquote>\n","site":{"data":{"friends":[{"avatar":"http://image.luokangyuan.com/1_qq_27922023.jpg","name":"码酱","introduction":"我不是大佬，只是在追寻大佬的脚步","url":"http://luokangyuan.com/","title":"前去学习"},{"avatar":"http://image.luokangyuan.com/4027734.jpeg","name":"闪烁之狐","introduction":"编程界大佬，技术牛，人还特别好，不懂的都可以请教大佬","url":"https://blinkfox.github.io/","title":"前去学习"},{"avatar":"http://image.luokangyuan.com/avatar.jpg","name":"ja_rome","introduction":"平凡的脚步也可以走出伟大的行程","url":"https://me.csdn.net/jlh912008548","title":"前去学习"}]}},"excerpt":"","more":"<blockquote>\n<p>马氏距离(Mahalanobis Distance)是度量学习中一种常用的距离指标，同欧氏距离、曼哈顿距离、汉明距离等一样被用作评定数据之间的相似度指标。但却可以应对高维线性分布的数据中各维度间非独立同分布的问题。</p>\n</blockquote>\n<p><em>使用马氏距离，对高维非独立分布的数据进行距离度量。</em></p>\n<p><strong>那我们为什么要用马氏距离呢？</strong><br>马氏距离有很多<strong>优点：</strong> <strong>马氏距离不受量纲的影响</strong>，两点之间的马氏距离与原始数据的测量单位无关；由标准化数据和中心化数据(即原始数据与均值之差）计算出的二点之间的马氏距离相同。<strong>马氏距离还可以排除变量之间的相关性的干扰</strong>。</p>\n<h2 id=\"什么是马氏距离\"><a href=\"#什么是马氏距离\" class=\"headerlink\" title=\"什么是马氏距离\"></a>什么是马氏距离</h2><p>马氏距离(Mahalanobis Distance)是一种距离的度量，可以看作是欧氏距离的一种修正，修正了欧式距离中各个维度尺度不一致且相关的问题。</p>\n<p>单个数据点的马氏距离</p>\n<p><img src=\"https://pic4.zhimg.com/80/v2-d2987369d8167a362482d6cbecefb8bb_720w.jpg\"></p>\n<p>数据点x, y之间的马氏距离</p>\n<p><img src=\"https://pic3.zhimg.com/80/v2-d54956df14c05568f8c0c0548ac16416_720w.jpg\"></p>\n<p><em>其中Σ是多维随机变量的协方差矩阵，μ为样本均值，如果协方差矩阵是单位向量，也就是各维度独立同分布，马氏距离就变成了欧氏距离。</em></p>\n<h2 id=\"马氏距离实际意义\"><a href=\"#马氏距离实际意义\" class=\"headerlink\" title=\"马氏距离实际意义\"></a>马氏距离实际意义</h2><p>那么马氏距离就能能干什么？它比欧氏距离好在哪里？举几个栗子</p>\n<p><strong>欧式距离近就一定相似？</strong></p>\n<p>先举个比较常用的例子，身高和体重，这两个变量拥有不同的单位标准，也就是有不同的scale。比如身高用毫米计算，而体重用千克计算，显然差10mm的身高与差10kg的体重是完全不同的。但在普通的欧氏距离中，这将会算作相同的差距。</p>\n<p><strong>归一化后欧氏距离近就一定相似？</strong></p>\n<p>当然我们可以先做归一化来消除这种维度间scale不同的问题，但是样本分布也会影响分类</p>\n<p>举个一维的栗子，现在有两个类别，统一单位，第一个类别均值为0，方差为0.1，第二个类别均值为5，方差为5。那么一个值为2的点属于第一类的概率大还是第二类的概率大？距离上说应该是第一类，但是直觉上显然是第二类，因为第一类不太可能到达2这个位置。</p>\n<p>所以，在一个方差较小的维度下很小的差别就有可能成为离群点。就像下图一样，A与B相对于原点的距离是相同的。但是由于样本总体沿着横轴分布，所以B点更有可能是这个样本中的点，而A则更有可能是离群点。</p>\n<p><img src=\"https://pic4.zhimg.com/80/v2-6f5d1b59fd1687cfeecd0c6991c6db77_720w.jpg\"></p>\n<p><strong>算上维度的方差就够了？</strong></p>\n<p>还有一个问题——如果维度间不独立同分布，样本点一定与欧氏距离近的样本点同类的概率更大吗？</p>\n<p><img src=\"https://pic3.zhimg.com/80/v2-3cee35b79d272dda86e2604c160934ee_720w.jpg\"></p>\n<p>可以看到样本基本服从f(x) = x的线性分布，A与B相对于原点的距离依旧相等，显然A更像是一个离群点</p>\n<p>即使数据已经经过了标准化，也不会改变AB与原点间距离大小的相互关系。所以要本质上解决这个问题，就要针对<a href=\"https://link.zhihu.com/?target=https://www.ph0en1x.space/2018/03/06/PCA/\">主成分分析</a>中的<code>主成分</code>来进行标准化。</p>\n<h2 id=\"马氏距离的几何意义\"><a href=\"#马氏距离的几何意义\" class=\"headerlink\" title=\"马氏距离的几何意义\"></a>马氏距离的几何意义</h2><p>上面搞懂了，马氏距离就好理解了，<u>只需要将变量<code>按照主成分进行旋转</code>，让维度间相互<strong>独立</strong>，然后进行<code>标准化</code></u>，让维度<strong>同分布</strong>就可以了。</p>\n<p>由主成分分析可知，由于主成分就是特征向量方向，每个方向的方差就是对应的特征值，所以只需要按照特征向量的方向旋转，然后缩放特征值倍就可以了，可以得到以下的结果：</p>\n<p><img src=\"https://pic3.zhimg.com/80/v2-068306ff7e62b7af24b126eafe0b8bc6_720w.jpg\"></p>\n<p>离群点就被成功分离，这时候的欧式距离就是马氏距离。</p>\n<h2 id=\"马氏距离的推导\"><a href=\"#马氏距离的推导\" class=\"headerlink\" title=\"马氏距离的推导\"></a>马氏距离的推导</h2><p>首先要对数据点进行<em>旋转</em>，旋转至主成分，维度间线性无关，假设新的坐标为</p>\n<p><img src=\"https://pic2.zhimg.com/80/v2-e924839926a256cb277a8cfc850d5a89_720w.jpg\"></p>\n<p>又变换后<em>维度间线性无关且每个维度自己的方差为特征值</em>，所以满足：</p>\n<p><img src=\"https://pic1.zhimg.com/80/v2-24ace781a1f0b2cc64ea359b1bb78d74_720w.jpg\"></p>\n<p>马氏距离是旋转变换缩放之后的欧式距离，所以马氏距离的计算公式为：</p>\n<p><img src=\"https://pic3.zhimg.com/80/v2-4435a733478fafe47ee0198e315e67f6_720w.jpg\"></p>\n<p>这就是之前提到的马氏距离的公式</p>\n<h2 id=\"马氏距离的问题\"><a href=\"#马氏距离的问题\" class=\"headerlink\" title=\"马氏距离的问题\"></a>马氏距离的问题</h2><ul>\n<li>协方差矩阵必须满秩</li>\n</ul>\n<p>里面有求逆矩阵的过程，不满秩不行，要求数据要有原维度个特征值，如果没有可以考虑先进行PCA，这种情况下PCA不会损失信息</p>\n<ul>\n<li>不能处理非线性流形(manifold)上的问题</li>\n</ul>\n<p>只对线性空间有效，如果要处理流形，只能在局部定义，可以用来建立KNN图</p>\n<blockquote>\n<p>参考：</p>\n<p><a href=\"https://zhuanlan.zhihu.com/p/46626607\">https://zhuanlan.zhihu.com/p/46626607</a></p>\n</blockquote>\n"},{"title":"直观理解协方差矩阵","date":"2021-08-05T03:26:21.000Z","math":true,"_content":"\n> 原文出自 https://zhuanlan.zhihu.com/p/349802953\n\n## 1 概率论中的定义\n\n### 随机变量：\n\n随机变量(Random Variable) X 是一个映射，把随机试验的结果与实数建立起了一一对应的关系。而期望与方差是随机变量的两个重要的数字特征。\n\n### 数学期望：\n\n在概率论和统计学中，数学期望(mean)(或均值，亦简称期望(Expectation, or expected value))是试验中每次可能结果的概率乘以其结果的总和，是最基本的数学特征之一。它反映随机变量平均取值的大小。 期望值是该变量输出值的平均数。期望值并不一定包含于变量的输出值集合里。\n\n大数定律规定，随着重复次数接近无穷大，数值的算术平均值几乎肯定地收敛于期望值。\n\n### 方差：\n\n方差(Variance)是在概率论和统计方差衡量随机变量或一组数据时离散程度的度量。概率论中方差用来度量随机变量和其数学期望(即均值)之间的偏离程度。统计中的方差(样本方差)是每个样本值与全体样本值的平均数之差的平方值的平均数。\n\n设$X$为随机变量， 如果$\\mathrm{E}[X]$，则随机变量$X$的方差为：\n$$\n\\mu=\\mathrm{E}[X]\n$$\n\n方差也记为 $\\sigma_{X}^{2}$。\n\n样本方差计算公式：\n\n$$\nS^{2}=\\Sigma\\left(X-\\overline{X}\\right)^{2}/\\left(n-1\\right)\n$$\n\n其中，$S^{2}$为样本方差，$X$ 为变量，$\\overline{X}$为样本均值，$n$ 为样本例数。如果要了解为什么要除以$n-1$，请看[这篇文章](https://link.zhihu.com/?target=https%3A//www.visiondummy.com/2014/03/divide-variance-n-1/)。\n\n### 标准差：\n\n标准差(Standard Deviation)是离均差平方的算术平均数(即：方差)的算术平方根，用$\\sigma$表示。标准差也被称为标准偏差，或者实验标准差，在概率统计中最常使用作为统计分布程度上的测量依据。 见下图：\n\n![](https://pic1.zhimg.com/80/v2-37e04458baf17d09c914981b5dbae140_720w.jpg)\n\n标准差是方差的算术平方根。标准差能反映一个数据集的离散程度。平均数相同的两组数据，标准差未必相同。\n\n### 协方差：\n\n**协方差(Covariance)在概率论和统计学中用于衡量两个变量的总体误差。而方差是协方差的一种特殊情况，即当两个变量是相同的情况。**\n\n期望值分别为$ E[X]$与$[Y]$的两个实随机变量$X$与$Y$之间的协方差 $\\mathrm{Cov}(X,Y)$ 定义为：\n\n{% raw %}\n$$\n\\begin{aligned}\n\\mathrm{Cov}(X,Y)&=\\mathrm{E}\\left[\\left(X\\mathrm{E}\\left[X\\right]\\right)\\left(Y-\\mathrm{E}\\left[Y\\right]\\right)\\right]  \n\\\\&=\\mathrm{E}\\left[XY\\right]-2\\mathrm{E}\\left[Y\\right]\\mathrm{E}\\left[X\\right]+\\mathrm{E}\\left[X\\right]\\mathrm{E}\\left[Y\\right]\n\\\\&=\\mathrm{E}\\left[XY\\right]-\\mathrm{E}\\left[X\\right]\\mathrm{E}\\left[Y\\right] \n\\\\&=\\mathrm{E}\\left[XY\\right]-\\mathrm{E}\\left[X\\right]\\mathrm{E}\\left[Y\\right]\n\\end{aligned}\n$$\n{% endraw %}\n\n协方差表示的是两个变量总体误差的期望。 如果两个变量的变化趋势一致，也就是说如果其中一个大于自身的期望值，另外一个也大于自身的期望值，那么两个变量之间的协方差就是正值。 如果两个变量的变化趋势相反，即其中一个大于自身的期望值，另外一个却小于自身的期望值，那么两个变量之间的协方差就是负值。\n\n如果$X$与$Y$是统计独立的，那么二者之间的协方差就是0，因为两个独立的随机变量满足$\\mathrm{E}[XY]=\\mathrm{E}[X]\\mathrm{E}[Y]$。但是，反过来并不成立。即如果$X$与$Y$的协方差为0，二者并不一定是统计独立的。\n\n**协方差为0的两个随机变量称为是不相关的。**\n\n### 协方差矩阵：\n\n在统计学与概率论中，协方差矩阵(Covariance matrix)的每个元素是各个向量元素之间的协方差，是从标量随机变量到高维度随机向量的自然推广。\n\n设$X=\\left(X_{1},X_{2},\\ldots,X_{n}\\right)^{\\mathrm{T}}$为$n$ 维随机变量，称矩阵\n\n{% raw %}\n$$\nC=\\left(\\begin{array}{cccc} c_{11} & c_{12} & \\cdots & c_{1n}\\\\ c_{21} & c_{22} & \\cdots & c_{2n}\\\\ \\vdots & \\vdots & \\ddots & \\vdots\\\\ c_{n1} & c_{n2} & \\cdots & c_{nn} \\end{array}\\right)\n$$\n{% endraw %}\n\n为 n 维随机变量x的协方差矩阵，也记为 $D\\left(X\\right)$ ，其中\n$$\nc_{ij}=\\mathrm{Cov}(X_{i},X_{j}),\\quad i,j=1,2,\\ldots,n\n$$\n为X的分量$X_{i}$和$X_{j}$的协方差。*并且对角线上的元素为各个随机变量的方差：*\n\n$$\nc_{ii}=\\mathrm{Cov}(X_{i},X_{i}),\\quad i=1,2,\\ldots,n\n$$\n\n协方差矩阵是对称半正定矩阵。协方差矩阵的对称性，可从定义得知。对于半正定特性，证明如下：\n\n现给定任意一个非零向量$\\boldsymbol{x}$，则\n\n{% raw %}\n$$\n\\begin{aligned}\n\\boldsymbol{x}^{\\mathrm{T}}C\\boldsymbol{x}\t&=\\boldsymbol{x}^{\\mathrm{T}}\\mathrm{E}\\left[\\left(X-\\mu\\right)\\left(X-\\mu\\right)^{\\mathrm{T}}\\right]\\boldsymbol{x} \t\n\\\\&=\\mathrm{E}\\left[\\boldsymbol{x}^{\\mathrm{T}}\\left(X-\\mu\\right)\\left(X-\\mu\\right)^{\\mathrm{T}}\\boldsymbol{x}\\right] \t\\\\&=\\mathrm{E}\\left[\\left(\\left(X-\\mu\\right)^{\\mathrm{T}}\\boldsymbol{x}\\right)^{\\mathrm{T}}\\left(\\left(X-\\mu\\right)^{\\mathrm{T}}\\boldsymbol{x}\\right)\\right] \t\n\\\\&=\\mathrm{E}\\left(\\left\\Vert \\left(X-\\mu\\right)^{\\mathrm{T}}\\boldsymbol{x}\\right\\Vert ^{2}\\right) \t\n\\\\&=\\sigma_{X}^{2}\n\\end{aligned}\n$$\n{% endraw %}\n\n其中，\n$$\n\\sigma_{X}=\\left(X-\\mu \\right)^{\\mathrm{T}}\\boldsymbol{x}\n$$\n由于 $\\sigma_{X}^{2}\\geq0$，因此$\\boldsymbol{x}^{\\mathrm{T}}C\\boldsymbol{x}\\geq0$，因此协方差矩阵$C$ 是半正定矩阵。\n\n","source":"_posts/covariance-matrix.md","raw":"---\ntitle: 直观理解协方差矩阵\ndate: 2021-08-05 11:26:21\ntags: [math,概率论]\ncategories: [math,概率论]\nmath: true\n---\n\n> 原文出自 https://zhuanlan.zhihu.com/p/349802953\n\n## 1 概率论中的定义\n\n### 随机变量：\n\n随机变量(Random Variable) X 是一个映射，把随机试验的结果与实数建立起了一一对应的关系。而期望与方差是随机变量的两个重要的数字特征。\n\n### 数学期望：\n\n在概率论和统计学中，数学期望(mean)(或均值，亦简称期望(Expectation, or expected value))是试验中每次可能结果的概率乘以其结果的总和，是最基本的数学特征之一。它反映随机变量平均取值的大小。 期望值是该变量输出值的平均数。期望值并不一定包含于变量的输出值集合里。\n\n大数定律规定，随着重复次数接近无穷大，数值的算术平均值几乎肯定地收敛于期望值。\n\n### 方差：\n\n方差(Variance)是在概率论和统计方差衡量随机变量或一组数据时离散程度的度量。概率论中方差用来度量随机变量和其数学期望(即均值)之间的偏离程度。统计中的方差(样本方差)是每个样本值与全体样本值的平均数之差的平方值的平均数。\n\n设$X$为随机变量， 如果$\\mathrm{E}[X]$，则随机变量$X$的方差为：\n$$\n\\mu=\\mathrm{E}[X]\n$$\n\n方差也记为 $\\sigma_{X}^{2}$。\n\n样本方差计算公式：\n\n$$\nS^{2}=\\Sigma\\left(X-\\overline{X}\\right)^{2}/\\left(n-1\\right)\n$$\n\n其中，$S^{2}$为样本方差，$X$ 为变量，$\\overline{X}$为样本均值，$n$ 为样本例数。如果要了解为什么要除以$n-1$，请看[这篇文章](https://link.zhihu.com/?target=https%3A//www.visiondummy.com/2014/03/divide-variance-n-1/)。\n\n### 标准差：\n\n标准差(Standard Deviation)是离均差平方的算术平均数(即：方差)的算术平方根，用$\\sigma$表示。标准差也被称为标准偏差，或者实验标准差，在概率统计中最常使用作为统计分布程度上的测量依据。 见下图：\n\n![](https://pic1.zhimg.com/80/v2-37e04458baf17d09c914981b5dbae140_720w.jpg)\n\n标准差是方差的算术平方根。标准差能反映一个数据集的离散程度。平均数相同的两组数据，标准差未必相同。\n\n### 协方差：\n\n**协方差(Covariance)在概率论和统计学中用于衡量两个变量的总体误差。而方差是协方差的一种特殊情况，即当两个变量是相同的情况。**\n\n期望值分别为$ E[X]$与$[Y]$的两个实随机变量$X$与$Y$之间的协方差 $\\mathrm{Cov}(X,Y)$ 定义为：\n\n{% raw %}\n$$\n\\begin{aligned}\n\\mathrm{Cov}(X,Y)&=\\mathrm{E}\\left[\\left(X\\mathrm{E}\\left[X\\right]\\right)\\left(Y-\\mathrm{E}\\left[Y\\right]\\right)\\right]  \n\\\\&=\\mathrm{E}\\left[XY\\right]-2\\mathrm{E}\\left[Y\\right]\\mathrm{E}\\left[X\\right]+\\mathrm{E}\\left[X\\right]\\mathrm{E}\\left[Y\\right]\n\\\\&=\\mathrm{E}\\left[XY\\right]-\\mathrm{E}\\left[X\\right]\\mathrm{E}\\left[Y\\right] \n\\\\&=\\mathrm{E}\\left[XY\\right]-\\mathrm{E}\\left[X\\right]\\mathrm{E}\\left[Y\\right]\n\\end{aligned}\n$$\n{% endraw %}\n\n协方差表示的是两个变量总体误差的期望。 如果两个变量的变化趋势一致，也就是说如果其中一个大于自身的期望值，另外一个也大于自身的期望值，那么两个变量之间的协方差就是正值。 如果两个变量的变化趋势相反，即其中一个大于自身的期望值，另外一个却小于自身的期望值，那么两个变量之间的协方差就是负值。\n\n如果$X$与$Y$是统计独立的，那么二者之间的协方差就是0，因为两个独立的随机变量满足$\\mathrm{E}[XY]=\\mathrm{E}[X]\\mathrm{E}[Y]$。但是，反过来并不成立。即如果$X$与$Y$的协方差为0，二者并不一定是统计独立的。\n\n**协方差为0的两个随机变量称为是不相关的。**\n\n### 协方差矩阵：\n\n在统计学与概率论中，协方差矩阵(Covariance matrix)的每个元素是各个向量元素之间的协方差，是从标量随机变量到高维度随机向量的自然推广。\n\n设$X=\\left(X_{1},X_{2},\\ldots,X_{n}\\right)^{\\mathrm{T}}$为$n$ 维随机变量，称矩阵\n\n{% raw %}\n$$\nC=\\left(\\begin{array}{cccc} c_{11} & c_{12} & \\cdots & c_{1n}\\\\ c_{21} & c_{22} & \\cdots & c_{2n}\\\\ \\vdots & \\vdots & \\ddots & \\vdots\\\\ c_{n1} & c_{n2} & \\cdots & c_{nn} \\end{array}\\right)\n$$\n{% endraw %}\n\n为 n 维随机变量x的协方差矩阵，也记为 $D\\left(X\\right)$ ，其中\n$$\nc_{ij}=\\mathrm{Cov}(X_{i},X_{j}),\\quad i,j=1,2,\\ldots,n\n$$\n为X的分量$X_{i}$和$X_{j}$的协方差。*并且对角线上的元素为各个随机变量的方差：*\n\n$$\nc_{ii}=\\mathrm{Cov}(X_{i},X_{i}),\\quad i=1,2,\\ldots,n\n$$\n\n协方差矩阵是对称半正定矩阵。协方差矩阵的对称性，可从定义得知。对于半正定特性，证明如下：\n\n现给定任意一个非零向量$\\boldsymbol{x}$，则\n\n{% raw %}\n$$\n\\begin{aligned}\n\\boldsymbol{x}^{\\mathrm{T}}C\\boldsymbol{x}\t&=\\boldsymbol{x}^{\\mathrm{T}}\\mathrm{E}\\left[\\left(X-\\mu\\right)\\left(X-\\mu\\right)^{\\mathrm{T}}\\right]\\boldsymbol{x} \t\n\\\\&=\\mathrm{E}\\left[\\boldsymbol{x}^{\\mathrm{T}}\\left(X-\\mu\\right)\\left(X-\\mu\\right)^{\\mathrm{T}}\\boldsymbol{x}\\right] \t\\\\&=\\mathrm{E}\\left[\\left(\\left(X-\\mu\\right)^{\\mathrm{T}}\\boldsymbol{x}\\right)^{\\mathrm{T}}\\left(\\left(X-\\mu\\right)^{\\mathrm{T}}\\boldsymbol{x}\\right)\\right] \t\n\\\\&=\\mathrm{E}\\left(\\left\\Vert \\left(X-\\mu\\right)^{\\mathrm{T}}\\boldsymbol{x}\\right\\Vert ^{2}\\right) \t\n\\\\&=\\sigma_{X}^{2}\n\\end{aligned}\n$$\n{% endraw %}\n\n其中，\n$$\n\\sigma_{X}=\\left(X-\\mu \\right)^{\\mathrm{T}}\\boldsymbol{x}\n$$\n由于 $\\sigma_{X}^{2}\\geq0$，因此$\\boldsymbol{x}^{\\mathrm{T}}C\\boldsymbol{x}\\geq0$，因此协方差矩阵$C$ 是半正定矩阵。\n\n","slug":"covariance-matrix","published":1,"updated":"2021-08-05T13:14:23.401Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cks4ew7uh0007xox44y0qcuiv","content":"<blockquote>\n<p>原文出自 <a href=\"https://zhuanlan.zhihu.com/p/349802953\">https://zhuanlan.zhihu.com/p/349802953</a></p>\n</blockquote>\n<h2 id=\"1-概率论中的定义\"><a href=\"#1-概率论中的定义\" class=\"headerlink\" title=\"1 概率论中的定义\"></a>1 概率论中的定义</h2><h3 id=\"随机变量：\"><a href=\"#随机变量：\" class=\"headerlink\" title=\"随机变量：\"></a>随机变量：</h3><p>随机变量(Random Variable) X 是一个映射，把随机试验的结果与实数建立起了一一对应的关系。而期望与方差是随机变量的两个重要的数字特征。</p>\n<h3 id=\"数学期望：\"><a href=\"#数学期望：\" class=\"headerlink\" title=\"数学期望：\"></a>数学期望：</h3><p>在概率论和统计学中，数学期望(mean)(或均值，亦简称期望(Expectation, or expected value))是试验中每次可能结果的概率乘以其结果的总和，是最基本的数学特征之一。它反映随机变量平均取值的大小。 期望值是该变量输出值的平均数。期望值并不一定包含于变量的输出值集合里。</p>\n<p>大数定律规定，随着重复次数接近无穷大，数值的算术平均值几乎肯定地收敛于期望值。</p>\n<h3 id=\"方差：\"><a href=\"#方差：\" class=\"headerlink\" title=\"方差：\"></a>方差：</h3><p>方差(Variance)是在概率论和统计方差衡量随机变量或一组数据时离散程度的度量。概率论中方差用来度量随机变量和其数学期望(即均值)之间的偏离程度。统计中的方差(样本方差)是每个样本值与全体样本值的平均数之差的平方值的平均数。</p>\n<p>设$X$为随机变量， 如果$\\mathrm{E}[X]$，则随机变量$X$的方差为：<br>$$<br>\\mu=\\mathrm{E}[X]<br>$$</p>\n<p>方差也记为 $\\sigma_{X}^{2}$。</p>\n<p>样本方差计算公式：</p>\n<p>$$<br>S^{2}=\\Sigma\\left(X-\\overline{X}\\right)^{2}/\\left(n-1\\right)<br>$$</p>\n<p>其中，$S^{2}$为样本方差，$X$ 为变量，$\\overline{X}$为样本均值，$n$ 为样本例数。如果要了解为什么要除以$n-1$，请看<a href=\"https://link.zhihu.com/?target=https://www.visiondummy.com/2014/03/divide-variance-n-1/\">这篇文章</a>。</p>\n<h3 id=\"标准差：\"><a href=\"#标准差：\" class=\"headerlink\" title=\"标准差：\"></a>标准差：</h3><p>标准差(Standard Deviation)是离均差平方的算术平均数(即：方差)的算术平方根，用$\\sigma$表示。标准差也被称为标准偏差，或者实验标准差，在概率统计中最常使用作为统计分布程度上的测量依据。 见下图：</p>\n<p><img src=\"https://pic1.zhimg.com/80/v2-37e04458baf17d09c914981b5dbae140_720w.jpg\"></p>\n<p>标准差是方差的算术平方根。标准差能反映一个数据集的离散程度。平均数相同的两组数据，标准差未必相同。</p>\n<h3 id=\"协方差：\"><a href=\"#协方差：\" class=\"headerlink\" title=\"协方差：\"></a>协方差：</h3><p><strong>协方差(Covariance)在概率论和统计学中用于衡量两个变量的总体误差。而方差是协方差的一种特殊情况，即当两个变量是相同的情况。</strong></p>\n<p>期望值分别为$ E[X]$与$[Y]$的两个实随机变量$X$与$Y$之间的协方差 $\\mathrm{Cov}(X,Y)$ 定义为：</p>\n\n$$\n\\begin{aligned}\n\\mathrm{Cov}(X,Y)&amp;=\\mathrm{E}\\left[\\left(X\\mathrm{E}\\left[X\\right]\\right)\\left(Y-\\mathrm{E}\\left[Y\\right]\\right)\\right]  \n\\\\&amp;=\\mathrm{E}\\left[XY\\right]-2\\mathrm{E}\\left[Y\\right]\\mathrm{E}\\left[X\\right]+\\mathrm{E}\\left[X\\right]\\mathrm{E}\\left[Y\\right]\n\\\\&amp;=\\mathrm{E}\\left[XY\\right]-\\mathrm{E}\\left[X\\right]\\mathrm{E}\\left[Y\\right] \n\\\\&amp;=\\mathrm{E}\\left[XY\\right]-\\mathrm{E}\\left[X\\right]\\mathrm{E}\\left[Y\\right]\n\\end{aligned}\n$$\n\n\n<p>协方差表示的是两个变量总体误差的期望。 如果两个变量的变化趋势一致，也就是说如果其中一个大于自身的期望值，另外一个也大于自身的期望值，那么两个变量之间的协方差就是正值。 如果两个变量的变化趋势相反，即其中一个大于自身的期望值，另外一个却小于自身的期望值，那么两个变量之间的协方差就是负值。</p>\n<p>如果$X$与$Y$是统计独立的，那么二者之间的协方差就是0，因为两个独立的随机变量满足$\\mathrm{E}[XY]=\\mathrm{E}[X]\\mathrm{E}[Y]$。但是，反过来并不成立。即如果$X$与$Y$的协方差为0，二者并不一定是统计独立的。</p>\n<p><strong>协方差为0的两个随机变量称为是不相关的。</strong></p>\n<h3 id=\"协方差矩阵：\"><a href=\"#协方差矩阵：\" class=\"headerlink\" title=\"协方差矩阵：\"></a>协方差矩阵：</h3><p>在统计学与概率论中，协方差矩阵(Covariance matrix)的每个元素是各个向量元素之间的协方差，是从标量随机变量到高维度随机向量的自然推广。</p>\n<p>设$X=\\left(X_{1},X_{2},\\ldots,X_{n}\\right)^{\\mathrm{T}}$为$n$ 维随机变量，称矩阵</p>\n\n$$\nC=\\left(\\begin{array}{cccc} c_{11} &amp; c_{12} &amp; \\cdots &amp; c_{1n}\\\\ c_{21} &amp; c_{22} &amp; \\cdots &amp; c_{2n}\\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots\\\\ c_{n1} &amp; c_{n2} &amp; \\cdots &amp; c_{nn} \\end{array}\\right)\n$$\n\n\n<p>为 n 维随机变量x的协方差矩阵，也记为 $D\\left(X\\right)$ ，其中<br>$$<br>c_{ij}=\\mathrm{Cov}(X_{i},X_{j}),\\quad i,j=1,2,\\ldots,n<br>$$<br>为X的分量$X_{i}$和$X_{j}$的协方差。<em>并且对角线上的元素为各个随机变量的方差：</em></p>\n<p>$$<br>c_{ii}=\\mathrm{Cov}(X_{i},X_{i}),\\quad i=1,2,\\ldots,n<br>$$</p>\n<p>协方差矩阵是对称半正定矩阵。协方差矩阵的对称性，可从定义得知。对于半正定特性，证明如下：</p>\n<p>现给定任意一个非零向量$\\boldsymbol{x}$，则</p>\n\n$$\n\\begin{aligned}\n\\boldsymbol{x}^{\\mathrm{T}}C\\boldsymbol{x}\t&amp;=\\boldsymbol{x}^{\\mathrm{T}}\\mathrm{E}\\left[\\left(X-\\mu\\right)\\left(X-\\mu\\right)^{\\mathrm{T}}\\right]\\boldsymbol{x} \t\n\\\\&amp;=\\mathrm{E}\\left[\\boldsymbol{x}^{\\mathrm{T}}\\left(X-\\mu\\right)\\left(X-\\mu\\right)^{\\mathrm{T}}\\boldsymbol{x}\\right] \t\\\\&amp;=\\mathrm{E}\\left[\\left(\\left(X-\\mu\\right)^{\\mathrm{T}}\\boldsymbol{x}\\right)^{\\mathrm{T}}\\left(\\left(X-\\mu\\right)^{\\mathrm{T}}\\boldsymbol{x}\\right)\\right] \t\n\\\\&amp;=\\mathrm{E}\\left(\\left\\Vert \\left(X-\\mu\\right)^{\\mathrm{T}}\\boldsymbol{x}\\right\\Vert ^{2}\\right) \t\n\\\\&amp;=\\sigma_{X}^{2}\n\\end{aligned}\n$$\n\n\n<p>其中，<br>$$<br>\\sigma_{X}=\\left(X-\\mu \\right)^{\\mathrm{T}}\\boldsymbol{x}<br>$$<br>由于 $\\sigma_{X}^{2}\\geq0$，因此$\\boldsymbol{x}^{\\mathrm{T}}C\\boldsymbol{x}\\geq0$，因此协方差矩阵$C$ 是半正定矩阵。</p>\n","site":{"data":{"friends":[{"avatar":"http://image.luokangyuan.com/1_qq_27922023.jpg","name":"码酱","introduction":"我不是大佬，只是在追寻大佬的脚步","url":"http://luokangyuan.com/","title":"前去学习"},{"avatar":"http://image.luokangyuan.com/4027734.jpeg","name":"闪烁之狐","introduction":"编程界大佬，技术牛，人还特别好，不懂的都可以请教大佬","url":"https://blinkfox.github.io/","title":"前去学习"},{"avatar":"http://image.luokangyuan.com/avatar.jpg","name":"ja_rome","introduction":"平凡的脚步也可以走出伟大的行程","url":"https://me.csdn.net/jlh912008548","title":"前去学习"}]}},"excerpt":"","more":"<blockquote>\n<p>原文出自 <a href=\"https://zhuanlan.zhihu.com/p/349802953\">https://zhuanlan.zhihu.com/p/349802953</a></p>\n</blockquote>\n<h2 id=\"1-概率论中的定义\"><a href=\"#1-概率论中的定义\" class=\"headerlink\" title=\"1 概率论中的定义\"></a>1 概率论中的定义</h2><h3 id=\"随机变量：\"><a href=\"#随机变量：\" class=\"headerlink\" title=\"随机变量：\"></a>随机变量：</h3><p>随机变量(Random Variable) X 是一个映射，把随机试验的结果与实数建立起了一一对应的关系。而期望与方差是随机变量的两个重要的数字特征。</p>\n<h3 id=\"数学期望：\"><a href=\"#数学期望：\" class=\"headerlink\" title=\"数学期望：\"></a>数学期望：</h3><p>在概率论和统计学中，数学期望(mean)(或均值，亦简称期望(Expectation, or expected value))是试验中每次可能结果的概率乘以其结果的总和，是最基本的数学特征之一。它反映随机变量平均取值的大小。 期望值是该变量输出值的平均数。期望值并不一定包含于变量的输出值集合里。</p>\n<p>大数定律规定，随着重复次数接近无穷大，数值的算术平均值几乎肯定地收敛于期望值。</p>\n<h3 id=\"方差：\"><a href=\"#方差：\" class=\"headerlink\" title=\"方差：\"></a>方差：</h3><p>方差(Variance)是在概率论和统计方差衡量随机变量或一组数据时离散程度的度量。概率论中方差用来度量随机变量和其数学期望(即均值)之间的偏离程度。统计中的方差(样本方差)是每个样本值与全体样本值的平均数之差的平方值的平均数。</p>\n<p>设$X$为随机变量， 如果$\\mathrm{E}[X]$，则随机变量$X$的方差为：<br>$$<br>\\mu=\\mathrm{E}[X]<br>$$</p>\n<p>方差也记为 $\\sigma_{X}^{2}$。</p>\n<p>样本方差计算公式：</p>\n<p>$$<br>S^{2}=\\Sigma\\left(X-\\overline{X}\\right)^{2}/\\left(n-1\\right)<br>$$</p>\n<p>其中，$S^{2}$为样本方差，$X$ 为变量，$\\overline{X}$为样本均值，$n$ 为样本例数。如果要了解为什么要除以$n-1$，请看<a href=\"https://link.zhihu.com/?target=https://www.visiondummy.com/2014/03/divide-variance-n-1/\">这篇文章</a>。</p>\n<h3 id=\"标准差：\"><a href=\"#标准差：\" class=\"headerlink\" title=\"标准差：\"></a>标准差：</h3><p>标准差(Standard Deviation)是离均差平方的算术平均数(即：方差)的算术平方根，用$\\sigma$表示。标准差也被称为标准偏差，或者实验标准差，在概率统计中最常使用作为统计分布程度上的测量依据。 见下图：</p>\n<p><img src=\"https://pic1.zhimg.com/80/v2-37e04458baf17d09c914981b5dbae140_720w.jpg\"></p>\n<p>标准差是方差的算术平方根。标准差能反映一个数据集的离散程度。平均数相同的两组数据，标准差未必相同。</p>\n<h3 id=\"协方差：\"><a href=\"#协方差：\" class=\"headerlink\" title=\"协方差：\"></a>协方差：</h3><p><strong>协方差(Covariance)在概率论和统计学中用于衡量两个变量的总体误差。而方差是协方差的一种特殊情况，即当两个变量是相同的情况。</strong></p>\n<p>期望值分别为$ E[X]$与$[Y]$的两个实随机变量$X$与$Y$之间的协方差 $\\mathrm{Cov}(X,Y)$ 定义为：</p>\n\n$$\n\\begin{aligned}\n\\mathrm{Cov}(X,Y)&=\\mathrm{E}\\left[\\left(X\\mathrm{E}\\left[X\\right]\\right)\\left(Y-\\mathrm{E}\\left[Y\\right]\\right)\\right]  \n\\\\&=\\mathrm{E}\\left[XY\\right]-2\\mathrm{E}\\left[Y\\right]\\mathrm{E}\\left[X\\right]+\\mathrm{E}\\left[X\\right]\\mathrm{E}\\left[Y\\right]\n\\\\&=\\mathrm{E}\\left[XY\\right]-\\mathrm{E}\\left[X\\right]\\mathrm{E}\\left[Y\\right] \n\\\\&=\\mathrm{E}\\left[XY\\right]-\\mathrm{E}\\left[X\\right]\\mathrm{E}\\left[Y\\right]\n\\end{aligned}\n$$\n\n\n<p>协方差表示的是两个变量总体误差的期望。 如果两个变量的变化趋势一致，也就是说如果其中一个大于自身的期望值，另外一个也大于自身的期望值，那么两个变量之间的协方差就是正值。 如果两个变量的变化趋势相反，即其中一个大于自身的期望值，另外一个却小于自身的期望值，那么两个变量之间的协方差就是负值。</p>\n<p>如果$X$与$Y$是统计独立的，那么二者之间的协方差就是0，因为两个独立的随机变量满足$\\mathrm{E}[XY]=\\mathrm{E}[X]\\mathrm{E}[Y]$。但是，反过来并不成立。即如果$X$与$Y$的协方差为0，二者并不一定是统计独立的。</p>\n<p><strong>协方差为0的两个随机变量称为是不相关的。</strong></p>\n<h3 id=\"协方差矩阵：\"><a href=\"#协方差矩阵：\" class=\"headerlink\" title=\"协方差矩阵：\"></a>协方差矩阵：</h3><p>在统计学与概率论中，协方差矩阵(Covariance matrix)的每个元素是各个向量元素之间的协方差，是从标量随机变量到高维度随机向量的自然推广。</p>\n<p>设$X=\\left(X_{1},X_{2},\\ldots,X_{n}\\right)^{\\mathrm{T}}$为$n$ 维随机变量，称矩阵</p>\n\n$$\nC=\\left(\\begin{array}{cccc} c_{11} & c_{12} & \\cdots & c_{1n}\\\\ c_{21} & c_{22} & \\cdots & c_{2n}\\\\ \\vdots & \\vdots & \\ddots & \\vdots\\\\ c_{n1} & c_{n2} & \\cdots & c_{nn} \\end{array}\\right)\n$$\n\n\n<p>为 n 维随机变量x的协方差矩阵，也记为 $D\\left(X\\right)$ ，其中<br>$$<br>c_{ij}=\\mathrm{Cov}(X_{i},X_{j}),\\quad i,j=1,2,\\ldots,n<br>$$<br>为X的分量$X_{i}$和$X_{j}$的协方差。<em>并且对角线上的元素为各个随机变量的方差：</em></p>\n<p>$$<br>c_{ii}=\\mathrm{Cov}(X_{i},X_{i}),\\quad i=1,2,\\ldots,n<br>$$</p>\n<p>协方差矩阵是对称半正定矩阵。协方差矩阵的对称性，可从定义得知。对于半正定特性，证明如下：</p>\n<p>现给定任意一个非零向量$\\boldsymbol{x}$，则</p>\n\n$$\n\\begin{aligned}\n\\boldsymbol{x}^{\\mathrm{T}}C\\boldsymbol{x}\t&=\\boldsymbol{x}^{\\mathrm{T}}\\mathrm{E}\\left[\\left(X-\\mu\\right)\\left(X-\\mu\\right)^{\\mathrm{T}}\\right]\\boldsymbol{x} \t\n\\\\&=\\mathrm{E}\\left[\\boldsymbol{x}^{\\mathrm{T}}\\left(X-\\mu\\right)\\left(X-\\mu\\right)^{\\mathrm{T}}\\boldsymbol{x}\\right] \t\\\\&=\\mathrm{E}\\left[\\left(\\left(X-\\mu\\right)^{\\mathrm{T}}\\boldsymbol{x}\\right)^{\\mathrm{T}}\\left(\\left(X-\\mu\\right)^{\\mathrm{T}}\\boldsymbol{x}\\right)\\right] \t\n\\\\&=\\mathrm{E}\\left(\\left\\Vert \\left(X-\\mu\\right)^{\\mathrm{T}}\\boldsymbol{x}\\right\\Vert ^{2}\\right) \t\n\\\\&=\\sigma_{X}^{2}\n\\end{aligned}\n$$\n\n\n<p>其中，<br>$$<br>\\sigma_{X}=\\left(X-\\mu \\right)^{\\mathrm{T}}\\boldsymbol{x}<br>$$<br>由于 $\\sigma_{X}^{2}\\geq0$，因此$\\boldsymbol{x}^{\\mathrm{T}}C\\boldsymbol{x}\\geq0$，因此协方差矩阵$C$ 是半正定矩阵。</p>\n"},{"title":"子模块为空的解决方案","date":"2021-08-05T18:09:00.000Z","_content":"\n> 针对子模块文件夹为空的情况，采取下列解决方案。\n>\n> 当一个 git 项目包含子模块（submodule) 时，直接克隆下来的子模块目录里面是空的。\n\n**有两种方法解决**：\n\n### 方法一\n\n如果项目已经克隆到了本地，执行下面的步骤：\n\n1. 初始化本地子模块配置文件\n\n   ```\n   git submodule init\n   1\n   ```\n\n2. 更新项目，抓取子模块内容。\n\n   ```\n   git submodule update\n   ```\n\n### 方法二\n\n另外一种更简单的方法，就是在执行 `git clone` 时加上 `--recursive` 参数。它会自动初始化并更新每一个子模块。例如：\n\n```\ngit clone --recursive https://github.com/example/example.git\n```\n\n","source":"_posts/git-submodule.md","raw":"---\ntitle: 子模块为空的解决方案\ndate: 2021-08-06 02:09:00\ntags: git\ncategories: git\n---\n\n> 针对子模块文件夹为空的情况，采取下列解决方案。\n>\n> 当一个 git 项目包含子模块（submodule) 时，直接克隆下来的子模块目录里面是空的。\n\n**有两种方法解决**：\n\n### 方法一\n\n如果项目已经克隆到了本地，执行下面的步骤：\n\n1. 初始化本地子模块配置文件\n\n   ```\n   git submodule init\n   1\n   ```\n\n2. 更新项目，抓取子模块内容。\n\n   ```\n   git submodule update\n   ```\n\n### 方法二\n\n另外一种更简单的方法，就是在执行 `git clone` 时加上 `--recursive` 参数。它会自动初始化并更新每一个子模块。例如：\n\n```\ngit clone --recursive https://github.com/example/example.git\n```\n\n","slug":"git-submodule","published":1,"updated":"2021-08-06T08:06:48.563Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cks4ew7ui0009xox44x8bduwo","content":"<blockquote>\n<p>针对子模块文件夹为空的情况，采取下列解决方案。</p>\n<p>当一个 git 项目包含子模块（submodule) 时，直接克隆下来的子模块目录里面是空的。</p>\n</blockquote>\n<p><strong>有两种方法解决</strong>：</p>\n<h3 id=\"方法一\"><a href=\"#方法一\" class=\"headerlink\" title=\"方法一\"></a>方法一</h3><p>如果项目已经克隆到了本地，执行下面的步骤：</p>\n<ol>\n<li><p>初始化本地子模块配置文件</p>\n<figure class=\"highlight csharp\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs csharp\">git submodule <span class=\"hljs-keyword\">init</span><br><span class=\"hljs-number\">1</span><br></code></pre></td></tr></tbody></table></figure></li>\n<li><p>更新项目，抓取子模块内容。</p>\n<figure class=\"highlight ebnf\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs ebnf\"><span class=\"hljs-attribute\">git submodule update</span><br></code></pre></td></tr></tbody></table></figure></li>\n</ol>\n<h3 id=\"方法二\"><a href=\"#方法二\" class=\"headerlink\" title=\"方法二\"></a>方法二</h3><p>另外一种更简单的方法，就是在执行 <code>git clone</code> 时加上 <code>--recursive</code> 参数。它会自动初始化并更新每一个子模块。例如：</p>\n<figure class=\"highlight awk\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs awk\">git clone --recursive https:<span class=\"hljs-regexp\">//gi</span>thub.com<span class=\"hljs-regexp\">/example/</span>example.git<br></code></pre></td></tr></tbody></table></figure>\n\n","site":{"data":{"friends":[{"avatar":"http://image.luokangyuan.com/1_qq_27922023.jpg","name":"码酱","introduction":"我不是大佬，只是在追寻大佬的脚步","url":"http://luokangyuan.com/","title":"前去学习"},{"avatar":"http://image.luokangyuan.com/4027734.jpeg","name":"闪烁之狐","introduction":"编程界大佬，技术牛，人还特别好，不懂的都可以请教大佬","url":"https://blinkfox.github.io/","title":"前去学习"},{"avatar":"http://image.luokangyuan.com/avatar.jpg","name":"ja_rome","introduction":"平凡的脚步也可以走出伟大的行程","url":"https://me.csdn.net/jlh912008548","title":"前去学习"}]}},"excerpt":"","more":"<blockquote>\n<p>针对子模块文件夹为空的情况，采取下列解决方案。</p>\n<p>当一个 git 项目包含子模块（submodule) 时，直接克隆下来的子模块目录里面是空的。</p>\n</blockquote>\n<p><strong>有两种方法解决</strong>：</p>\n<h3 id=\"方法一\"><a href=\"#方法一\" class=\"headerlink\" title=\"方法一\"></a>方法一</h3><p>如果项目已经克隆到了本地，执行下面的步骤：</p>\n<ol>\n<li><p>初始化本地子模块配置文件</p>\n<figure class=\"highlight csharp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs csharp\">git submodule <span class=\"hljs-keyword\">init</span><br><span class=\"hljs-number\">1</span><br></code></pre></td></tr></table></figure></li>\n<li><p>更新项目，抓取子模块内容。</p>\n<figure class=\"highlight ebnf\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs ebnf\"><span class=\"hljs-attribute\">git submodule update</span><br></code></pre></td></tr></table></figure></li>\n</ol>\n<h3 id=\"方法二\"><a href=\"#方法二\" class=\"headerlink\" title=\"方法二\"></a>方法二</h3><p>另外一种更简单的方法，就是在执行 <code>git clone</code> 时加上 <code>--recursive</code> 参数。它会自动初始化并更新每一个子模块。例如：</p>\n<figure class=\"highlight awk\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs awk\">git clone --recursive https:<span class=\"hljs-regexp\">//gi</span>thub.com<span class=\"hljs-regexp\">/example/</span>example.git<br></code></pre></td></tr></table></figure>\n\n"},{"title":"hexo中公式显示","date":"2021-08-05T12:38:51.000Z","math":true,"_content":"\n> 公式的显示问题。Hexo中Mathjax是用于显示公式的插件，但是多行显示会出现问题，有时还会出现乱码的情况。\n\n### 配置\n\n在根目录下的config\\_fluid.yml​文件中打开math的相关配置。\n\n```yaml\n  # 数学公式，开启之前需要更换 Markdown 渲染器，否则复杂公式会有兼容问题，具体请见：https://hexo.fluid-dev.com/docs/guide/##latex-数学公式\n  # Mathematical formula. If enable, you need to change the Markdown renderer, see: https://hexo.fluid-dev.com/docs/en/guide/#math\n  math:\n    # 开启后文章默认可用，自定义页面如需使用，需在 Front-matter 中指定 `math: true`\n    # If you want to use math on the custom page, you need to set `math: true` in Front-matter\n    enable: true\n\n    # 开启后，只有在文章 Front-matter 里指定 `math: true` 才会在文章页启动公式转换，以便在页面不包含公式时提高加载速度\n    # If true, only set `math: true` in Front-matter will enable math, to load faster when the page does not contain math\n    specific: true\n\n    # Options: mathjax | katex\n    engine: mathjax\n\n```\n\n### 出现的问题\n\n#### 问题1\n\n- 由于hexo解码时关注{{，}}，%% 等连续字符，会将这部分代码解读为其他带有特殊含义的内容\n- 如果公式中恰巧出现了此类字符，会报出上述错误\n\n#### 问题2\n\n- 由于hexo在公式中的`\\\\`错会成了转义符，也就是说他只看见了一个反斜杠，不会执行换行命令，导致公式堆成一行\n\n### 解决方案\n\n#### 临时方案\n\n##### 针对问题1\n\n- 可以在连续的 `{` `}` `%`中间插入空格，分开就没事了\n\n##### 针对问题2\n\n- 可以将`\\\\`换成`\\\\\\\\`，可以实现公式的多行正确显示\n\n#### 终极方案\n\n- 在官方文档中提到了可以为hexo提供标记，阻止其按照自己的规则解释我们的字符串，显示其原本的含义\n\n- 标记为\n\n  ```\n  {% raw %}\n  $$\n  ...\n  $$\n  {% endraw %}\n  ```\n\n### 多行显示和对齐\n- 默认是显示为一行要实现公式多行和对齐可以使用{aligned}模式，使用\"&\"来标记对齐位置。\"\\\\\\\\\"表示换行\n\n    ```\n    $$\n    \\begin{aligned}\n    \\boldsymbol{x}^{\\mathrm{T}}C\\boldsymbol{x}\t&=\\boldsymbol{x}^{\\mathrm{T}}\\mathrm{E}\\left[\\left(X-\\mu\\right)\\left(X-\\mu\\right)^{\\mathrm{T}}\\right]\\boldsymbol{x} \t\n    \\\\&=\\mathrm{E}\\left[\\boldsymbol{x}^{\\mathrm{T}}\\left(X-\\mu\\right)\\left(X-\\mu\\right)^{\\mathrm{T}}\\boldsymbol{x}\\right] \t\\\\&=\\mathrm{E}\\left[\\left(\\left(X-\\mu\\right)^{\\mathrm{T}}\\boldsymbol{x}\\right)^{\\mathrm{T}}\\left(\\left(X-\\mu\\right)^{\\mathrm{T}}\\boldsymbol{x}\\right)\\right] \t\n    \\\\&=\\mathrm{E}\\left(\\left\\Vert \\left(X-\\mu\\right)^{\\mathrm{T}}\\boldsymbol{x}\\right\\Vert ^{2}\\right) \t\n    \\\\&=\\sigma_{X}^{2}\n    \\end{aligned}\n    $$\n    ```\n\n- 显示为\n\n{% raw %}\n$$\n\\begin{aligned}\n\\boldsymbol{x}^{\\mathrm{T}}C\\boldsymbol{x}\t&=\\boldsymbol{x}^{\\mathrm{T}}\\mathrm{E}\\left[\\left(X-\\mu\\right)\\left(X-\\mu\\right)^{\\mathrm{T}}\\right]\\boldsymbol{x} \t\n\\\\&=\\mathrm{E}\\left[\\boldsymbol{x}^{\\mathrm{T}}\\left(X-\\mu\\right)\\left(X-\\mu\\right)^{\\mathrm{T}}\\boldsymbol{x}\\right] \t\\\\&=\\mathrm{E}\\left[\\left(\\left(X-\\mu\\right)^{\\mathrm{T}}\\boldsymbol{x}\\right)^{\\mathrm{T}}\\left(\\left(X-\\mu\\right)^{\\mathrm{T}}\\boldsymbol{x}\\right)\\right] \t\n\\\\&=\\mathrm{E}\\left(\\left\\Vert \\left(X-\\mu\\right)^{\\mathrm{T}}\\boldsymbol{x}\\right\\Vert ^{2}\\right) \t\n\\\\&=\\sigma_{X}^{2}\n\\end{aligned}\n$$\n{% endraw %}\n\n","source":"_posts/hexo-math-config.md","raw":"---\ntitle: hexo中公式显示\ndate: 2021-08-05 20:38:51\ntags: [hexo,fluid,配置]\ncategories: [配置,hexo]\nmath: true\n---\n\n> 公式的显示问题。Hexo中Mathjax是用于显示公式的插件，但是多行显示会出现问题，有时还会出现乱码的情况。\n\n### 配置\n\n在根目录下的config\\_fluid.yml​文件中打开math的相关配置。\n\n```yaml\n  # 数学公式，开启之前需要更换 Markdown 渲染器，否则复杂公式会有兼容问题，具体请见：https://hexo.fluid-dev.com/docs/guide/##latex-数学公式\n  # Mathematical formula. If enable, you need to change the Markdown renderer, see: https://hexo.fluid-dev.com/docs/en/guide/#math\n  math:\n    # 开启后文章默认可用，自定义页面如需使用，需在 Front-matter 中指定 `math: true`\n    # If you want to use math on the custom page, you need to set `math: true` in Front-matter\n    enable: true\n\n    # 开启后，只有在文章 Front-matter 里指定 `math: true` 才会在文章页启动公式转换，以便在页面不包含公式时提高加载速度\n    # If true, only set `math: true` in Front-matter will enable math, to load faster when the page does not contain math\n    specific: true\n\n    # Options: mathjax | katex\n    engine: mathjax\n\n```\n\n### 出现的问题\n\n#### 问题1\n\n- 由于hexo解码时关注{{，}}，%% 等连续字符，会将这部分代码解读为其他带有特殊含义的内容\n- 如果公式中恰巧出现了此类字符，会报出上述错误\n\n#### 问题2\n\n- 由于hexo在公式中的`\\\\`错会成了转义符，也就是说他只看见了一个反斜杠，不会执行换行命令，导致公式堆成一行\n\n### 解决方案\n\n#### 临时方案\n\n##### 针对问题1\n\n- 可以在连续的 `{` `}` `%`中间插入空格，分开就没事了\n\n##### 针对问题2\n\n- 可以将`\\\\`换成`\\\\\\\\`，可以实现公式的多行正确显示\n\n#### 终极方案\n\n- 在官方文档中提到了可以为hexo提供标记，阻止其按照自己的规则解释我们的字符串，显示其原本的含义\n\n- 标记为\n\n  ```\n  {% raw %}\n  $$\n  ...\n  $$\n  {% endraw %}\n  ```\n\n### 多行显示和对齐\n- 默认是显示为一行要实现公式多行和对齐可以使用{aligned}模式，使用\"&\"来标记对齐位置。\"\\\\\\\\\"表示换行\n\n    ```\n    $$\n    \\begin{aligned}\n    \\boldsymbol{x}^{\\mathrm{T}}C\\boldsymbol{x}\t&=\\boldsymbol{x}^{\\mathrm{T}}\\mathrm{E}\\left[\\left(X-\\mu\\right)\\left(X-\\mu\\right)^{\\mathrm{T}}\\right]\\boldsymbol{x} \t\n    \\\\&=\\mathrm{E}\\left[\\boldsymbol{x}^{\\mathrm{T}}\\left(X-\\mu\\right)\\left(X-\\mu\\right)^{\\mathrm{T}}\\boldsymbol{x}\\right] \t\\\\&=\\mathrm{E}\\left[\\left(\\left(X-\\mu\\right)^{\\mathrm{T}}\\boldsymbol{x}\\right)^{\\mathrm{T}}\\left(\\left(X-\\mu\\right)^{\\mathrm{T}}\\boldsymbol{x}\\right)\\right] \t\n    \\\\&=\\mathrm{E}\\left(\\left\\Vert \\left(X-\\mu\\right)^{\\mathrm{T}}\\boldsymbol{x}\\right\\Vert ^{2}\\right) \t\n    \\\\&=\\sigma_{X}^{2}\n    \\end{aligned}\n    $$\n    ```\n\n- 显示为\n\n{% raw %}\n$$\n\\begin{aligned}\n\\boldsymbol{x}^{\\mathrm{T}}C\\boldsymbol{x}\t&=\\boldsymbol{x}^{\\mathrm{T}}\\mathrm{E}\\left[\\left(X-\\mu\\right)\\left(X-\\mu\\right)^{\\mathrm{T}}\\right]\\boldsymbol{x} \t\n\\\\&=\\mathrm{E}\\left[\\boldsymbol{x}^{\\mathrm{T}}\\left(X-\\mu\\right)\\left(X-\\mu\\right)^{\\mathrm{T}}\\boldsymbol{x}\\right] \t\\\\&=\\mathrm{E}\\left[\\left(\\left(X-\\mu\\right)^{\\mathrm{T}}\\boldsymbol{x}\\right)^{\\mathrm{T}}\\left(\\left(X-\\mu\\right)^{\\mathrm{T}}\\boldsymbol{x}\\right)\\right] \t\n\\\\&=\\mathrm{E}\\left(\\left\\Vert \\left(X-\\mu\\right)^{\\mathrm{T}}\\boldsymbol{x}\\right\\Vert ^{2}\\right) \t\n\\\\&=\\sigma_{X}^{2}\n\\end{aligned}\n$$\n{% endraw %}\n\n","slug":"hexo-math-config","published":1,"updated":"2021-08-06T08:06:48.572Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cks4ew7uj000bxox456vq8c3h","content":"<blockquote>\n<p>公式的显示问题。Hexo中Mathjax是用于显示公式的插件，但是多行显示会出现问题，有时还会出现乱码的情况。</p>\n</blockquote>\n<h3 id=\"配置\"><a href=\"#配置\" class=\"headerlink\" title=\"配置\"></a>配置</h3><p>在根目录下的config_fluid.yml​文件中打开math的相关配置。</p>\n<figure class=\"highlight yaml\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs yaml\"><span class=\"hljs-comment\"># 数学公式，开启之前需要更换 Markdown 渲染器，否则复杂公式会有兼容问题，具体请见：https://hexo.fluid-dev.com/docs/guide/##latex-数学公式</span><br><span class=\"hljs-comment\"># Mathematical formula. If enable, you need to change the Markdown renderer, see: https://hexo.fluid-dev.com/docs/en/guide/#math</span><br><span class=\"hljs-attr\">math:</span><br>  <span class=\"hljs-comment\"># 开启后文章默认可用，自定义页面如需使用，需在 Front-matter 中指定 `math: true`</span><br>  <span class=\"hljs-comment\"># If you want to use math on the custom page, you need to set `math: true` in Front-matter</span><br>  <span class=\"hljs-attr\">enable:</span> <span class=\"hljs-literal\">true</span><br><br>  <span class=\"hljs-comment\"># 开启后，只有在文章 Front-matter 里指定 `math: true` 才会在文章页启动公式转换，以便在页面不包含公式时提高加载速度</span><br>  <span class=\"hljs-comment\"># If true, only set `math: true` in Front-matter will enable math, to load faster when the page does not contain math</span><br>  <span class=\"hljs-attr\">specific:</span> <span class=\"hljs-literal\">true</span><br><br>  <span class=\"hljs-comment\"># Options: mathjax | katex</span><br>  <span class=\"hljs-attr\">engine:</span> <span class=\"hljs-string\">mathjax</span><br><br></code></pre></td></tr></tbody></table></figure>\n\n<h3 id=\"出现的问题\"><a href=\"#出现的问题\" class=\"headerlink\" title=\"出现的问题\"></a>出现的问题</h3><h4 id=\"问题1\"><a href=\"#问题1\" class=\"headerlink\" title=\"问题1\"></a>问题1</h4><ul>\n<li>由于hexo解码时关注，%% 等连续字符，会将这部分代码解读为其他带有特殊含义的内容</li>\n<li>如果公式中恰巧出现了此类字符，会报出上述错误</li>\n</ul>\n<h4 id=\"问题2\"><a href=\"#问题2\" class=\"headerlink\" title=\"问题2\"></a>问题2</h4><ul>\n<li>由于hexo在公式中的<code>\\\\</code>错会成了转义符，也就是说他只看见了一个反斜杠，不会执行换行命令，导致公式堆成一行</li>\n</ul>\n<h3 id=\"解决方案\"><a href=\"#解决方案\" class=\"headerlink\" title=\"解决方案\"></a>解决方案</h3><h4 id=\"临时方案\"><a href=\"#临时方案\" class=\"headerlink\" title=\"临时方案\"></a>临时方案</h4><h5 id=\"针对问题1\"><a href=\"#针对问题1\" class=\"headerlink\" title=\"针对问题1\"></a>针对问题1</h5><ul>\n<li>可以在连续的 <code>{</code> <code>}</code> <code>%</code>中间插入空格，分开就没事了</li>\n</ul>\n<h5 id=\"针对问题2\"><a href=\"#针对问题2\" class=\"headerlink\" title=\"针对问题2\"></a>针对问题2</h5><ul>\n<li>可以将<code>\\\\</code>换成<code>\\\\\\\\</code>，可以实现公式的多行正确显示</li>\n</ul>\n<h4 id=\"终极方案\"><a href=\"#终极方案\" class=\"headerlink\" title=\"终极方案\"></a>终极方案</h4><ul>\n<li><p>在官方文档中提到了可以为hexo提供标记，阻止其按照自己的规则解释我们的字符串，显示其原本的含义</p>\n</li>\n<li><p>标记为</p>\n<figure class=\"highlight django\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs django\"><span class=\"hljs-template-tag\">{% <span class=\"hljs-name\">raw</span> %}</span><span class=\"xml\"></span><br><span class=\"xml\">$$</span><br><span class=\"xml\">...</span><br><span class=\"xml\">$$</span><br><span class=\"xml\"></span><span class=\"hljs-template-tag\">{% <span class=\"hljs-name\">endraw</span> %}</span><br></code></pre></td></tr></tbody></table></figure></li>\n</ul>\n<h3 id=\"多行显示和对齐\"><a href=\"#多行显示和对齐\" class=\"headerlink\" title=\"多行显示和对齐\"></a>多行显示和对齐</h3><ul>\n<li><p>默认是显示为一行要实现公式多行和对齐可以使用{aligned}模式，使用”&amp;”来标记对齐位置。”\\\\“表示换行</p>\n  <figure class=\"highlight taggerscript\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs taggerscript\">$$<br><span class=\"hljs-symbol\">\\b</span>egin{aligned}<br><span class=\"hljs-symbol\">\\b</span>oldsymbol{x}^{<span class=\"hljs-symbol\">\\m</span>athrm{T}}C<span class=\"hljs-symbol\">\\b</span>oldsymbol{x}\t&amp;=<span class=\"hljs-symbol\">\\b</span>oldsymbol{x}^{<span class=\"hljs-symbol\">\\m</span>athrm{T}}<span class=\"hljs-symbol\">\\m</span>athrm{E}<span class=\"hljs-symbol\">\\l</span>eft[<span class=\"hljs-symbol\">\\l</span>eft(X-<span class=\"hljs-symbol\">\\m</span>u<span class=\"hljs-symbol\">\\r</span>ight)<span class=\"hljs-symbol\">\\l</span>eft(X-<span class=\"hljs-symbol\">\\m</span>u<span class=\"hljs-symbol\">\\r</span>ight)^{<span class=\"hljs-symbol\">\\m</span>athrm{T}}<span class=\"hljs-symbol\">\\r</span>ight]<span class=\"hljs-symbol\">\\b</span>oldsymbol{x} \t<br><span class=\"hljs-symbol\">\\\\</span>&amp;=<span class=\"hljs-symbol\">\\m</span>athrm{E}<span class=\"hljs-symbol\">\\l</span>eft[<span class=\"hljs-symbol\">\\b</span>oldsymbol{x}^{<span class=\"hljs-symbol\">\\m</span>athrm{T}}<span class=\"hljs-symbol\">\\l</span>eft(X-<span class=\"hljs-symbol\">\\m</span>u<span class=\"hljs-symbol\">\\r</span>ight)<span class=\"hljs-symbol\">\\l</span>eft(X-<span class=\"hljs-symbol\">\\m</span>u<span class=\"hljs-symbol\">\\r</span>ight)^{<span class=\"hljs-symbol\">\\m</span>athrm{T}}<span class=\"hljs-symbol\">\\b</span>oldsymbol{x}<span class=\"hljs-symbol\">\\r</span>ight] \t<span class=\"hljs-symbol\">\\\\</span>&amp;=<span class=\"hljs-symbol\">\\m</span>athrm{E}<span class=\"hljs-symbol\">\\l</span>eft[<span class=\"hljs-symbol\">\\l</span>eft(<span class=\"hljs-symbol\">\\l</span>eft(X-<span class=\"hljs-symbol\">\\m</span>u<span class=\"hljs-symbol\">\\r</span>ight)^{<span class=\"hljs-symbol\">\\m</span>athrm{T}}<span class=\"hljs-symbol\">\\b</span>oldsymbol{x}<span class=\"hljs-symbol\">\\r</span>ight)^{<span class=\"hljs-symbol\">\\m</span>athrm{T}}<span class=\"hljs-symbol\">\\l</span>eft(<span class=\"hljs-symbol\">\\l</span>eft(X-<span class=\"hljs-symbol\">\\m</span>u<span class=\"hljs-symbol\">\\r</span>ight)^{<span class=\"hljs-symbol\">\\m</span>athrm{T}}<span class=\"hljs-symbol\">\\b</span>oldsymbol{x}<span class=\"hljs-symbol\">\\r</span>ight)<span class=\"hljs-symbol\">\\r</span>ight] \t<br><span class=\"hljs-symbol\">\\\\</span>&amp;=<span class=\"hljs-symbol\">\\m</span>athrm{E}<span class=\"hljs-symbol\">\\l</span>eft(<span class=\"hljs-symbol\">\\l</span>eft<span class=\"hljs-symbol\">\\V</span>ert <span class=\"hljs-symbol\">\\l</span>eft(X-<span class=\"hljs-symbol\">\\m</span>u<span class=\"hljs-symbol\">\\r</span>ight)^{<span class=\"hljs-symbol\">\\m</span>athrm{T}}<span class=\"hljs-symbol\">\\b</span>oldsymbol{x}<span class=\"hljs-symbol\">\\r</span>ight<span class=\"hljs-symbol\">\\V</span>ert ^{2}<span class=\"hljs-symbol\">\\r</span>ight) \t<br><span class=\"hljs-symbol\">\\\\</span>&amp;=<span class=\"hljs-symbol\">\\s</span>igma_{X}^{2}<br><span class=\"hljs-symbol\">\\e</span>nd{aligned}<br>$$<br></code></pre></td></tr></tbody></table></figure></li>\n<li><p>显示为</p>\n</li>\n</ul>\n\n$$\n\\begin{aligned}\n\\boldsymbol{x}^{\\mathrm{T}}C\\boldsymbol{x}\t&amp;=\\boldsymbol{x}^{\\mathrm{T}}\\mathrm{E}\\left[\\left(X-\\mu\\right)\\left(X-\\mu\\right)^{\\mathrm{T}}\\right]\\boldsymbol{x} \t\n\\\\&amp;=\\mathrm{E}\\left[\\boldsymbol{x}^{\\mathrm{T}}\\left(X-\\mu\\right)\\left(X-\\mu\\right)^{\\mathrm{T}}\\boldsymbol{x}\\right] \t\\\\&amp;=\\mathrm{E}\\left[\\left(\\left(X-\\mu\\right)^{\\mathrm{T}}\\boldsymbol{x}\\right)^{\\mathrm{T}}\\left(\\left(X-\\mu\\right)^{\\mathrm{T}}\\boldsymbol{x}\\right)\\right] \t\n\\\\&amp;=\\mathrm{E}\\left(\\left\\Vert \\left(X-\\mu\\right)^{\\mathrm{T}}\\boldsymbol{x}\\right\\Vert ^{2}\\right) \t\n\\\\&amp;=\\sigma_{X}^{2}\n\\end{aligned}\n$$\n\n\n","site":{"data":{"friends":[{"avatar":"http://image.luokangyuan.com/1_qq_27922023.jpg","name":"码酱","introduction":"我不是大佬，只是在追寻大佬的脚步","url":"http://luokangyuan.com/","title":"前去学习"},{"avatar":"http://image.luokangyuan.com/4027734.jpeg","name":"闪烁之狐","introduction":"编程界大佬，技术牛，人还特别好，不懂的都可以请教大佬","url":"https://blinkfox.github.io/","title":"前去学习"},{"avatar":"http://image.luokangyuan.com/avatar.jpg","name":"ja_rome","introduction":"平凡的脚步也可以走出伟大的行程","url":"https://me.csdn.net/jlh912008548","title":"前去学习"}]}},"excerpt":"","more":"<blockquote>\n<p>公式的显示问题。Hexo中Mathjax是用于显示公式的插件，但是多行显示会出现问题，有时还会出现乱码的情况。</p>\n</blockquote>\n<h3 id=\"配置\"><a href=\"#配置\" class=\"headerlink\" title=\"配置\"></a>配置</h3><p>在根目录下的config_fluid.yml​文件中打开math的相关配置。</p>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs yaml\"><span class=\"hljs-comment\"># 数学公式，开启之前需要更换 Markdown 渲染器，否则复杂公式会有兼容问题，具体请见：https://hexo.fluid-dev.com/docs/guide/##latex-数学公式</span><br><span class=\"hljs-comment\"># Mathematical formula. If enable, you need to change the Markdown renderer, see: https://hexo.fluid-dev.com/docs/en/guide/#math</span><br><span class=\"hljs-attr\">math:</span><br>  <span class=\"hljs-comment\"># 开启后文章默认可用，自定义页面如需使用，需在 Front-matter 中指定 `math: true`</span><br>  <span class=\"hljs-comment\"># If you want to use math on the custom page, you need to set `math: true` in Front-matter</span><br>  <span class=\"hljs-attr\">enable:</span> <span class=\"hljs-literal\">true</span><br><br>  <span class=\"hljs-comment\"># 开启后，只有在文章 Front-matter 里指定 `math: true` 才会在文章页启动公式转换，以便在页面不包含公式时提高加载速度</span><br>  <span class=\"hljs-comment\"># If true, only set `math: true` in Front-matter will enable math, to load faster when the page does not contain math</span><br>  <span class=\"hljs-attr\">specific:</span> <span class=\"hljs-literal\">true</span><br><br>  <span class=\"hljs-comment\"># Options: mathjax | katex</span><br>  <span class=\"hljs-attr\">engine:</span> <span class=\"hljs-string\">mathjax</span><br><br></code></pre></td></tr></table></figure>\n\n<h3 id=\"出现的问题\"><a href=\"#出现的问题\" class=\"headerlink\" title=\"出现的问题\"></a>出现的问题</h3><h4 id=\"问题1\"><a href=\"#问题1\" class=\"headerlink\" title=\"问题1\"></a>问题1</h4><ul>\n<li>由于hexo解码时关注，%% 等连续字符，会将这部分代码解读为其他带有特殊含义的内容</li>\n<li>如果公式中恰巧出现了此类字符，会报出上述错误</li>\n</ul>\n<h4 id=\"问题2\"><a href=\"#问题2\" class=\"headerlink\" title=\"问题2\"></a>问题2</h4><ul>\n<li>由于hexo在公式中的<code>\\\\</code>错会成了转义符，也就是说他只看见了一个反斜杠，不会执行换行命令，导致公式堆成一行</li>\n</ul>\n<h3 id=\"解决方案\"><a href=\"#解决方案\" class=\"headerlink\" title=\"解决方案\"></a>解决方案</h3><h4 id=\"临时方案\"><a href=\"#临时方案\" class=\"headerlink\" title=\"临时方案\"></a>临时方案</h4><h5 id=\"针对问题1\"><a href=\"#针对问题1\" class=\"headerlink\" title=\"针对问题1\"></a>针对问题1</h5><ul>\n<li>可以在连续的 <code>&#123;</code> <code>&#125;</code> <code>%</code>中间插入空格，分开就没事了</li>\n</ul>\n<h5 id=\"针对问题2\"><a href=\"#针对问题2\" class=\"headerlink\" title=\"针对问题2\"></a>针对问题2</h5><ul>\n<li>可以将<code>\\\\</code>换成<code>\\\\\\\\</code>，可以实现公式的多行正确显示</li>\n</ul>\n<h4 id=\"终极方案\"><a href=\"#终极方案\" class=\"headerlink\" title=\"终极方案\"></a>终极方案</h4><ul>\n<li><p>在官方文档中提到了可以为hexo提供标记，阻止其按照自己的规则解释我们的字符串，显示其原本的含义</p>\n</li>\n<li><p>标记为</p>\n<figure class=\"highlight django\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs django\"><span class=\"hljs-template-tag\">&#123;% <span class=\"hljs-name\">raw</span> %&#125;</span><span class=\"xml\"></span><br><span class=\"xml\">$$</span><br><span class=\"xml\">...</span><br><span class=\"xml\">$$</span><br><span class=\"xml\"></span><span class=\"hljs-template-tag\">&#123;% <span class=\"hljs-name\">endraw</span> %&#125;</span><br></code></pre></td></tr></table></figure></li>\n</ul>\n<h3 id=\"多行显示和对齐\"><a href=\"#多行显示和对齐\" class=\"headerlink\" title=\"多行显示和对齐\"></a>多行显示和对齐</h3><ul>\n<li><p>默认是显示为一行要实现公式多行和对齐可以使用{aligned}模式，使用”&amp;”来标记对齐位置。”\\\\“表示换行</p>\n  <figure class=\"highlight taggerscript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs taggerscript\">$$<br><span class=\"hljs-symbol\">\\b</span>egin&#123;aligned&#125;<br><span class=\"hljs-symbol\">\\b</span>oldsymbol&#123;x&#125;^&#123;<span class=\"hljs-symbol\">\\m</span>athrm&#123;T&#125;&#125;C<span class=\"hljs-symbol\">\\b</span>oldsymbol&#123;x&#125;\t&amp;=<span class=\"hljs-symbol\">\\b</span>oldsymbol&#123;x&#125;^&#123;<span class=\"hljs-symbol\">\\m</span>athrm&#123;T&#125;&#125;<span class=\"hljs-symbol\">\\m</span>athrm&#123;E&#125;<span class=\"hljs-symbol\">\\l</span>eft[<span class=\"hljs-symbol\">\\l</span>eft(X-<span class=\"hljs-symbol\">\\m</span>u<span class=\"hljs-symbol\">\\r</span>ight)<span class=\"hljs-symbol\">\\l</span>eft(X-<span class=\"hljs-symbol\">\\m</span>u<span class=\"hljs-symbol\">\\r</span>ight)^&#123;<span class=\"hljs-symbol\">\\m</span>athrm&#123;T&#125;&#125;<span class=\"hljs-symbol\">\\r</span>ight]<span class=\"hljs-symbol\">\\b</span>oldsymbol&#123;x&#125; \t<br><span class=\"hljs-symbol\">\\\\</span>&amp;=<span class=\"hljs-symbol\">\\m</span>athrm&#123;E&#125;<span class=\"hljs-symbol\">\\l</span>eft[<span class=\"hljs-symbol\">\\b</span>oldsymbol&#123;x&#125;^&#123;<span class=\"hljs-symbol\">\\m</span>athrm&#123;T&#125;&#125;<span class=\"hljs-symbol\">\\l</span>eft(X-<span class=\"hljs-symbol\">\\m</span>u<span class=\"hljs-symbol\">\\r</span>ight)<span class=\"hljs-symbol\">\\l</span>eft(X-<span class=\"hljs-symbol\">\\m</span>u<span class=\"hljs-symbol\">\\r</span>ight)^&#123;<span class=\"hljs-symbol\">\\m</span>athrm&#123;T&#125;&#125;<span class=\"hljs-symbol\">\\b</span>oldsymbol&#123;x&#125;<span class=\"hljs-symbol\">\\r</span>ight] \t<span class=\"hljs-symbol\">\\\\</span>&amp;=<span class=\"hljs-symbol\">\\m</span>athrm&#123;E&#125;<span class=\"hljs-symbol\">\\l</span>eft[<span class=\"hljs-symbol\">\\l</span>eft(<span class=\"hljs-symbol\">\\l</span>eft(X-<span class=\"hljs-symbol\">\\m</span>u<span class=\"hljs-symbol\">\\r</span>ight)^&#123;<span class=\"hljs-symbol\">\\m</span>athrm&#123;T&#125;&#125;<span class=\"hljs-symbol\">\\b</span>oldsymbol&#123;x&#125;<span class=\"hljs-symbol\">\\r</span>ight)^&#123;<span class=\"hljs-symbol\">\\m</span>athrm&#123;T&#125;&#125;<span class=\"hljs-symbol\">\\l</span>eft(<span class=\"hljs-symbol\">\\l</span>eft(X-<span class=\"hljs-symbol\">\\m</span>u<span class=\"hljs-symbol\">\\r</span>ight)^&#123;<span class=\"hljs-symbol\">\\m</span>athrm&#123;T&#125;&#125;<span class=\"hljs-symbol\">\\b</span>oldsymbol&#123;x&#125;<span class=\"hljs-symbol\">\\r</span>ight)<span class=\"hljs-symbol\">\\r</span>ight] \t<br><span class=\"hljs-symbol\">\\\\</span>&amp;=<span class=\"hljs-symbol\">\\m</span>athrm&#123;E&#125;<span class=\"hljs-symbol\">\\l</span>eft(<span class=\"hljs-symbol\">\\l</span>eft<span class=\"hljs-symbol\">\\V</span>ert <span class=\"hljs-symbol\">\\l</span>eft(X-<span class=\"hljs-symbol\">\\m</span>u<span class=\"hljs-symbol\">\\r</span>ight)^&#123;<span class=\"hljs-symbol\">\\m</span>athrm&#123;T&#125;&#125;<span class=\"hljs-symbol\">\\b</span>oldsymbol&#123;x&#125;<span class=\"hljs-symbol\">\\r</span>ight<span class=\"hljs-symbol\">\\V</span>ert ^&#123;2&#125;<span class=\"hljs-symbol\">\\r</span>ight) \t<br><span class=\"hljs-symbol\">\\\\</span>&amp;=<span class=\"hljs-symbol\">\\s</span>igma_&#123;X&#125;^&#123;2&#125;<br><span class=\"hljs-symbol\">\\e</span>nd&#123;aligned&#125;<br>$$<br></code></pre></td></tr></table></figure></li>\n<li><p>显示为</p>\n</li>\n</ul>\n\n$$\n\\begin{aligned}\n\\boldsymbol{x}^{\\mathrm{T}}C\\boldsymbol{x}\t&=\\boldsymbol{x}^{\\mathrm{T}}\\mathrm{E}\\left[\\left(X-\\mu\\right)\\left(X-\\mu\\right)^{\\mathrm{T}}\\right]\\boldsymbol{x} \t\n\\\\&=\\mathrm{E}\\left[\\boldsymbol{x}^{\\mathrm{T}}\\left(X-\\mu\\right)\\left(X-\\mu\\right)^{\\mathrm{T}}\\boldsymbol{x}\\right] \t\\\\&=\\mathrm{E}\\left[\\left(\\left(X-\\mu\\right)^{\\mathrm{T}}\\boldsymbol{x}\\right)^{\\mathrm{T}}\\left(\\left(X-\\mu\\right)^{\\mathrm{T}}\\boldsymbol{x}\\right)\\right] \t\n\\\\&=\\mathrm{E}\\left(\\left\\Vert \\left(X-\\mu\\right)^{\\mathrm{T}}\\boldsymbol{x}\\right\\Vert ^{2}\\right) \t\n\\\\&=\\sigma_{X}^{2}\n\\end{aligned}\n$$\n\n\n"},{"title":"低秩逼近的思考","date":"2021-08-06T08:38:25.000Z","math":true,"_content":"\n> 阅读文章**Semi-orthogonal Embedding for Effificient Unsupervised Anomaly Segmentation**时出现一个概念--**Low-rank approximation** ，就此进行相关讨论。\n\n### 低秩（Low-Rank）\n\n如果X是一个m行n列的数值矩阵，rank(X)是X的秩，假如rank (X)远小于m和n，则我们称X是低秩矩阵。低秩矩阵每行或每列都可以用其他的行或列线性表出，可见它包含大量的冗余信息。利用这种冗余信息，可以对缺失数据进行恢复，也可以对数据进行特征提取。\n\n图像处理中，*rank可以理解为图像所包含的信息的丰富程度*，在显示生活中，一张图片中大部分成分是相似的。比如给一张大草原的图片\n\n![](https://pic1.zhimg.com/50/ce29981e00f4d519ff547e986bf8a5d6_720w.jpg?source=1940ef5c)\n\n\n\n草原是由很多草组成的，而草是相似的，所以如果全是草，那么这张图所包含的信息量是很少的的，因为可以理解为草是草的复制品。而上图的蒙古包，人，马之类的则可以理解为图片所包含的信息，实际上，相对于只有草的草原图片和有草和蒙古包的草原图片，后者的秩是较高的。也就是说，图片中比较突兀的成分，比如蒙古包，比如人像照片中的红眼亮点，会增加图像矩阵的秩。而现实生活中一张不错的图片的秩其实是比较低的，如果图像的秩比较高，往往是因为图像中的噪声比较严重。比如拍照的时候ISO感光度设置过高造成噪点太过泛滥之类的。所以，*图像处理的低秩性其实可以拿来去除照片中的噪点*。\n\n### 低秩和稀疏\n\n我们认为图像有一些公共的模式，所有图像都由这些基本的模式组成。例如，如果图像是一个叉，可以看成是一个正斜线和反斜线的叠加。**只要我们找到了所有的基底（称作字典**，就是上面说的正斜线和反斜线之类的东西）**，就能通过基底的线性组合表示出所有的图像。**这就好像学画画，先学会基本的画正方体、球体、圆柱体等等，就可以组合出各种各样的复杂形状。\n\n**在很多情形下，基底的数量是很少的**，比如一张照片拍的是一面砖墙，那么它显然具有周期重复的特点，换句话说低秩。即使整个图不低秩，往往也能找出一些相似的块，这些块是低秩的。再退一步，就算这也做不到，往往也可以把已有的数据看成一组低维的结果加上噪声，也即原来的数据**可以被低秩矩阵很好的逼近**。**稀疏性**的意思是（以稀疏表示为例），任给一个图像，**字典可能是过完备的**，从而用字典里的基向量表出这幅图有很多种不同的方案。我们希望**选取使用基底数量最少的那种方案**，\n\n应用：\n\n***1）矩阵填充(Matrix Completion)***\n\n***2）鲁棒PCA***\n\n***3）背景建模***\n\n***4）变换不变低秩纹理（TILT）***\n\n> 参考\n>\n>  https://www.zhihu.com/question/28630628\n>\n> https://blog.csdn.net/zouxy09/article/details/24972869\n","source":"_posts/low-rank-app.md","raw":"---\ntitle: 低秩逼近的思考\ndate: 2021-08-06 16:38:25\ntags: [math,线性代数]\ncategories: [math,线性代数]\nmath: true\n---\n\n> 阅读文章**Semi-orthogonal Embedding for Effificient Unsupervised Anomaly Segmentation**时出现一个概念--**Low-rank approximation** ，就此进行相关讨论。\n\n### 低秩（Low-Rank）\n\n如果X是一个m行n列的数值矩阵，rank(X)是X的秩，假如rank (X)远小于m和n，则我们称X是低秩矩阵。低秩矩阵每行或每列都可以用其他的行或列线性表出，可见它包含大量的冗余信息。利用这种冗余信息，可以对缺失数据进行恢复，也可以对数据进行特征提取。\n\n图像处理中，*rank可以理解为图像所包含的信息的丰富程度*，在显示生活中，一张图片中大部分成分是相似的。比如给一张大草原的图片\n\n![](https://pic1.zhimg.com/50/ce29981e00f4d519ff547e986bf8a5d6_720w.jpg?source=1940ef5c)\n\n\n\n草原是由很多草组成的，而草是相似的，所以如果全是草，那么这张图所包含的信息量是很少的的，因为可以理解为草是草的复制品。而上图的蒙古包，人，马之类的则可以理解为图片所包含的信息，实际上，相对于只有草的草原图片和有草和蒙古包的草原图片，后者的秩是较高的。也就是说，图片中比较突兀的成分，比如蒙古包，比如人像照片中的红眼亮点，会增加图像矩阵的秩。而现实生活中一张不错的图片的秩其实是比较低的，如果图像的秩比较高，往往是因为图像中的噪声比较严重。比如拍照的时候ISO感光度设置过高造成噪点太过泛滥之类的。所以，*图像处理的低秩性其实可以拿来去除照片中的噪点*。\n\n### 低秩和稀疏\n\n我们认为图像有一些公共的模式，所有图像都由这些基本的模式组成。例如，如果图像是一个叉，可以看成是一个正斜线和反斜线的叠加。**只要我们找到了所有的基底（称作字典**，就是上面说的正斜线和反斜线之类的东西）**，就能通过基底的线性组合表示出所有的图像。**这就好像学画画，先学会基本的画正方体、球体、圆柱体等等，就可以组合出各种各样的复杂形状。\n\n**在很多情形下，基底的数量是很少的**，比如一张照片拍的是一面砖墙，那么它显然具有周期重复的特点，换句话说低秩。即使整个图不低秩，往往也能找出一些相似的块，这些块是低秩的。再退一步，就算这也做不到，往往也可以把已有的数据看成一组低维的结果加上噪声，也即原来的数据**可以被低秩矩阵很好的逼近**。**稀疏性**的意思是（以稀疏表示为例），任给一个图像，**字典可能是过完备的**，从而用字典里的基向量表出这幅图有很多种不同的方案。我们希望**选取使用基底数量最少的那种方案**，\n\n应用：\n\n***1）矩阵填充(Matrix Completion)***\n\n***2）鲁棒PCA***\n\n***3）背景建模***\n\n***4）变换不变低秩纹理（TILT）***\n\n> 参考\n>\n>  https://www.zhihu.com/question/28630628\n>\n> https://blog.csdn.net/zouxy09/article/details/24972869\n","slug":"low-rank-app","published":1,"updated":"2021-08-09T06:11:11.759Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cks4ew7um000fxox41ur036bz","content":"<blockquote>\n<p>阅读文章<strong>Semi-orthogonal Embedding for Effificient Unsupervised Anomaly Segmentation</strong>时出现一个概念–<strong>Low-rank approximation</strong> ，就此进行相关讨论。</p>\n</blockquote>\n<h3 id=\"低秩（Low-Rank）\"><a href=\"#低秩（Low-Rank）\" class=\"headerlink\" title=\"低秩（Low-Rank）\"></a>低秩（Low-Rank）</h3><p>如果X是一个m行n列的数值矩阵，rank(X)是X的秩，假如rank (X)远小于m和n，则我们称X是低秩矩阵。低秩矩阵每行或每列都可以用其他的行或列线性表出，可见它包含大量的冗余信息。利用这种冗余信息，可以对缺失数据进行恢复，也可以对数据进行特征提取。</p>\n<p>图像处理中，<em>rank可以理解为图像所包含的信息的丰富程度</em>，在显示生活中，一张图片中大部分成分是相似的。比如给一张大草原的图片</p>\n<p><img src=\"https://pic1.zhimg.com/50/ce29981e00f4d519ff547e986bf8a5d6_720w.jpg?source=1940ef5c\"></p>\n<p>草原是由很多草组成的，而草是相似的，所以如果全是草，那么这张图所包含的信息量是很少的的，因为可以理解为草是草的复制品。而上图的蒙古包，人，马之类的则可以理解为图片所包含的信息，实际上，相对于只有草的草原图片和有草和蒙古包的草原图片，后者的秩是较高的。也就是说，图片中比较突兀的成分，比如蒙古包，比如人像照片中的红眼亮点，会增加图像矩阵的秩。而现实生活中一张不错的图片的秩其实是比较低的，如果图像的秩比较高，往往是因为图像中的噪声比较严重。比如拍照的时候ISO感光度设置过高造成噪点太过泛滥之类的。所以，<em>图像处理的低秩性其实可以拿来去除照片中的噪点</em>。</p>\n<h3 id=\"低秩和稀疏\"><a href=\"#低秩和稀疏\" class=\"headerlink\" title=\"低秩和稀疏\"></a>低秩和稀疏</h3><p>我们认为图像有一些公共的模式，所有图像都由这些基本的模式组成。例如，如果图像是一个叉，可以看成是一个正斜线和反斜线的叠加。<strong>只要我们找到了所有的基底（称作字典</strong>，就是上面说的正斜线和反斜线之类的东西）<strong>，就能通过基底的线性组合表示出所有的图像。</strong>这就好像学画画，先学会基本的画正方体、球体、圆柱体等等，就可以组合出各种各样的复杂形状。</p>\n<p><strong>在很多情形下，基底的数量是很少的</strong>，比如一张照片拍的是一面砖墙，那么它显然具有周期重复的特点，换句话说低秩。即使整个图不低秩，往往也能找出一些相似的块，这些块是低秩的。再退一步，就算这也做不到，往往也可以把已有的数据看成一组低维的结果加上噪声，也即原来的数据<strong>可以被低秩矩阵很好的逼近</strong>。<strong>稀疏性</strong>的意思是（以稀疏表示为例），任给一个图像，<strong>字典可能是过完备的</strong>，从而用字典里的基向量表出这幅图有很多种不同的方案。我们希望<strong>选取使用基底数量最少的那种方案</strong>，</p>\n<p>应用：</p>\n<p><em><strong>1）矩阵填充(Matrix Completion)</strong></em></p>\n<p><em><strong>2）鲁棒PCA</strong></em></p>\n<p><em><strong>3）背景建模</strong></em></p>\n<p><em><strong>4）变换不变低秩纹理（TILT）</strong></em></p>\n<blockquote>\n<p>参考</p>\n<p> <a href=\"https://www.zhihu.com/question/28630628\">https://www.zhihu.com/question/28630628</a></p>\n<p><a href=\"https://blog.csdn.net/zouxy09/article/details/24972869\">https://blog.csdn.net/zouxy09/article/details/24972869</a></p>\n</blockquote>\n","site":{"data":{"friends":[{"avatar":"http://image.luokangyuan.com/1_qq_27922023.jpg","name":"码酱","introduction":"我不是大佬，只是在追寻大佬的脚步","url":"http://luokangyuan.com/","title":"前去学习"},{"avatar":"http://image.luokangyuan.com/4027734.jpeg","name":"闪烁之狐","introduction":"编程界大佬，技术牛，人还特别好，不懂的都可以请教大佬","url":"https://blinkfox.github.io/","title":"前去学习"},{"avatar":"http://image.luokangyuan.com/avatar.jpg","name":"ja_rome","introduction":"平凡的脚步也可以走出伟大的行程","url":"https://me.csdn.net/jlh912008548","title":"前去学习"}]}},"excerpt":"","more":"<blockquote>\n<p>阅读文章<strong>Semi-orthogonal Embedding for Effificient Unsupervised Anomaly Segmentation</strong>时出现一个概念–<strong>Low-rank approximation</strong> ，就此进行相关讨论。</p>\n</blockquote>\n<h3 id=\"低秩（Low-Rank）\"><a href=\"#低秩（Low-Rank）\" class=\"headerlink\" title=\"低秩（Low-Rank）\"></a>低秩（Low-Rank）</h3><p>如果X是一个m行n列的数值矩阵，rank(X)是X的秩，假如rank (X)远小于m和n，则我们称X是低秩矩阵。低秩矩阵每行或每列都可以用其他的行或列线性表出，可见它包含大量的冗余信息。利用这种冗余信息，可以对缺失数据进行恢复，也可以对数据进行特征提取。</p>\n<p>图像处理中，<em>rank可以理解为图像所包含的信息的丰富程度</em>，在显示生活中，一张图片中大部分成分是相似的。比如给一张大草原的图片</p>\n<p><img src=\"https://pic1.zhimg.com/50/ce29981e00f4d519ff547e986bf8a5d6_720w.jpg?source=1940ef5c\"></p>\n<p>草原是由很多草组成的，而草是相似的，所以如果全是草，那么这张图所包含的信息量是很少的的，因为可以理解为草是草的复制品。而上图的蒙古包，人，马之类的则可以理解为图片所包含的信息，实际上，相对于只有草的草原图片和有草和蒙古包的草原图片，后者的秩是较高的。也就是说，图片中比较突兀的成分，比如蒙古包，比如人像照片中的红眼亮点，会增加图像矩阵的秩。而现实生活中一张不错的图片的秩其实是比较低的，如果图像的秩比较高，往往是因为图像中的噪声比较严重。比如拍照的时候ISO感光度设置过高造成噪点太过泛滥之类的。所以，<em>图像处理的低秩性其实可以拿来去除照片中的噪点</em>。</p>\n<h3 id=\"低秩和稀疏\"><a href=\"#低秩和稀疏\" class=\"headerlink\" title=\"低秩和稀疏\"></a>低秩和稀疏</h3><p>我们认为图像有一些公共的模式，所有图像都由这些基本的模式组成。例如，如果图像是一个叉，可以看成是一个正斜线和反斜线的叠加。<strong>只要我们找到了所有的基底（称作字典</strong>，就是上面说的正斜线和反斜线之类的东西）<strong>，就能通过基底的线性组合表示出所有的图像。</strong>这就好像学画画，先学会基本的画正方体、球体、圆柱体等等，就可以组合出各种各样的复杂形状。</p>\n<p><strong>在很多情形下，基底的数量是很少的</strong>，比如一张照片拍的是一面砖墙，那么它显然具有周期重复的特点，换句话说低秩。即使整个图不低秩，往往也能找出一些相似的块，这些块是低秩的。再退一步，就算这也做不到，往往也可以把已有的数据看成一组低维的结果加上噪声，也即原来的数据<strong>可以被低秩矩阵很好的逼近</strong>。<strong>稀疏性</strong>的意思是（以稀疏表示为例），任给一个图像，<strong>字典可能是过完备的</strong>，从而用字典里的基向量表出这幅图有很多种不同的方案。我们希望<strong>选取使用基底数量最少的那种方案</strong>，</p>\n<p>应用：</p>\n<p><em><strong>1）矩阵填充(Matrix Completion)</strong></em></p>\n<p><em><strong>2）鲁棒PCA</strong></em></p>\n<p><em><strong>3）背景建模</strong></em></p>\n<p><em><strong>4）变换不变低秩纹理（TILT）</strong></em></p>\n<blockquote>\n<p>参考</p>\n<p> <a href=\"https://www.zhihu.com/question/28630628\">https://www.zhihu.com/question/28630628</a></p>\n<p><a href=\"https://blog.csdn.net/zouxy09/article/details/24972869\">https://blog.csdn.net/zouxy09/article/details/24972869</a></p>\n</blockquote>\n"}],"PostAsset":[],"PostCategory":[{"post_id":"cks4ew7ui0009xox44x8bduwo","category_id":"cks4ew7uo000kxox4012704po","_id":"cks4ew7up000rxox4b0vg4bz9"},{"post_id":"cks4ew7uc0001xox471tr05m8","category_id":"cks4ew7uf0004xox4dgovc1z3","_id":"cks4ew7uq000vxox4ehnq4xt2"},{"post_id":"cks4ew7uc0001xox471tr05m8","category_id":"cks4ew7up000oxox4ghlk9hnu","_id":"cks4ew7us000zxox45hk1477t"},{"post_id":"cks4ew7um000fxox41ur036bz","category_id":"cks4ew7uf0004xox4dgovc1z3","_id":"cks4ew7ut0013xox45zkx7ibo"},{"post_id":"cks4ew7um000fxox41ur036bz","category_id":"cks4ew7up000oxox4ghlk9hnu","_id":"cks4ew7uu0016xox4603ohrxo"},{"post_id":"cks4ew7ue0003xox4hhai8gxn","category_id":"cks4ew7uf0004xox4dgovc1z3","_id":"cks4ew7uu0018xox49pilbevk"},{"post_id":"cks4ew7ue0003xox4hhai8gxn","category_id":"cks4ew7ut0011xox4dcuq36sd","_id":"cks4ew7uu0019xox45m8c2r00"},{"post_id":"cks4ew7uh0007xox44y0qcuiv","category_id":"cks4ew7uf0004xox4dgovc1z3","_id":"cks4ew7uv001bxox4geppffyy"},{"post_id":"cks4ew7uh0007xox44y0qcuiv","category_id":"cks4ew7ut0011xox4dcuq36sd","_id":"cks4ew7uv001dxox49pgnblf5"},{"post_id":"cks4ew7uj000bxox456vq8c3h","category_id":"cks4ew7up000sxox48nrv081m","_id":"cks4ew7uv001fxox4bl7g44p7"},{"post_id":"cks4ew7uj000bxox456vq8c3h","category_id":"cks4ew7uu0017xox48ujy06zd","_id":"cks4ew7uv001gxox4gpvz49i6"}],"PostTag":[{"post_id":"cks4ew7um000fxox41ur036bz","tag_id":"cks4ew7ug0005xox46qc7egjv","_id":"cks4ew7uo000ixox468iocbcz"},{"post_id":"cks4ew7um000fxox41ur036bz","tag_id":"cks4ew7uk000dxox4hjn0djdn","_id":"cks4ew7uo000jxox457chew7v"},{"post_id":"cks4ew7uc0001xox471tr05m8","tag_id":"cks4ew7ug0005xox46qc7egjv","_id":"cks4ew7uo000mxox48vatcg7y"},{"post_id":"cks4ew7uc0001xox471tr05m8","tag_id":"cks4ew7uk000dxox4hjn0djdn","_id":"cks4ew7uo000nxox457ts18te"},{"post_id":"cks4ew7ue0003xox4hhai8gxn","tag_id":"cks4ew7un000hxox42vc6gw9x","_id":"cks4ew7up000qxox4bvwb6gfh"},{"post_id":"cks4ew7uh0007xox44y0qcuiv","tag_id":"cks4ew7ug0005xox46qc7egjv","_id":"cks4ew7uq000uxox44ak3a3dt"},{"post_id":"cks4ew7uh0007xox44y0qcuiv","tag_id":"cks4ew7up000pxox4fswk44ix","_id":"cks4ew7uq000wxox46ffu8gau"},{"post_id":"cks4ew7ui0009xox44x8bduwo","tag_id":"cks4ew7uq000txox40ffo1haa","_id":"cks4ew7ut0010xox4bu6dfwuv"},{"post_id":"cks4ew7uj000bxox456vq8c3h","tag_id":"cks4ew7ur000yxox4cd65hjab","_id":"cks4ew7uv001axox427cza079"},{"post_id":"cks4ew7uj000bxox456vq8c3h","tag_id":"cks4ew7ut0012xox47ijrbq68","_id":"cks4ew7uv001cxox4bf6lfw9n"},{"post_id":"cks4ew7uj000bxox456vq8c3h","tag_id":"cks4ew7uu0015xox4ft8w5rpu","_id":"cks4ew7uv001exox49ia41qb6"}],"Tag":[{"name":"math","_id":"cks4ew7ug0005xox46qc7egjv"},{"name":"线性代数","_id":"cks4ew7uk000dxox4hjn0djdn"},{"name":"马氏距离","_id":"cks4ew7un000hxox42vc6gw9x"},{"name":"概率论","_id":"cks4ew7up000pxox4fswk44ix"},{"name":"git","_id":"cks4ew7uq000txox40ffo1haa"},{"name":"hexo","_id":"cks4ew7ur000yxox4cd65hjab"},{"name":"fluid","_id":"cks4ew7ut0012xox47ijrbq68"},{"name":"配置","_id":"cks4ew7uu0015xox4ft8w5rpu"}]}}